#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ä¿®å¤åçš„åŒ¹é…ç®—æ³•
"""

import sys
import os
import re
from difflib import SequenceMatcher

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

class FixedMatcher:
    """ä¿®å¤åçš„åŒ¹é…å™¨"""
    
    def __init__(self, class_names):
        self.class_names = class_names or []
    
    def _smart_class_matching(self, filename, class_names):
        """ä¿®å¤åçš„æ™ºèƒ½ç±»åˆ«åŒ¹é…ç®—æ³• - æœ€ç»ˆä¼˜åŒ–ç‰ˆæœ¬"""
        filename_upper = filename.upper()
        best_match = None
        best_score = 0.0
        match_details = []
        
        # å¦‚æœæå–çš„ç±»åˆ«å¤ªçŸ­ï¼ˆå•å­—ç¬¦ï¼‰ï¼Œç›´æ¥æ‹’ç»
        if len(filename.strip()) <= 1:
            print(f"å•å­—ç¬¦ç±»åˆ«æå–è¢«æ‹’ç»: {filename}")
            return None
        
        # å¦‚æœåŒ…å«æ˜æ˜¾çš„"å™ªéŸ³"å…³é”®è¯ï¼Œç›´æ¥æ‹’ç»
        noise_keywords = ['UNKNOWN', 'TEST', 'SAMPLE', 'TEMP', 'DEBUG', 'CLASS']
        if any(noise in filename_upper for noise in noise_keywords):
            print(f"å™ªéŸ³å…³é”®è¯ç±»åˆ«è¢«æ‹’ç»: {filename}")
            return None
        
        # å¯¹æ¯ä¸ªç±»åˆ«è¿›è¡Œå…¨é¢çš„ç›¸ä¼¼åº¦åˆ†æ
        for class_name in class_names:
            class_upper = class_name.upper()
            max_similarity = 0.0
            best_match_type = ""
            
            # 1. ç²¾ç¡®åŒ¹é…ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
            if filename_upper == class_upper:
                max_similarity = 1.0
                best_match_type = f"ç²¾ç¡®åŒ¹é…"
            
            # 2. åŒ…å«å…³ç³»æ£€æŸ¥ - ä¼˜åŒ–ç²¾ç¡®åº¦è®¡ç®—
            elif class_upper in filename_upper:
                # è®¡ç®—ç²¾ç¡®åŒ¹é…åº¦ï¼Œé¿å…çŸ­ç±»åˆ«åŒ¹é…é•¿æ–‡ä»¶å
                precision = len(class_upper) / len(filename_upper)
                # åªæœ‰å½“ç±»åˆ«å æ–‡ä»¶åçš„æ¯”ä¾‹è¶³å¤Ÿå¤§æ—¶æ‰ç»™é«˜åˆ†
                if precision >= 0.5:  # ç±»åˆ«è‡³å°‘è¦å æ–‡ä»¶åçš„50%
                    max_similarity = 0.95 * precision
                    best_match_type = f"åŒ…å«åŒ¹é…(ç²¾ç¡®åº¦:{precision:.3f})"
                else:
                    # å¦‚æœæ¯”ä¾‹å¤ªå°ï¼Œé™ä½åˆ†æ•°
                    max_similarity = 0.7 * precision
                    best_match_type = f"éƒ¨åˆ†åŒ…å«åŒ¹é…(ç²¾ç¡®åº¦:{precision:.3f})"
            
            elif filename_upper in class_upper:
                # åå‘åŒ…å«ï¼šæ–‡ä»¶ååœ¨ç±»åˆ«åä¸­
                precision = len(filename_upper) / len(class_upper)
                # åªæœ‰å½“æ–‡ä»¶åå ç±»åˆ«çš„æ¯”ä¾‹è¶³å¤Ÿå¤§æ—¶æ‰ç»™é«˜åˆ†
                if precision >= 0.7:  # æ–‡ä»¶åè‡³å°‘è¦å ç±»åˆ«çš„70%
                    max_similarity = 0.90 * precision
                    best_match_type = f"åå‘åŒ…å«åŒ¹é…(ç²¾ç¡®åº¦:{precision:.3f})"
                else:
                    max_similarity = 0.6 * precision
                    best_match_type = f"éƒ¨åˆ†åå‘åŒ…å«åŒ¹é…(ç²¾ç¡®åº¦:{precision:.3f})"
            
            else:
                # 3. å®Œæ•´å­—ç¬¦ä¸²ç›¸ä¼¼åº¦
                full_similarity = SequenceMatcher(None, filename_upper, class_upper).ratio()
                if full_similarity > max_similarity:
                    max_similarity = full_similarity
                    best_match_type = f"å®Œæ•´åŒ¹é…(ç›¸ä¼¼åº¦:{full_similarity:.3f})"
                
                # 4. æ™ºèƒ½éƒ¨åˆ†åŒ¹é…
                filename_parts = [p for p in re.split(r'[_\-\s\d\(\)]+', filename_upper) if p and len(p) >= 2]
                class_parts = [p for p in re.split(r'[_\-\s\d]+', class_upper) if p and len(p) >= 2]
                
                if filename_parts and class_parts:
                    # è®¡ç®—éƒ¨åˆ†åŒ¹é…çš„æœ€é«˜ç›¸ä¼¼åº¦
                    part_similarities = []
                    for file_part in filename_parts:
                        for class_part in class_parts:
                            part_sim = SequenceMatcher(None, file_part, class_part).ratio()
                            part_similarities.append(part_sim)
                    
                    if part_similarities:
                        # ä½¿ç”¨æœ€é«˜çš„éƒ¨åˆ†ç›¸ä¼¼åº¦ï¼Œä½†ç»™äºˆæƒé‡
                        best_part_similarity = max(part_similarities)
                        weighted_similarity = best_part_similarity * 0.7  # é™æƒé‡
                        if weighted_similarity > max_similarity:
                            max_similarity = weighted_similarity
                            best_match_type = f"éƒ¨åˆ†åŒ¹é…(ç›¸ä¼¼åº¦:{best_part_similarity:.3f})"
            
            # è®°å½•åŒ¹é…è¯¦æƒ…
            match_details.append({
                'class_name': class_name,
                'similarity': max_similarity,
                'match_type': best_match_type,
                'length_diff': abs(len(class_upper) - len(filename_upper))  # é•¿åº¦å·®å¼‚
            })
        
        # ä¼˜åŒ–æ’åºç­–ç•¥ï¼šç›¸ä¼¼åº¦ä¼˜å…ˆï¼Œç„¶åæ˜¯é•¿åº¦å·®å¼‚æœ€å°çš„
        match_details.sort(key=lambda x: (-x['similarity'], x['length_diff']))
        
        if match_details:
            best_match_detail = match_details[0]
            best_score = best_match_detail['similarity']
            best_match = best_match_detail['class_name']
            
            # ä½¿ç”¨æ›´é«˜çš„é˜ˆå€¼ï¼Œå‡å°‘è¯¯åŒ¹é…
            threshold = 0.65 if len(filename) <= 3 else 0.55  # æé«˜é˜ˆå€¼
            
            if best_score >= threshold:
                return best_match
        
        return None
    
    def extract_class_from_filename(self, filename):
        """ä»æ–‡ä»¶åä¸­æå–ç±»åˆ«ä¿¡æ¯"""
        name_without_ext = os.path.splitext(filename)[0]
        
        if self.class_names:
            return self._smart_class_matching(name_without_ext, self.class_names)
        
        return None


def test_fixed_matching():
    """æµ‹è¯•ä¿®å¤åçš„åŒ¹é…ç®—æ³•"""
    print("=" * 80)
    print("ä¿®å¤åçš„åŒ¹é…ç®—æ³•æµ‹è¯•")
    print("=" * 80)
    
    # å¤æ‚çš„ç±»åˆ«åˆ—è¡¨
    complex_class_names = [
        "Missing_hole",
        "Mouse_bite", 
        "Open_circuit",
        "Short",
        "Spur",
        "Spurious_copper",
        "A_B",
        "A_B_C",
        "X_Y_Z", 
        "A_B_C_D",
        "Very_long_class_name",
    ]
    
    # å…³é”®æµ‹è¯•ç”¨ä¾‹ï¼ˆä¹‹å‰å¤±è´¥çš„ï¼‰
    critical_test_cases = [
        # å¤åˆç±»åé—®é¢˜
        ("A_B_C (1).jpg", "A_B_C"),       # ä¹‹å‰é”™è¯¯åŒ¹é…åˆ°A_B
        ("A_B_C (2).jpg", "A_B_C"),       # ä¹‹å‰é”™è¯¯åŒ¹é…åˆ°A_B
        ("A_B_C_001.jpg", "A_B_C"),       # ä¹‹å‰é”™è¯¯åŒ¹é…åˆ°A_B
        ("A_B_C_D (1).jpg", "A_B_C_D"),   # ä¹‹å‰é”™è¯¯åŒ¹é…åˆ°A_B
        ("A_B_C_D_001.jpg", "A_B_C_D"),   # ä¹‹å‰é”™è¯¯åŒ¹é…åˆ°A_B
        
        # å•å­—ç¬¦é—®é¢˜
        ("A.jpg", None),                  # åº”è¯¥è¢«æ‹’ç»
        ("B.jpg", None),                  # åº”è¯¥è¢«æ‹’ç»
        
        # å™ªéŸ³å…³é”®è¯
        ("unknown_class.jpg", None),      # åº”è¯¥è¢«æ‹’ç»
        ("test_sample.jpg", None),        # åº”è¯¥è¢«æ‹’ç»
        
        # æ­£å¸¸æƒ…å†µ
        ("A_B (1).jpg", "A_B"),          # åº”è¯¥æ­£ç¡®
        ("Missing_hole_001.jpg", "Missing_hole"),  # åº”è¯¥æ­£ç¡®
        ("X_Y_Z_002.jpg", "X_Y_Z"),      # åº”è¯¥æ­£ç¡®
    ]
    
    print(f"ç±»åˆ«åˆ—è¡¨: {complex_class_names}")
    print(f"å…³é”®æµ‹è¯•ç”¨ä¾‹æ•°é‡: {len(critical_test_cases)}")
    
    # åˆ›å»ºä¿®å¤åçš„åŒ¹é…å™¨
    matcher = FixedMatcher(complex_class_names)
    
    print("\n" + "=" * 80)
    print("å…³é”®æµ‹è¯•ç»“æœ:")
    print("=" * 80)
    
    # æµ‹è¯•æ¯ä¸ªå…³é”®ç”¨ä¾‹
    correct_matches = 0
    total_tests = len(critical_test_cases)
    
    for filename, expected_class in critical_test_cases:
        # ä½¿ç”¨ä¿®å¤åçš„åŒ¹é…ç®—æ³•
        matched_class = matcher.extract_class_from_filename(filename)
        
        # åˆ¤æ–­åŒ¹é…ç»“æœ
        is_correct = matched_class == expected_class
        if is_correct:
            correct_matches += 1
            status = "âœ… æ­£ç¡®"
        else:
            status = "âŒ é”™è¯¯"
        
        expected_str = str(expected_class) if expected_class is not None else "None"
        matched_str = str(matched_class) if matched_class is not None else "None"
        print(f"{status} | æ–‡ä»¶: {filename:<25} | æœŸæœ›: {expected_str:<15} | å®é™…: {matched_str}")
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•ç»Ÿè®¡:")
    print("=" * 80)
    print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"æ­£ç¡®åŒ¹é…: {correct_matches}")
    print(f"é”™è¯¯åŒ¹é…: {total_tests - correct_matches}")
    print(f"å‡†ç¡®ç‡: {correct_matches / total_tests * 100:.2f}%")
    
    # åˆ†ææ”¹è¿›æ•ˆæœ
    print("\n" + "=" * 80)
    print("æ”¹è¿›æ•ˆæœåˆ†æ:")
    print("=" * 80)
    
    if correct_matches / total_tests >= 0.9:
        print("ğŸ‰ ä¼˜ç§€ï¼ä¿®å¤åçš„ç®—æ³•æ˜¾è‘—æ”¹å–„äº†åŒ¹é…å‡†ç¡®ç‡")
    elif correct_matches / total_tests >= 0.8:
        print("âœ… è‰¯å¥½ï¼ä¿®å¤æœ‰æ•ˆï¼Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´")
    else:
        print("âš ï¸  éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
    
    return correct_matches / total_tests


if __name__ == "__main__":
    accuracy = test_fixed_matching()
    
    print("\n" + "=" * 80)
    print("ç»“è®º:")
    print("=" * 80)
    print("å…³é”®ä¿®å¤:")
    print("1. ç²¾ç¡®åº¦æƒé‡ï¼šåŒ…å«åŒ¹é…ç°åœ¨è€ƒè™‘ç²¾ç¡®åº¦ï¼ŒA_B_Cä¸ä¼šé”™è¯¯åŒ¹é…åˆ°A_B")
    print("2. å•å­—ç¬¦è¿‡æ»¤ï¼šAã€Bç­‰å•å­—ç¬¦æå–ç»“æœè¢«ç›´æ¥æ‹’ç»")
    print("3. å™ªéŸ³è¿‡æ»¤ï¼šunknownã€testç­‰å…³é”®è¯è¢«è¿‡æ»¤")
    print("4. æ’åºä¼˜åŒ–ï¼šç›¸ä¼¼åº¦ç›¸åŒæ—¶ï¼Œä¼˜å…ˆé€‰æ‹©æ›´é•¿çš„ç±»åˆ«å")
    print("5. é˜ˆå€¼æå‡ï¼šå‡å°‘è¯¯åŒ¹é…")
    print("=" * 80) 