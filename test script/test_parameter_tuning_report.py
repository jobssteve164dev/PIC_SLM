#!/usr/bin/env python3
"""
å‚æ•°å¾®è°ƒæŠ¥å‘Šç”ŸæˆåŠŸèƒ½æµ‹è¯•è„šæœ¬

æµ‹è¯•æ™ºèƒ½è®­ç»ƒç»„ä»¶çš„å‚æ•°å¾®è°ƒæŠ¥å‘Šç”ŸæˆåŠŸèƒ½
"""

import os
import sys
import json
import time
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from src.training_components.parameter_tuning_report_generator import ParameterTuningReportGenerator


def test_report_generator():
    """æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨åŠŸèƒ½"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•å‚æ•°å¾®è°ƒæŠ¥å‘Šç”Ÿæˆå™¨...")
    
    # æµ‹è¯•é…ç½®
    test_config = {
        'parameter_tuning_reports': {
            'enabled': True,
            'save_path': 'test_reports/parameter_tuning',
            'format': 'markdown',
            'include_llm_analysis': True,
            'include_metrics_comparison': True,
            'include_config_changes': True
        }
    }
    
    # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
    generator = ParameterTuningReportGenerator(test_config)
    print("âœ… æŠ¥å‘Šç”Ÿæˆå™¨åˆ›å»ºæˆåŠŸ")
    
    # æµ‹è¯•æ•°æ®
    original_config = {
        'model_name': 'MobileNetV2',
        'learning_rate': 0.001,
        'batch_size': 32,
        'num_epochs': 50,
        'dropout_rate': 0.2,
        'weight_decay': 0.0001,
        'early_stopping_patience': 10
    }
    
    adjusted_config = {
        'model_name': 'MobileNetV2',
        'learning_rate': 0.0005,  # é™ä½å­¦ä¹ ç‡
        'batch_size': 16,         # å‡å°æ‰¹æ¬¡å¤§å°
        'num_epochs': 50,
        'dropout_rate': 0.3,      # å¢åŠ dropout
        'weight_decay': 0.0002,   # å¢åŠ æƒé‡è¡°å‡
        'early_stopping_patience': 10
    }
    
    changes = {
        'learning_rate': {'from': 0.001, 'to': 0.0005},
        'batch_size': {'from': 32, 'to': 16},
        'dropout_rate': {'from': 0.2, 'to': 0.3},
        'weight_decay': {'from': 0.0001, 'to': 0.0002}
    }
    
    llm_analysis = {
        'reason': 'æ£€æµ‹åˆ°è¿‡æ‹Ÿåˆé£é™©ï¼Œéœ€è¦è°ƒæ•´å‚æ•°',
        'analysis': '''
åŸºäºå½“å‰è®­ç»ƒæŒ‡æ ‡åˆ†æï¼Œå‘ç°ä»¥ä¸‹é—®é¢˜ï¼š

1. **è¿‡æ‹Ÿåˆé£é™©**: éªŒè¯æŸå¤±å¼€å§‹ä¸Šå‡ï¼Œè€Œè®­ç»ƒæŸå¤±ç»§ç»­ä¸‹é™
2. **å­¦ä¹ ç‡è¿‡é«˜**: å½“å‰å­¦ä¹ ç‡å¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®š
3. **æ­£åˆ™åŒ–ä¸è¶³**: Dropoutå’Œæƒé‡è¡°å‡éœ€è¦å¢å¼º

å»ºè®®çš„ä¼˜åŒ–ç­–ç•¥ï¼š
- é™ä½å­¦ä¹ ç‡ä»¥æé«˜è®­ç»ƒç¨³å®šæ€§
- å‡å°æ‰¹æ¬¡å¤§å°ä»¥å¢åŠ æ¢¯åº¦å™ªå£°
- å¢åŠ Dropoutç‡ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆ
- å¢å¼ºæƒé‡è¡°å‡ä»¥æ”¹å–„æ³›åŒ–èƒ½åŠ›
        ''',
        'suggestions': [
            {
                'parameter': 'learning_rate',
                'current_value': 0.001,
                'suggested_value': 0.0005,
                'reason': 'è®­ç»ƒæŸå¤±ä¸‹é™ç¼“æ…¢ï¼Œå»ºè®®é™ä½å­¦ä¹ ç‡',
                'priority': 'high'
            },
            {
                'parameter': 'batch_size',
                'current_value': 32,
                'suggested_value': 16,
                'reason': 'GPUå†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®å‡å°æ‰¹æ¬¡å¤§å°',
                'priority': 'medium'
            },
            {
                'parameter': 'dropout_rate',
                'current_value': 0.2,
                'suggested_value': 0.3,
                'reason': 'æ£€æµ‹åˆ°è¿‡æ‹Ÿåˆï¼Œå»ºè®®å¢åŠ Dropoutç‡',
                'priority': 'high'
            },
            {
                'parameter': 'weight_decay',
                'current_value': 0.0001,
                'suggested_value': 0.0002,
                'reason': 'æ£€æµ‹åˆ°è¿‡æ‹Ÿåˆï¼Œå»ºè®®å¢åŠ æƒé‡è¡°å‡',
                'priority': 'high'
            }
        ]
    }
    
    training_metrics = {
        'epoch': 15,
        'train_loss': 0.234,
        'val_loss': 0.312,
        'train_accuracy': 0.892,
        'val_accuracy': 0.856,
        'learning_rate': 0.001,
        'batch_size': 32,
        'gpu_memory_usage': 0.78,
        'training_time': 125.6
    }
    
    # ç”ŸæˆæŠ¥å‘Š
    print("ğŸ“ æ­£åœ¨ç”Ÿæˆå‚æ•°å¾®è°ƒæŠ¥å‘Š...")
    report_path = generator.generate_report(
        original_config=original_config,
        adjusted_config=adjusted_config,
        changes=changes,
        llm_analysis=llm_analysis,
        training_metrics=training_metrics,
        reason="æ™ºèƒ½å‚æ•°ä¼˜åŒ– - è¿‡æ‹Ÿåˆé£é™©è°ƒæ•´",
        session_id="test_session_001",
        adjustment_id="adj_001"
    )
    
    if report_path:
        print(f"âœ… æŠ¥å‘Šç”ŸæˆæˆåŠŸ: {report_path}")
        
        # éªŒè¯æŠ¥å‘Šæ–‡ä»¶
        if os.path.exists(report_path):
            print("âœ… æŠ¥å‘Šæ–‡ä»¶å­˜åœ¨")
            
            # è¯»å–å¹¶æ˜¾ç¤ºæŠ¥å‘Šå†…å®¹
            with open(report_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            print(f"ğŸ“Š æŠ¥å‘Šå†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            print("ğŸ“‹ æŠ¥å‘Šå†…å®¹é¢„è§ˆ:")
            print("-" * 50)
            print(content[:500] + "..." if len(content) > 500 else content)
            print("-" * 50)
            
            # æ£€æŸ¥æŠ¥å‘Šå†…å®¹æ˜¯å¦åŒ…å«å…³é”®ä¿¡æ¯
            required_sections = [
                "# æ™ºèƒ½è®­ç»ƒå‚æ•°å¾®è°ƒæŠ¥å‘Š",
                "## ğŸ“‹ è°ƒæ•´åŸå› ",
                "## ğŸ”§ é…ç½®å˜æ›´è¯¦æƒ…",
                "## ğŸ¤– LLMåˆ†æç»“æœ",
                "## ğŸ“Š è®­ç»ƒæŒ‡æ ‡",
                "## âš™ï¸ é…ç½®å¯¹æ¯”",
                "## ğŸ“ æŠ¥å‘Šæ€»ç»“"
            ]
            
            missing_sections = []
            for section in required_sections:
                if section not in content:
                    missing_sections.append(section)
            
            if missing_sections:
                print(f"âš ï¸ æŠ¥å‘Šç¼ºå°‘ä»¥ä¸‹éƒ¨åˆ†: {missing_sections}")
            else:
                print("âœ… æŠ¥å‘ŠåŒ…å«æ‰€æœ‰å¿…éœ€çš„éƒ¨åˆ†")
            
            # æ£€æŸ¥é…ç½®å˜æ›´æ˜¯å¦æ­£ç¡®æ˜¾ç¤º
            if "learning_rate" in content and "0.001" in content and "0.0005" in content:
                print("âœ… å­¦ä¹ ç‡å˜æ›´æ­£ç¡®æ˜¾ç¤º")
            else:
                print("âš ï¸ å­¦ä¹ ç‡å˜æ›´æ˜¾ç¤ºå¯èƒ½æœ‰é—®é¢˜")
            
            if "batch_size" in content and "32" in content and "16" in content:
                print("âœ… æ‰¹æ¬¡å¤§å°å˜æ›´æ­£ç¡®æ˜¾ç¤º")
            else:
                print("âš ï¸ æ‰¹æ¬¡å¤§å°å˜æ›´æ˜¾ç¤ºå¯èƒ½æœ‰é—®é¢˜")
            
            if "LLMåˆ†æç»“æœ" in content and "è¿‡æ‹Ÿåˆé£é™©" in content:
                print("âœ… LLMåˆ†æç»“æœæ­£ç¡®æ˜¾ç¤º")
            else:
                print("âš ï¸ LLMåˆ†æç»“æœæ˜¾ç¤ºå¯èƒ½æœ‰é—®é¢˜")
            
            if "è®­ç»ƒæŒ‡æ ‡" in content and "0.234" in content and "0.312" in content:
                print("âœ… è®­ç»ƒæŒ‡æ ‡æ­£ç¡®æ˜¾ç¤º")
            else:
                print("âš ï¸ è®­ç»ƒæŒ‡æ ‡æ˜¾ç¤ºå¯èƒ½æœ‰é—®é¢˜")
            
        else:
            print("âŒ æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨")
            return False
    else:
        print("âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
        return False
    
    return True


def test_config_update():
    """æµ‹è¯•é…ç½®æ›´æ–°åŠŸèƒ½"""
    print("\nğŸ”§ æµ‹è¯•é…ç½®æ›´æ–°åŠŸèƒ½...")
    
    generator = ParameterTuningReportGenerator()
    
    # æµ‹è¯•é…ç½®æ›´æ–°
    new_config = {
        'parameter_tuning_reports': {
            'enabled': False,
            'save_path': 'new_reports/path',
            'format': 'json',
            'include_llm_analysis': False
        }
    }
    
    generator.update_config(new_config)
    current_config = generator.get_config()
    
    print(f"âœ… é…ç½®æ›´æ–°æˆåŠŸ")
    print(f"ğŸ“‹ å½“å‰é…ç½®: {json.dumps(current_config, indent=2, ensure_ascii=False)}")
    
    return True


def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print("\nğŸ›¡ï¸ æµ‹è¯•é”™è¯¯å¤„ç†...")
    
    generator = ParameterTuningReportGenerator()
    
    # æµ‹è¯•æ— æ•ˆé…ç½®
    try:
        report_path = generator.generate_report(
            original_config={},
            adjusted_config={},
            changes={},
            llm_analysis={},
            training_metrics={},
            reason="æµ‹è¯•é”™è¯¯å¤„ç†",
            session_id="error_test",
            adjustment_id="error_001"
        )
        
        if not report_path:
            print("âœ… é”™è¯¯å¤„ç†æ­£å¸¸ - æ— æ•ˆé…ç½®æœªç”ŸæˆæŠ¥å‘Š")
        else:
            print("âš ï¸ é”™è¯¯å¤„ç†å¯èƒ½æœ‰é—®é¢˜ - æ— æ•ˆé…ç½®ç”Ÿæˆäº†æŠ¥å‘Š")
            
    except Exception as e:
        print(f"âœ… é”™è¯¯å¤„ç†æ­£å¸¸ - æ•è·åˆ°å¼‚å¸¸: {str(e)}")
    
    return True


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å‚æ•°å¾®è°ƒæŠ¥å‘Šç”ŸæˆåŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    test_results = []
    
    # è¿è¡Œæµ‹è¯•
    test_results.append(("æŠ¥å‘Šç”Ÿæˆå™¨åŸºæœ¬åŠŸèƒ½", test_report_generator()))
    test_results.append(("é…ç½®æ›´æ–°åŠŸèƒ½", test_config_update()))
    test_results.append(("é”™è¯¯å¤„ç†", test_error_handling()))
    
    # æ˜¾ç¤ºæµ‹è¯•ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    print("=" * 60)
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print("=" * 60)
    print(f"ğŸ“ˆ æµ‹è¯•é€šè¿‡ç‡: {passed}/{total} ({passed/total*100:.1f}%)")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å‚æ•°å¾®è°ƒæŠ¥å‘Šç”ŸæˆåŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½ã€‚")
    
    return passed == total


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
