#!/usr/bin/env python3
"""
æµ‹è¯•æ•°æ®æµæœåŠ¡å™¨å¼€å…³åŠŸèƒ½

éªŒè¯AIè®¾ç½®ä¸­çš„æ•°æ®æµæœåŠ¡å™¨å¼€å…³æ˜¯å¦èƒ½å¤Ÿæ­£ç¡®æ§åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ•°æ®æµæœåŠ¡å™¨å¯åŠ¨ã€‚
"""

import json
import os
import sys
import time
import tempfile
import shutil

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def test_data_stream_server_switch():
    """æµ‹è¯•æ•°æ®æµæœåŠ¡å™¨å¼€å…³åŠŸèƒ½"""
    print("=== æµ‹è¯•æ•°æ®æµæœåŠ¡å™¨å¼€å…³åŠŸèƒ½ ===\n")
    
    # 1. å¤‡ä»½åŸå§‹é…ç½®æ–‡ä»¶
    config_file = "setting/ai_config.json"
    backup_file = "setting/ai_config_backup.json"
    
    print("1. å¤‡ä»½åŸå§‹é…ç½®æ–‡ä»¶")
    if os.path.exists(config_file):
        shutil.copy2(config_file, backup_file)
        print(f"âœ… å·²å¤‡ä»½åˆ°: {backup_file}")
    else:
        print("âŒ åŸå§‹é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    try:
        # 2. æµ‹è¯•å¯ç”¨çŠ¶æ€
        print("\n2. æµ‹è¯•å¯ç”¨çŠ¶æ€")
        test_enabled_config = {
            "openai": {
                "api_key": "sk-test12345",
                "base_url": "",
                "model": "gpt-3.5-turbo",
                "temperature": 0.7,
                "max_tokens": 1003
            },
            "deepseek": {
                "api_key": "sk-63363d60338d444f9ad3709736609cd2",
                "base_url": "https://api.deepseek.com/v1",
                "model": "deepseek-chat",
                "temperature": 0.7,
                "max_tokens": 3000
            },
            "ollama": {
                "base_url": "http://localhost:11434",
                "model": "deepseek-r1:8b",
                "temperature": 0.7,
                "num_predict": 1000,
                "timeout": 120
            },
            "custom_api": {
                "name": "openrouter",
                "base_url": "https://openrouter.ai/api/v1",
                "api_key": "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",
                "provider_type": "OpenAIå…¼å®¹",
                "model": "deepseek/deepseek-r1-0528:free",
                "temperature": 0.7,
                "max_tokens": 1000
            },
            "general": {
                "default_adapter": "deepseek",
                "request_timeout": 180,
                "max_retries": 3,
                "enable_cache": True,
                "enable_streaming": True,
                "enable_data_stream_server": True
            }
        }
        
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(test_enabled_config, f, indent=2, ensure_ascii=False)
        
        print("âœ… å·²è®¾ç½®å¯ç”¨çŠ¶æ€")
        
        # 3. æµ‹è¯•ç¦ç”¨çŠ¶æ€
        print("\n3. æµ‹è¯•ç¦ç”¨çŠ¶æ€")
        test_disabled_config = test_enabled_config.copy()
        test_disabled_config['general']['enable_data_stream_server'] = False
        
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(test_disabled_config, f, indent=2, ensure_ascii=False)
        
        print("âœ… å·²è®¾ç½®ç¦ç”¨çŠ¶æ€")
        
        # 4. æµ‹è¯•é…ç½®åŠ è½½åŠŸèƒ½
        print("\n4. æµ‹è¯•é…ç½®åŠ è½½åŠŸèƒ½")
        from src.training_components.training_thread import TrainingThread
        
        # åˆ›å»ºä¸´æ—¶è®­ç»ƒé…ç½®
        temp_config = {
            'data_dir': 'test_data',
            'model_name': 'test_model',
            'num_epochs': 1,
            'batch_size': 2,
            'learning_rate': 0.001,
            'task_type': 'classification'
        }
        
        # åˆ›å»ºè®­ç»ƒçº¿ç¨‹å®ä¾‹
        training_thread = TrainingThread(temp_config)
        
        # æµ‹è¯•é…ç½®åŠ è½½
        ai_config = training_thread._load_ai_config()
        enable_server = ai_config.get('general', {}).get('enable_data_stream_server', True)
        
        print(f"åŠ è½½çš„é…ç½®: enable_data_stream_server = {enable_server}")
        
        if enable_server == False:
            print("âœ… ç¦ç”¨çŠ¶æ€é…ç½®åŠ è½½æ­£ç¡®")
        else:
            print("âŒ ç¦ç”¨çŠ¶æ€é…ç½®åŠ è½½é”™è¯¯")
            return False
        
        # 5. æµ‹è¯•å¯ç”¨çŠ¶æ€é…ç½®åŠ è½½
        print("\n5. æµ‹è¯•å¯ç”¨çŠ¶æ€é…ç½®åŠ è½½")
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(test_enabled_config, f, indent=2, ensure_ascii=False)
        
        ai_config = training_thread._load_ai_config()
        enable_server = ai_config.get('general', {}).get('enable_data_stream_server', True)
        
        print(f"åŠ è½½çš„é…ç½®: enable_data_stream_server = {enable_server}")
        
        if enable_server == True:
            print("âœ… å¯ç”¨çŠ¶æ€é…ç½®åŠ è½½æ­£ç¡®")
        else:
            print("âŒ å¯ç”¨çŠ¶æ€é…ç½®åŠ è½½é”™è¯¯")
            return False
        
        # 6. æµ‹è¯•é»˜è®¤å€¼å¤„ç†
        print("\n6. æµ‹è¯•é»˜è®¤å€¼å¤„ç†")
        test_default_config = test_enabled_config.copy()
        del test_default_config['general']['enable_data_stream_server']
        
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(test_default_config, f, indent=2, ensure_ascii=False)
        
        ai_config = training_thread._load_ai_config()
        enable_server = ai_config.get('general', {}).get('enable_data_stream_server', True)
        
        print(f"åŠ è½½çš„é…ç½®: enable_data_stream_server = {enable_server}")
        
        if enable_server == True:
            print("âœ… é»˜è®¤å€¼å¤„ç†æ­£ç¡®")
        else:
            print("âŒ é»˜è®¤å€¼å¤„ç†é”™è¯¯")
            return False
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®æµæœåŠ¡å™¨å¼€å…³åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        return False
    
    finally:
        # 7. æ¢å¤åŸå§‹é…ç½®æ–‡ä»¶
        print("\n7. æ¢å¤åŸå§‹é…ç½®æ–‡ä»¶")
        if os.path.exists(backup_file):
            shutil.copy2(backup_file, config_file)
            os.remove(backup_file)
            print("âœ… å·²æ¢å¤åŸå§‹é…ç½®æ–‡ä»¶")
        else:
            print("âš ï¸ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•æ¢å¤")

if __name__ == "__main__":
    success = test_data_stream_server_switch()
    sys.exit(0 if success else 1) 