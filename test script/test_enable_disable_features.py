#!/usr/bin/env python3
"""
æµ‹è¯•é«˜çº§è¶…å‚æ•°å¯ç”¨/ç¦ç”¨åŠŸèƒ½

éªŒè¯æ–°å¢çš„å¤é€‰æ¡†æ§åˆ¶åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
src_dir = os.path.join(current_dir, '..', 'src')
sys.path.insert(0, src_dir)

try:
    # å°è¯•ç›´æ¥å¯¼å…¥
    import training_components.training_validator as tv
    TrainingValidator = tv.TrainingValidator
    print("âœ… æˆåŠŸå¯¼å…¥TrainingValidator")
except ImportError as e:
    print(f"âŒ å¯¼å…¥TrainingValidatorå¤±è´¥: {e}")
    # å°è¯•æ·»åŠ æ›´å¤šè·¯å¾„
    import importlib.util
    validator_path = os.path.join(src_dir, 'training_components', 'training_validator.py')
    if os.path.exists(validator_path):
        spec = importlib.util.spec_from_file_location("training_validator", validator_path)
        tv_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(tv_module)
        TrainingValidator = tv_module.TrainingValidator
        print("âœ… é€šè¿‡æ–‡ä»¶è·¯å¾„æˆåŠŸå¯¼å…¥TrainingValidator")
    else:
        print(f"âŒ æ‰¾ä¸åˆ°éªŒè¯å™¨æ–‡ä»¶: {validator_path}")
        sys.exit(1)


def test_warmup_enable_disable():
    """æµ‹è¯•é¢„çƒ­åŠŸèƒ½å¯ç”¨/ç¦ç”¨"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•é¢„çƒ­åŠŸèƒ½å¯ç”¨/ç¦ç”¨")
    print("=" * 60)
    
    validator = TrainingValidator()
    
    # æµ‹è¯•1ï¼šå¯ç”¨é¢„çƒ­ä½†æœªè®¾ç½®å‚æ•°
    config_warmup_no_params = {
        'warmup_enabled': True,
        'warmup_steps': 0,
        'warmup_ratio': 0.0,
        'optimizer': 'Adam',
        'data_dir': 'test_data',
        'model_name': 'ResNet50',
        'num_epochs': 10,
        'batch_size': 32,
        'learning_rate': 0.001,
        'model_save_dir': 'test_models',
        'task_type': 'classification'
    }
    
    conflicts, suggestions = validator._detect_hyperparameter_conflicts(config_warmup_no_params)
    
    print(f"æµ‹è¯•1 - å¯ç”¨é¢„çƒ­ä½†æœªè®¾ç½®å‚æ•°:")
    print(f"  å‘ç°å†²çª: {len(conflicts)} ä¸ª")
    for conflict in conflicts:
        print(f"    - {conflict['type']}: {conflict['description']}")
    
    # æµ‹è¯•2ï¼šç¦ç”¨é¢„çƒ­ï¼Œä¸åº”è¯¥æ£€æµ‹åˆ°é¢„çƒ­ç›¸å…³å†²çª
    config_warmup_disabled = {
        'warmup_enabled': False,
        'warmup_steps': 1000,  # è™½ç„¶è®¾ç½®äº†å‚æ•°
        'warmup_ratio': 0.1,   # ä½†é¢„çƒ­è¢«ç¦ç”¨
        'optimizer': 'Adam',
        'data_dir': 'test_data',
        'model_name': 'ResNet50',
        'num_epochs': 10,
        'batch_size': 32,
        'learning_rate': 0.001,
        'model_save_dir': 'test_models',
        'task_type': 'classification'
    }
    
    conflicts2, suggestions2 = validator._detect_hyperparameter_conflicts(config_warmup_disabled)
    
    print(f"\næµ‹è¯•2 - ç¦ç”¨é¢„çƒ­:")
    print(f"  å‘ç°å†²çª: {len(conflicts2)} ä¸ª")
    for conflict in conflicts2:
        print(f"    - {conflict['type']}: {conflict['description']}")
    
    return len(conflicts) > 0 and len(conflicts2) == 0


def test_augmentation_enable_disable():
    """æµ‹è¯•é«˜çº§æ•°æ®å¢å¼ºå¯ç”¨/ç¦ç”¨"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•é«˜çº§æ•°æ®å¢å¼ºå¯ç”¨/ç¦ç”¨")
    print("=" * 60)
    
    validator = TrainingValidator()
    
    # æµ‹è¯•1ï¼šå¯ç”¨æ•°æ®å¢å¼ºä½†ä»»åŠ¡ç±»å‹ä¸ºæ£€æµ‹
    config_detection_augmentation = {
        'advanced_augmentation_enabled': True,
        'cutmix_prob': 0.5,
        'mixup_alpha': 0.2,
        'task_type': 'detection',
        'optimizer': 'Adam',
        'data_dir': 'test_data',
        'model_name': 'YOLOv5',
        'num_epochs': 10,
        'batch_size': 16,
        'learning_rate': 0.001,
        'model_save_dir': 'test_models'
    }
    
    conflicts, suggestions = validator._detect_hyperparameter_conflicts(config_detection_augmentation)
    
    print(f"æµ‹è¯•1 - æ£€æµ‹ä»»åŠ¡å¯ç”¨é«˜çº§æ•°æ®å¢å¼º:")
    print(f"  å‘ç°å†²çª: {len(conflicts)} ä¸ª")
    for conflict in conflicts:
        print(f"    - {conflict['type']}: {conflict['description']}")
    
    # æµ‹è¯•2ï¼šç¦ç”¨æ•°æ®å¢å¼ºï¼Œå³ä½¿ä»»åŠ¡ç±»å‹ä¸ºæ£€æµ‹ä¹Ÿä¸åº”è¯¥å†²çª
    config_detection_no_augmentation = {
        'advanced_augmentation_enabled': False,
        'cutmix_prob': 0.5,  # è™½ç„¶è®¾ç½®äº†å‚æ•°
        'mixup_alpha': 0.2,  # ä½†æ•°æ®å¢å¼ºè¢«ç¦ç”¨
        'task_type': 'detection',
        'optimizer': 'Adam',
        'data_dir': 'test_data',
        'model_name': 'YOLOv5',
        'num_epochs': 10,
        'batch_size': 16,
        'learning_rate': 0.001,
        'model_save_dir': 'test_models'
    }
    
    conflicts2, suggestions2 = validator._detect_hyperparameter_conflicts(config_detection_no_augmentation)
    
    print(f"\næµ‹è¯•2 - æ£€æµ‹ä»»åŠ¡ç¦ç”¨é«˜çº§æ•°æ®å¢å¼º:")
    print(f"  å‘ç°å†²çª: {len(conflicts2)} ä¸ª")
    for conflict in conflicts2:
        print(f"    - {conflict['type']}: {conflict['description']}")
    
    return len(conflicts) > 0 and len(conflicts2) == 0


def test_label_smoothing_enable_disable():
    """æµ‹è¯•æ ‡ç­¾å¹³æ»‘å¯ç”¨/ç¦ç”¨"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ ‡ç­¾å¹³æ»‘å¯ç”¨/ç¦ç”¨")
    print("=" * 60)
    
    validator = TrainingValidator()
    
    # æµ‹è¯•1ï¼šå¯ç”¨æ ‡ç­¾å¹³æ»‘ä½†ä»»åŠ¡ç±»å‹ä¸ºæ£€æµ‹
    config_detection_label_smoothing = {
        'label_smoothing_enabled': True,
        'label_smoothing': 0.1,
        'task_type': 'detection',
        'optimizer': 'Adam',
        'data_dir': 'test_data',
        'model_name': 'YOLOv5',
        'num_epochs': 10,
        'batch_size': 16,
        'learning_rate': 0.001,
        'model_save_dir': 'test_models'
    }
    
    conflicts, suggestions = validator._detect_hyperparameter_conflicts(config_detection_label_smoothing)
    
    print(f"æµ‹è¯•1 - æ£€æµ‹ä»»åŠ¡å¯ç”¨æ ‡ç­¾å¹³æ»‘:")
    print(f"  å‘ç°å†²çª: {len(conflicts)} ä¸ª")
    for conflict in conflicts:
        print(f"    - {conflict['type']}: {conflict['description']}")
    
    # æµ‹è¯•2ï¼šç¦ç”¨æ ‡ç­¾å¹³æ»‘ï¼Œå³ä½¿ä»»åŠ¡ç±»å‹ä¸ºæ£€æµ‹ä¹Ÿä¸åº”è¯¥å†²çª
    config_detection_no_label_smoothing = {
        'label_smoothing_enabled': False,
        'label_smoothing': 0.1,  # è™½ç„¶è®¾ç½®äº†å‚æ•°
        'task_type': 'detection',
        'optimizer': 'Adam',
        'data_dir': 'test_data',
        'model_name': 'YOLOv5',
        'num_epochs': 10,
        'batch_size': 16,
        'learning_rate': 0.001,
        'model_save_dir': 'test_models'
    }
    
    conflicts2, suggestions2 = validator._detect_hyperparameter_conflicts(config_detection_no_label_smoothing)
    
    print(f"\næµ‹è¯•2 - æ£€æµ‹ä»»åŠ¡ç¦ç”¨æ ‡ç­¾å¹³æ»‘:")
    print(f"  å‘ç°å†²çª: {len(conflicts2)} ä¸ª")
    for conflict in conflicts2:
        print(f"    - {conflict['type']}: {conflict['description']}")
    
    return len(conflicts) > 0 and len(conflicts2) == 0


def test_gradient_accumulation_enable_disable():
    """æµ‹è¯•æ¢¯åº¦ç´¯ç§¯å¯ç”¨/ç¦ç”¨"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ¢¯åº¦ç´¯ç§¯å¯ç”¨/ç¦ç”¨")
    print("=" * 60)
    
    validator = TrainingValidator()
    
    # æµ‹è¯•1ï¼šå¯ç”¨æ¢¯åº¦ç´¯ç§¯ä½†æ‰¹æ¬¡è¿‡å¤§
    config_large_batch = {
        'gradient_accumulation_enabled': True,
        'batch_size': 128,
        'gradient_accumulation_steps': 8,  # æœ‰æ•ˆæ‰¹æ¬¡ = 128 * 8 = 1024
        'optimizer': 'Adam',
        'data_dir': 'test_data',
        'model_name': 'ResNet50',
        'num_epochs': 10,
        'learning_rate': 0.001,
        'model_save_dir': 'test_models',
        'task_type': 'classification'
    }
    
    conflicts, suggestions = validator._detect_hyperparameter_conflicts(config_large_batch)
    
    print(f"æµ‹è¯•1 - å¯ç”¨æ¢¯åº¦ç´¯ç§¯ä½†æ‰¹æ¬¡è¿‡å¤§:")
    print(f"  å‘ç°å†²çª: {len(conflicts)} ä¸ª")
    for conflict in conflicts:
        print(f"    - {conflict['type']}: {conflict['description']}")
    
    # æµ‹è¯•2ï¼šç¦ç”¨æ¢¯åº¦ç´¯ç§¯ï¼Œä¸åº”è¯¥æ£€æµ‹åˆ°æ‰¹æ¬¡ç›¸å…³å†²çª
    config_no_accumulation = {
        'gradient_accumulation_enabled': False,
        'batch_size': 128,
        'gradient_accumulation_steps': 8,  # è™½ç„¶è®¾ç½®äº†å‚æ•°
        'optimizer': 'Adam',
        'data_dir': 'test_data',
        'model_name': 'ResNet50',
        'num_epochs': 10,
        'learning_rate': 0.001,
        'model_save_dir': 'test_models',
        'task_type': 'classification'
    }
    
    conflicts2, suggestions2 = validator._detect_hyperparameter_conflicts(config_no_accumulation)
    
    print(f"\næµ‹è¯•2 - ç¦ç”¨æ¢¯åº¦ç´¯ç§¯:")
    print(f"  å‘ç°å†²çª: {len(conflicts2)} ä¸ª")
    for conflict in conflicts2:
        print(f"    - {conflict['type']}: {conflict['description']}")
    
    return len(conflicts) > 0 and len(conflicts2) == 0


def test_loss_scaling_enable_disable():
    """æµ‹è¯•æŸå¤±ç¼©æ”¾å¯ç”¨/ç¦ç”¨"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•æŸå¤±ç¼©æ”¾å¯ç”¨/ç¦ç”¨")
    print("=" * 60)
    
    validator = TrainingValidator()
    
    # æµ‹è¯•1ï¼šå¯ç”¨æŸå¤±ç¼©æ”¾ä½†æœªå¯ç”¨æ··åˆç²¾åº¦
    config_loss_scaling_no_mixed_precision = {
        'loss_scaling_enabled': True,
        'loss_scale': 'static',
        'mixed_precision': False,
        'optimizer': 'Adam',
        'data_dir': 'test_data',
        'model_name': 'ResNet50',
        'num_epochs': 10,
        'batch_size': 32,
        'learning_rate': 0.001,
        'model_save_dir': 'test_models',
        'task_type': 'classification'
    }
    
    conflicts, suggestions = validator._detect_hyperparameter_conflicts(config_loss_scaling_no_mixed_precision)
    
    print(f"æµ‹è¯•1 - å¯ç”¨æŸå¤±ç¼©æ”¾ä½†æœªå¯ç”¨æ··åˆç²¾åº¦:")
    print(f"  å‘ç°å†²çª: {len(conflicts)} ä¸ª")
    for conflict in conflicts:
        print(f"    - {conflict['type']}: {conflict['description']}")
    
    # æµ‹è¯•2ï¼šç¦ç”¨æŸå¤±ç¼©æ”¾ï¼Œä¸åº”è¯¥æ£€æµ‹åˆ°æ··åˆç²¾åº¦ç›¸å…³å†²çª
    config_no_loss_scaling = {
        'loss_scaling_enabled': False,
        'loss_scale': 'static',  # è™½ç„¶è®¾ç½®äº†å‚æ•°
        'mixed_precision': False,
        'optimizer': 'Adam',
        'data_dir': 'test_data',
        'model_name': 'ResNet50',
        'num_epochs': 10,
        'batch_size': 32,
        'learning_rate': 0.001,
        'model_save_dir': 'test_models',
        'task_type': 'classification'
    }
    
    conflicts2, suggestions2 = validator._detect_hyperparameter_conflicts(config_no_loss_scaling)
    
    print(f"\næµ‹è¯•2 - ç¦ç”¨æŸå¤±ç¼©æ”¾:")
    print(f"  å‘ç°å†²çª: {len(conflicts2)} ä¸ª")
    for conflict in conflicts2:
        print(f"    - {conflict['type']}: {conflict['description']}")
    
    return len(conflicts) > 0 and len(conflicts2) == 0


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ”§ é«˜çº§è¶…å‚æ•°å¯ç”¨/ç¦ç”¨åŠŸèƒ½æµ‹è¯•")
    print("=" * 80)
    
    test_results = []
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    test_results.append(("é¢„çƒ­åŠŸèƒ½å¯ç”¨/ç¦ç”¨", test_warmup_enable_disable()))
    test_results.append(("é«˜çº§æ•°æ®å¢å¼ºå¯ç”¨/ç¦ç”¨", test_augmentation_enable_disable()))
    test_results.append(("æ ‡ç­¾å¹³æ»‘å¯ç”¨/ç¦ç”¨", test_label_smoothing_enable_disable()))
    test_results.append(("æ¢¯åº¦ç´¯ç§¯å¯ç”¨/ç¦ç”¨", test_gradient_accumulation_enable_disable()))
    test_results.append(("æŸå¤±ç¼©æ”¾å¯ç”¨/ç¦ç”¨", test_loss_scaling_enable_disable()))
    
    # æ±‡æ€»æµ‹è¯•ç»“æœ
    print("\n" + "=" * 80)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 80)
    
    passed = 0
    failed = 0
    
    for test_name, result in test_results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
        else:
            failed += 1
    
    print(f"\næ€»è®¡: {passed} ä¸ªæµ‹è¯•é€šè¿‡, {failed} ä¸ªæµ‹è¯•å¤±è´¥")
    
    if failed == 0:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†ï¼å¯ç”¨/ç¦ç”¨åŠŸèƒ½å·¥ä½œæ­£å¸¸ã€‚")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥å¯ç”¨/ç¦ç”¨åŠŸèƒ½çš„å®ç°ã€‚")
    
    return failed == 0


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 