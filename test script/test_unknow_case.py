#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•UNKNOWç±»åˆ«è¯†åˆ«é—®é¢˜
"""

import sys
import os
import re
from difflib import SequenceMatcher

def current_smart_class_matching(filename, class_names):
    """å½“å‰çš„æ™ºèƒ½ç±»åˆ«åŒ¹é…ç®—æ³•ï¼ˆæœ‰é—®é¢˜çš„ç‰ˆæœ¬ï¼‰"""
    filename_upper = filename.upper()
    
    # å¦‚æœæå–çš„ç±»åˆ«å¤ªçŸ­ï¼ˆå•å­—ç¬¦ï¼‰ï¼Œç›´æ¥æ‹’ç»
    if len(filename.strip()) <= 1:
        return None
    
    # å¦‚æœåŒ…å«æ˜æ˜¾çš„"å™ªéŸ³"å…³é”®è¯ï¼Œç›´æ¥æ‹’ç»
    noise_keywords = ['UNKNOWN', 'TEST', 'SAMPLE', 'TEMP', 'DEBUG', 'CLASS']
    if any(noise in filename_upper for noise in noise_keywords):
        return None  # âŒ è¿™é‡Œä¼šè¯¯åˆ¤ UNKNOW
    
    # å…ˆå»æ‰æ–‡ä»¶åä¸­çš„æ•°å­—å’Œæ‹¬å·ï¼Œè·å¾—æ ¸å¿ƒç±»å
    filename_core = re.sub(r'[\d\(\)\s_]+$', '', filename_upper).rstrip('_')
    
    # å¯¹æ¯ä¸ªç±»åˆ«è¿›è¡ŒåŒ¹é…åˆ†æ
    match_details = []
    
    for class_name in class_names:
        class_upper = class_name.upper()
        max_similarity = 0.0
        best_match_type = ""
        
        # 1. æ ¸å¿ƒç±»åç²¾ç¡®åŒ¹é…ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        if filename_core == class_upper:
            max_similarity = 1.0
            best_match_type = "æ ¸å¿ƒç²¾ç¡®åŒ¹é…"
        
        # 2. å®Œæ•´ç²¾ç¡®åŒ¹é…
        elif filename_upper == class_upper:
            max_similarity = 0.99
            best_match_type = "å®Œæ•´ç²¾ç¡®åŒ¹é…"
        
        # 3. æ ¸å¿ƒç±»ååŒ…å«å…³ç³»æ£€æŸ¥ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
        elif class_upper == filename_core:
            max_similarity = 0.95
            best_match_type = "æ ¸å¿ƒç±»ååŒ¹é…"
        
        # 4. ä¼ ç»ŸåŒ…å«å…³ç³»æ£€æŸ¥
        elif class_upper in filename_upper:
            precision = len(class_upper) / len(filename_upper)
            max_similarity = 0.9 + precision * 0.05  # 0.9-0.95 ä¹‹é—´
            best_match_type = f"åŒ…å«åŒ¹é…(ç²¾ç¡®åº¦:{precision:.3f})"
        
        elif filename_upper in class_upper:
            precision = len(filename_upper) / len(class_upper)
            max_similarity = 0.85 + precision * 0.05  # 0.85-0.9 ä¹‹é—´
            best_match_type = f"åå‘åŒ…å«åŒ¹é…(ç²¾ç¡®åº¦:{precision:.3f})"
        
        else:
            # 5. å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼‰
            full_similarity = SequenceMatcher(None, filename_upper, class_upper).ratio()
            max_similarity = full_similarity * 0.8  # æœ€é«˜åªèƒ½åˆ°0.8
            best_match_type = f"ç›¸ä¼¼åº¦åŒ¹é…({full_similarity:.3f})"
        
        match_details.append({
            'class_name': class_name,
            'similarity': max_similarity,
            'match_type': best_match_type,
            'class_length': len(class_upper),
            'length_diff': abs(len(class_upper) - len(filename_upper))
        })
    
    # æ’åºï¼šä¼˜å…ˆç›¸ä¼¼åº¦ï¼Œç„¶åä¼˜å…ˆè¾ƒçŸ­çš„ç±»åï¼ˆé¿å…è¿‡åº¦åŒ¹é…ï¼‰
    match_details.sort(key=lambda x: (-x['similarity'], x['class_length'], x['length_diff']))
    
    if match_details:
        best_match = match_details[0]
        if best_match['similarity'] >= 0.4:
            return best_match['class_name'], match_details
        else:
            return None, match_details
    
    return None, []


def fixed_smart_class_matching(filename, class_names):
    """ä¿®å¤åçš„æ™ºèƒ½ç±»åˆ«åŒ¹é…ç®—æ³•"""
    filename_upper = filename.upper()
    
    # å¦‚æœæå–çš„ç±»åˆ«å¤ªçŸ­ï¼ˆå•å­—ç¬¦ï¼‰ï¼Œç›´æ¥æ‹’ç»
    if len(filename.strip()) <= 1:
        return None
    
    # ä¿®å¤çš„å…³é”®ï¼šæ›´æ™ºèƒ½çš„å™ªéŸ³å…³é”®è¯è¿‡æ»¤
    # åªæœ‰å½“æ–‡ä»¶åä¸åœ¨å·²çŸ¥ç±»åˆ«åˆ—è¡¨ä¸­æ—¶ï¼Œæ‰è¿›è¡Œå™ªéŸ³è¿‡æ»¤
    class_names_upper = [name.upper() for name in class_names]
    filename_core = re.sub(r'[\d\(\)\s_]+$', '', filename_upper).rstrip('_')
    
    # å¦‚æœæ ¸å¿ƒç±»åæˆ–å®Œæ•´æ–‡ä»¶ååœ¨ç±»åˆ«åˆ—è¡¨ä¸­ï¼Œè·³è¿‡å™ªéŸ³è¿‡æ»¤
    if filename_core not in class_names_upper and filename_upper not in class_names_upper:
        # åªå¯¹æ˜ç¡®çš„å™ªéŸ³å…³é”®è¯è¿›è¡Œè¿‡æ»¤ï¼Œå¹¶ä¸”è¦æ›´ç²¾ç¡®
        noise_keywords = ['UNKNOWN', 'TEST', 'SAMPLE', 'TEMP', 'DEBUG', 'CLASS']
        # ä½¿ç”¨ç²¾ç¡®åŒ¹é…è€Œä¸æ˜¯åŒ…å«åŒ¹é…ï¼Œé¿å…è¯¯åˆ¤
        if filename_core in noise_keywords or filename_upper in noise_keywords:
            return None
        
        # é¢å¤–æ£€æŸ¥ï¼šå¦‚æœæ–‡ä»¶åå®Œå…¨ç­‰äºå™ªéŸ³å…³é”®è¯ï¼Œæ‰æ‹’ç»
        for noise in noise_keywords:
            if filename_upper == noise or filename_core == noise:
                return None
    
    # å¯¹æ¯ä¸ªç±»åˆ«è¿›è¡ŒåŒ¹é…åˆ†æ
    match_details = []
    
    for class_name in class_names:
        class_upper = class_name.upper()
        max_similarity = 0.0
        best_match_type = ""
        
        # 1. æ ¸å¿ƒç±»åç²¾ç¡®åŒ¹é…ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        if filename_core == class_upper:
            max_similarity = 1.0
            best_match_type = "æ ¸å¿ƒç²¾ç¡®åŒ¹é…"
        
        # 2. å®Œæ•´ç²¾ç¡®åŒ¹é…
        elif filename_upper == class_upper:
            max_similarity = 0.99
            best_match_type = "å®Œæ•´ç²¾ç¡®åŒ¹é…"
        
        # 3. æ ¸å¿ƒç±»ååŒ…å«å…³ç³»æ£€æŸ¥ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
        elif class_upper == filename_core:
            max_similarity = 0.95
            best_match_type = "æ ¸å¿ƒç±»ååŒ¹é…"
        
        # 4. ä¼ ç»ŸåŒ…å«å…³ç³»æ£€æŸ¥
        elif class_upper in filename_upper:
            precision = len(class_upper) / len(filename_upper)
            max_similarity = 0.9 + precision * 0.05  # 0.9-0.95 ä¹‹é—´
            best_match_type = f"åŒ…å«åŒ¹é…(ç²¾ç¡®åº¦:{precision:.3f})"
        
        elif filename_upper in class_upper:
            precision = len(filename_upper) / len(class_upper)
            max_similarity = 0.85 + precision * 0.05  # 0.85-0.9 ä¹‹é—´
            best_match_type = f"åå‘åŒ…å«åŒ¹é…(ç²¾ç¡®åº¦:{precision:.3f})"
        
        else:
            # 5. å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼‰
            full_similarity = SequenceMatcher(None, filename_upper, class_upper).ratio()
            max_similarity = full_similarity * 0.8  # æœ€é«˜åªèƒ½åˆ°0.8
            best_match_type = f"ç›¸ä¼¼åº¦åŒ¹é…({full_similarity:.3f})"
        
        match_details.append({
            'class_name': class_name,
            'similarity': max_similarity,
            'match_type': best_match_type,
            'class_length': len(class_upper),
            'length_diff': abs(len(class_upper) - len(filename_upper))
        })
    
    # æ’åºï¼šä¼˜å…ˆç›¸ä¼¼åº¦ï¼Œç„¶åä¼˜å…ˆè¾ƒçŸ­çš„ç±»åï¼ˆé¿å…è¿‡åº¦åŒ¹é…ï¼‰
    match_details.sort(key=lambda x: (-x['similarity'], x['class_length'], x['length_diff']))
    
    if match_details:
        best_match = match_details[0]
        if best_match['similarity'] >= 0.4:
            return best_match['class_name'], match_details
        else:
            return None, match_details
    
    return None, []


def test_unknow_scenarios():
    """æµ‹è¯•UNKNOWç›¸å…³åœºæ™¯"""
    print("=" * 80)
    print("UNKNOWç±»åˆ«è¯†åˆ«æµ‹è¯•")
    print("=" * 80)
    
    # æµ‹è¯•åœºæ™¯
    test_scenarios = [
        {
            "name": "åŒ…å«UNKNOWç±»åˆ«çš„åœºæ™¯",
            "class_names": ["UNKNOW", "GOOD", "BAD", "DEFECT"],
            "test_cases": [
                ("UNKNOW (1)", "UNKNOW"),          # æ ¸å¿ƒé—®é¢˜ï¼šåº”è¯¥è¯†åˆ«ä¸ºUNKNOWç±»åˆ«
                ("UNKNOW_001", "UNKNOW"),          # åº”è¯¥è¯†åˆ«ä¸ºUNKNOWç±»åˆ«
                ("UNKNOW_test", "UNKNOW"),         # åº”è¯¥è¯†åˆ«ä¸ºUNKNOWç±»åˆ«
                ("GOOD_001", "GOOD"),              # æ­£å¸¸æƒ…å†µ
                ("unknown_class", None),           # çœŸæ­£çš„å™ªéŸ³ï¼Œåº”è¯¥æ‹’ç»
                ("UNKNOWN_noise", None),           # çœŸæ­£çš„å™ªéŸ³ï¼Œåº”è¯¥æ‹’ç»
            ]
        },
        {
            "name": "ç±»ä¼¼å™ªéŸ³ä½†å®é™…æ˜¯ç±»åˆ«åçš„åœºæ™¯",
            "class_names": ["TEST", "SAMPLE", "CLASS_A", "DEBUG_MODE"],
            "test_cases": [
                ("TEST (1)", "TEST"),              # TESTæ˜¯çœŸå®ç±»åˆ«å
                ("SAMPLE_001", "SAMPLE"),          # SAMPLEæ˜¯çœŸå®ç±»åˆ«å
                ("CLASS_A_002", "CLASS_A"),        # CLASS_Aæ˜¯çœŸå®ç±»åˆ«å
                ("DEBUG_MODE_003", "DEBUG_MODE"),  # DEBUG_MODEæ˜¯çœŸå®ç±»åˆ«å
                ("temp_file", None),               # çœŸæ­£çš„å™ªéŸ³
                ("debug_log", None),               # çœŸæ­£çš„å™ªéŸ³
            ]
        }
    ]
    
    print("å¯¹æ¯”æµ‹è¯•ï¼šå½“å‰ç®—æ³• vs ä¿®å¤åç®—æ³•")
    print("=" * 80)
    
    total_current_correct = 0
    total_fixed_correct = 0
    total_cases = 0
    
    for scenario in test_scenarios:
        print(f"\nã€{scenario['name']}ã€‘")
        print(f"ç±»åˆ«åˆ—è¡¨: {scenario['class_names']}")
        print("-" * 80)
        print(f"{'æ–‡ä»¶å':<20} {'æœŸæœ›':<15} {'å½“å‰ç®—æ³•':<15} {'ä¿®å¤ç®—æ³•':<15} {'çŠ¶æ€'}")
        print("-" * 80)
        
        for filename, expected in scenario['test_cases']:
            # å½“å‰ç®—æ³•æµ‹è¯•
            current_result, _ = current_smart_class_matching(filename, scenario['class_names'])
            
            # ä¿®å¤ç®—æ³•æµ‹è¯•
            fixed_result, _ = fixed_smart_class_matching(filename, scenario['class_names'])
            
            # è¯„ä¼°ç»“æœ
            current_correct = (current_result == expected)
            fixed_correct = (fixed_result == expected)
            
            if current_correct:
                total_current_correct += 1
            if fixed_correct:
                total_fixed_correct += 1
            total_cases += 1
            
            # æ˜¾ç¤ºç»“æœ
            expected_str = expected if expected else "None"
            current_str = current_result if current_result else "None"
            fixed_str = fixed_result if fixed_result else "None"
            
            # çŠ¶æ€æ ‡è¯†
            if current_correct and fixed_correct:
                status = "âœ…âœ…"  # ä¸¤ä¸ªéƒ½å¯¹
            elif not current_correct and fixed_correct:
                status = "âŒâœ…"  # ä¿®å¤æˆåŠŸ
            elif current_correct and not fixed_correct:
                status = "âœ…âŒ"  # ä¿®å¤å¼•å…¥é—®é¢˜
            else:
                status = "âŒâŒ"  # ä¸¤ä¸ªéƒ½é”™
            
            print(f"{filename:<20} {expected_str:<15} {current_str:<15} {fixed_str:<15} {status}")
    
    print(f"\n" + "=" * 80)
    print("æ€»ç»“")
    print("=" * 80)
    print(f"å½“å‰ç®—æ³•å‡†ç¡®ç‡: {total_current_correct}/{total_cases} = {total_current_correct/total_cases*100:.1f}%")
    print(f"ä¿®å¤ç®—æ³•å‡†ç¡®ç‡: {total_fixed_correct}/{total_cases} = {total_fixed_correct/total_cases*100:.1f}%")
    print(f"æ”¹è¿›å¹…åº¦: {total_fixed_correct - total_current_correct} ä¸ªæ¡ˆä¾‹")
    
    if total_fixed_correct > total_current_correct:
        print("ğŸ‰ ä¿®å¤æˆåŠŸï¼UNKNOWç±»åˆ«è¯†åˆ«é—®é¢˜å·²è§£å†³")
    elif total_fixed_correct == total_current_correct:
        print("âš–ï¸ ä¿®å¤æ— å®³ï¼Œä¿æŒåŸæœ‰å‡†ç¡®ç‡")
    else:
        print("âš ï¸ ä¿®å¤å¯èƒ½å¼•å…¥æ–°é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒæ•´")


if __name__ == "__main__":
    test_unknow_scenarios() 