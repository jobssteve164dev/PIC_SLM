"""
å‚æ•°è°ƒæ•´å¯è§£é‡Šæ€§å¼•æ“

ä¸ºæ™ºèƒ½è®­ç»ƒç³»ç»Ÿçš„å‚æ•°è°ƒæ•´æä¾›è¯¦ç»†çš„å¯è§£é‡Šæ€§åˆ†æ
ä¸»è¦åŠŸèƒ½ï¼š
- ä¸ºæ¯ä¸ªå‚æ•°è°ƒæ•´æä¾›è¯¦ç»†çš„ç†ç”±è¯´æ˜
- åŸºäºè®­ç»ƒæŒ‡æ ‡å’Œé…ç½®çŠ¶æ€ç”Ÿæˆè§£é‡Š
- æä¾›å‚æ•°è°ƒæ•´çš„é¢„æœŸæ•ˆæœå’Œé£é™©è¯„ä¼°
- ç”Ÿæˆç»“æ„åŒ–çš„å¯è§£é‡Šæ€§æŠ¥å‘Š
"""

import json
import time
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum


class ParameterType(Enum):
    """å‚æ•°ç±»å‹æšä¸¾"""
    LEARNING_RATE = "learning_rate"
    BATCH_SIZE = "batch_size"
    OPTIMIZER = "optimizer"
    REGULARIZATION = "regularization"
    DATA_AUGMENTATION = "data_augmentation"
    SCHEDULER = "scheduler"
    LOSS_FUNCTION = "loss_function"
    MODEL_ARCHITECTURE = "model_architecture"


class AdjustmentReason(Enum):
    """è°ƒæ•´åŸå› æšä¸¾"""
    CONVERGENCE_ISSUE = "convergence_issue"
    OVERFITTING = "overfitting"
    UNDERFITTING = "underfitting"
    TRAINING_STABILITY = "training_stability"
    PERFORMANCE_OPTIMIZATION = "performance_optimization"
    RESOURCE_OPTIMIZATION = "resource_optimization"
    CONFLICT_RESOLUTION = "conflict_resolution"


@dataclass
class ParameterExplanation:
    """å‚æ•°è°ƒæ•´è§£é‡Šæ•°æ®ç»“æ„"""
    parameter_name: str
    parameter_type: ParameterType
    original_value: Any
    new_value: Any
    adjustment_reason: AdjustmentReason
    detailed_reason: str
    expected_impact: str
    risk_assessment: str
    confidence_level: float  # 0.0 - 1.0
    supporting_evidence: List[str]
    alternative_options: List[Dict[str, Any]]
    implementation_notes: str


class ParameterExplanationEngine:
    """å‚æ•°è°ƒæ•´å¯è§£é‡Šæ€§å¼•æ“"""
    
    def __init__(self):
        self.explanation_templates = self._load_explanation_templates()
        self.parameter_constraints = self._load_parameter_constraints()
        self.performance_benchmarks = self._load_performance_benchmarks()
    
    def generate_parameter_explanations(self, 
                                      original_config: Dict[str, Any],
                                      adjusted_config: Dict[str, Any],
                                      training_metrics: Dict[str, Any],
                                      llm_analysis: Dict[str, Any]) -> List[ParameterExplanation]:
        """ç”Ÿæˆå‚æ•°è°ƒæ•´çš„å¯è§£é‡Šæ€§åˆ†æ"""
        try:
            explanations = []
            
            # è¯†åˆ«æ‰€æœ‰å˜æ›´çš„å‚æ•°
            changed_parameters = self._identify_changed_parameters(original_config, adjusted_config)
            
            for param_name, (old_value, new_value) in changed_parameters.items():
                explanation = self._generate_single_parameter_explanation(
                    param_name, old_value, new_value, 
                    original_config, training_metrics, llm_analysis
                )
                if explanation:
                    explanations.append(explanation)
            
            # æŒ‰ä¼˜å…ˆçº§æ’åº
            explanations.sort(key=lambda x: x.confidence_level, reverse=True)
            
            return explanations
            
        except Exception as e:
            print(f"ç”Ÿæˆå‚æ•°è§£é‡Šå¤±è´¥: {str(e)}")
            return []
    
    def _identify_changed_parameters(self, 
                                   original_config: Dict[str, Any], 
                                   adjusted_config: Dict[str, Any]) -> Dict[str, Tuple[Any, Any]]:
        """è¯†åˆ«å˜æ›´çš„å‚æ•°"""
        changed_params = {}
        
        for key in adjusted_config:
            if key in original_config:
                old_value = original_config[key]
                new_value = adjusted_config[key]
                if old_value != new_value:
                    changed_params[key] = (old_value, new_value)
            else:
                # æ–°å¢çš„å‚æ•°
                changed_params[key] = (None, adjusted_config[key])
        
        return changed_params
    
    def _generate_single_parameter_explanation(self,
                                             param_name: str,
                                             old_value: Any,
                                             new_value: Any,
                                             original_config: Dict[str, Any],
                                             training_metrics: Dict[str, Any],
                                             llm_analysis: Dict[str, Any]) -> Optional[ParameterExplanation]:
        """ä¸ºå•ä¸ªå‚æ•°ç”Ÿæˆè§£é‡Š"""
        try:
            # ç¡®å®šå‚æ•°ç±»å‹
            param_type = self._determine_parameter_type(param_name)
            
            # ç¡®å®šè°ƒæ•´åŸå› 
            adjustment_reason = self._determine_adjustment_reason(
                param_name, old_value, new_value, training_metrics, llm_analysis
            )
            
            # ç”Ÿæˆè¯¦ç»†è§£é‡Š
            detailed_reason = self._generate_detailed_reason(
                param_name, param_type, old_value, new_value, 
                adjustment_reason, training_metrics, original_config
            )
            
            # è¯„ä¼°é¢„æœŸå½±å“
            expected_impact = self._assess_expected_impact(
                param_name, param_type, old_value, new_value, training_metrics
            )
            
            # é£é™©è¯„ä¼°
            risk_assessment = self._assess_risks(
                param_name, param_type, old_value, new_value, original_config
            )
            
            # è®¡ç®—ç½®ä¿¡åº¦
            confidence_level = self._calculate_confidence(
                param_name, param_type, adjustment_reason, training_metrics
            )
            
            # æ”¶é›†æ”¯æŒè¯æ®
            supporting_evidence = self._collect_supporting_evidence(
                param_name, training_metrics, llm_analysis
            )
            
            # ç”Ÿæˆæ›¿ä»£é€‰é¡¹
            alternative_options = self._generate_alternative_options(
                param_name, param_type, old_value, new_value
            )
            
            # å®ç°è¯´æ˜
            implementation_notes = self._generate_implementation_notes(
                param_name, param_type, new_value
            )
            
            return ParameterExplanation(
                parameter_name=param_name,
                parameter_type=param_type,
                original_value=old_value,
                new_value=new_value,
                adjustment_reason=adjustment_reason,
                detailed_reason=detailed_reason,
                expected_impact=expected_impact,
                risk_assessment=risk_assessment,
                confidence_level=confidence_level,
                supporting_evidence=supporting_evidence,
                alternative_options=alternative_options,
                implementation_notes=implementation_notes
            )
            
        except Exception as e:
            print(f"ç”Ÿæˆå‚æ•° {param_name} çš„è§£é‡Šå¤±è´¥: {str(e)}")
            return None
    
    def _determine_parameter_type(self, param_name: str) -> ParameterType:
        """ç¡®å®šå‚æ•°ç±»å‹"""
        type_mapping = {
            'learning_rate': ParameterType.LEARNING_RATE,
            'batch_size': ParameterType.BATCH_SIZE,
            'optimizer': ParameterType.OPTIMIZER,
            'weight_decay': ParameterType.REGULARIZATION,
            'dropout_rate': ParameterType.REGULARIZATION,
            'advanced_augmentation_enabled': ParameterType.DATA_AUGMENTATION,
            'cutmix_prob': ParameterType.DATA_AUGMENTATION,
            'mixup_alpha': ParameterType.DATA_AUGMENTATION,
            'lr_scheduler': ParameterType.SCHEDULER,
            'gradient_accumulation_steps': ParameterType.REGULARIZATION,
            'class_weights': ParameterType.LOSS_FUNCTION,
        }
        
        return type_mapping.get(param_name, ParameterType.REGULARIZATION)
    
    def _determine_adjustment_reason(self,
                                   param_name: str,
                                   old_value: Any,
                                   new_value: Any,
                                   training_metrics: Dict[str, Any],
                                   llm_analysis: Dict[str, Any]) -> AdjustmentReason:
        """ç¡®å®šè°ƒæ•´åŸå› """
        # åŸºäºè®­ç»ƒæŒ‡æ ‡åˆ¤æ–­
        train_loss = training_metrics.get('loss', 0)
        accuracy = training_metrics.get('accuracy', 0)
        epoch = training_metrics.get('epoch', 0)
        
        # å­¦ä¹ ç‡è°ƒæ•´
        if param_name == 'learning_rate':
            if isinstance(old_value, (int, float)) and isinstance(new_value, (int, float)):
                if new_value < old_value:
                    if accuracy < 0.2:  # å‡†ç¡®ç‡æä½
                        return AdjustmentReason.CONVERGENCE_ISSUE
                    elif train_loss > 1.5:  # æŸå¤±è¿‡é«˜
                        return AdjustmentReason.TRAINING_STABILITY
                    else:
                        return AdjustmentReason.PERFORMANCE_OPTIMIZATION
        
        # æ•°æ®å¢å¼ºè°ƒæ•´
        if param_name in ['advanced_augmentation_enabled', 'cutmix_prob', 'mixup_alpha']:
            if old_value and not new_value:
                return AdjustmentReason.CONFLICT_RESOLUTION
            elif not old_value and new_value:
                return AdjustmentReason.PERFORMANCE_OPTIMIZATION
        
        # æ¢¯åº¦ç´¯ç§¯è°ƒæ•´
        if param_name == 'gradient_accumulation_steps':
            if isinstance(old_value, (int, float)) and isinstance(new_value, (int, float)):
                if new_value < old_value:
                    return AdjustmentReason.RESOURCE_OPTIMIZATION
        
        # ç±»åˆ«æƒé‡è°ƒæ•´
        if param_name == 'class_weights':
            return AdjustmentReason.PERFORMANCE_OPTIMIZATION
        
        # é»˜è®¤æƒ…å†µ
        return AdjustmentReason.PERFORMANCE_OPTIMIZATION
    
    def _generate_detailed_reason(self,
                                param_name: str,
                                param_type: ParameterType,
                                old_value: Any,
                                new_value: Any,
                                adjustment_reason: AdjustmentReason,
                                training_metrics: Dict[str, Any],
                                original_config: Dict[str, Any]) -> str:
        """ç”Ÿæˆè¯¦ç»†çš„è°ƒæ•´ç†ç”±"""
        
        # è·å–è®­ç»ƒçŠ¶æ€ä¿¡æ¯
        accuracy = training_metrics.get('accuracy', 0)
        loss = training_metrics.get('loss', 0)
        epoch = training_metrics.get('epoch', 0)
        
        # åŸºäºå‚æ•°ç±»å‹å’Œè°ƒæ•´åŸå› ç”Ÿæˆè§£é‡Š
        if param_name == 'learning_rate':
            if adjustment_reason == AdjustmentReason.CONVERGENCE_ISSUE:
                return f"""å­¦ä¹ ç‡ä» {old_value} é™ä½åˆ° {new_value}ï¼Œä¸»è¦åŸå› æ˜¯ï¼š
1. å½“å‰éªŒè¯å‡†ç¡®ç‡ä»…ä¸º {accuracy:.1%}ï¼Œè¿œä½äºé¢„æœŸæ°´å¹³
2. è®­ç»ƒæŸå¤± {loss:.3f} è¡¨æ˜æ¨¡å‹æ”¶æ•›å›°éš¾
3. é™ä½å­¦ä¹ ç‡æœ‰åŠ©äºæ¨¡å‹æ›´ç¨³å®šåœ°æ”¶æ•›åˆ°æ›´å¥½çš„å±€éƒ¨æœ€ä¼˜è§£
4. å¯¹äºé¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒï¼Œè¾ƒå°çš„å­¦ä¹ ç‡é€šå¸¸èƒ½è·å¾—æ›´å¥½çš„æ³›åŒ–æ€§èƒ½"""
            
            elif adjustment_reason == AdjustmentReason.TRAINING_STABILITY:
                return f"""å­¦ä¹ ç‡ä» {old_value} é™ä½åˆ° {new_value}ï¼Œä¸»è¦åŸå› æ˜¯ï¼š
1. å½“å‰è®­ç»ƒæŸå¤± {loss:.3f} è¾ƒé«˜ï¼Œå¯èƒ½å­˜åœ¨è®­ç»ƒä¸ç¨³å®šé—®é¢˜
2. è¾ƒå°çš„å­¦ä¹ ç‡èƒ½å‡å°‘æ¢¯åº¦éœ‡è¡ï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§
3. æœ‰åŠ©äºæ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¿æŒç¨³å®šçš„æ”¶æ•›è½¨è¿¹"""
        
        elif param_name == 'advanced_augmentation_enabled':
            if adjustment_reason == AdjustmentReason.CONFLICT_RESOLUTION:
                return f"""æ•°æ®å¢å¼ºä»å¯ç”¨æ”¹ä¸ºç¦ç”¨ï¼Œä¸»è¦åŸå› æ˜¯ï¼š
1. æ£€æµ‹åˆ°CutMixå’ŒMixUpåŒæ—¶å¯ç”¨å¯èƒ½å¯¼è‡´è¿‡åº¦å¢å¼º
2. å½“å‰å‡†ç¡®ç‡ {accuracy:.1%} æä½ï¼Œå¤æ‚çš„æ•°æ®å¢å¼ºå¯èƒ½å¹²æ‰°å­¦ä¹ è¿‡ç¨‹
3. åœ¨è®­ç»ƒåˆæœŸï¼Œç®€å•çš„æ•°æ®å¢å¼ºç­–ç•¥é€šå¸¸æ›´æœ‰æ•ˆ
4. é¿å…è¿‡åº¦å¢å¼ºå¯¼è‡´çš„è®­ç»ƒä¸ç¨³å®šé—®é¢˜"""
        
        elif param_name == 'gradient_accumulation_steps':
            if adjustment_reason == AdjustmentReason.RESOURCE_OPTIMIZATION:
                batch_size = original_config.get('batch_size', 32)
                effective_batch_size_old = batch_size * old_value
                effective_batch_size_new = batch_size * new_value
                return f"""æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ä» {old_value} å‡å°‘åˆ° {new_value}ï¼Œä¸»è¦åŸå› æ˜¯ï¼š
1. åŸå§‹æœ‰æ•ˆæ‰¹æ¬¡å¤§å° {effective_batch_size_old} å¯èƒ½è¿‡å¤§ï¼Œå½±å“è®­ç»ƒç¨³å®šæ€§
2. å½“å‰å‡†ç¡®ç‡ {accuracy:.1%} è¡¨æ˜éœ€è¦æ›´é¢‘ç¹çš„å‚æ•°æ›´æ–°
3. è¾ƒå°çš„æœ‰æ•ˆæ‰¹æ¬¡å¤§å°æœ‰åŠ©äºæ¨¡å‹æ›´å¿«åœ°é€‚åº”æ•°æ®åˆ†å¸ƒ
4. å‡å°‘å†…å­˜ä½¿ç”¨ï¼Œæé«˜è®­ç»ƒæ•ˆç‡"""
        
        elif param_name == 'class_weights':
            if adjustment_reason == AdjustmentReason.PERFORMANCE_OPTIMIZATION:
                return f"""ç±»åˆ«æƒé‡ä»æ‰‹åŠ¨è®¾ç½®æ”¹ä¸ºè‡ªåŠ¨è®¡ç®—ï¼Œä¸»è¦åŸå› æ˜¯ï¼š
1. æ‰‹åŠ¨è®¾ç½®çš„æƒé‡å‡ä¸º1.0ï¼Œä¸å¯ç”¨ç±»åˆ«æƒé‡åŠŸèƒ½å†²çª
2. è‡ªåŠ¨è®¡ç®—èƒ½æ ¹æ®æ•°æ®é›†ä¸­å„ç±»åˆ«çš„å®é™…åˆ†å¸ƒè°ƒæ•´æƒé‡
3. æœ‰åŠ©äºè§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œæé«˜æ¨¡å‹åœ¨å°‘æ•°ç±»åˆ«ä¸Šçš„æ€§èƒ½
4. åŸºäºæ•°æ®é©±åŠ¨çš„æƒé‡è®¾ç½®æ›´ç§‘å­¦åˆç†"""
        
        elif param_name == 'weight_decay':
            if isinstance(old_value, (int, float)) and isinstance(new_value, (int, float)):
                return f"""æƒé‡è¡°å‡ä» {old_value} è°ƒæ•´åˆ° {new_value}ï¼Œä¸»è¦åŸå› æ˜¯ï¼š
1. ä¸å­¦ä¹ ç‡è°ƒæ•´ä¿æŒä¸€è‡´çš„ä¼˜åŒ–ç­–ç•¥
2. é€‚å½“çš„æƒé‡è¡°å‡æœ‰åŠ©äºé˜²æ­¢è¿‡æ‹Ÿåˆ
3. åœ¨é™ä½å­¦ä¹ ç‡çš„åŒæ—¶è°ƒæ•´æ­£åˆ™åŒ–å¼ºåº¦ï¼Œä¿æŒè®­ç»ƒå¹³è¡¡"""
        
        # é»˜è®¤è§£é‡Š
        return f"""å‚æ•° {param_name} ä» {old_value} è°ƒæ•´ä¸º {new_value}ï¼Œä¸»è¦åŸå› æ˜¯ï¼š
1. åŸºäºå½“å‰è®­ç»ƒæŒ‡æ ‡ï¼ˆå‡†ç¡®ç‡: {accuracy:.1%}, æŸå¤±: {loss:.3f}ï¼‰çš„ä¼˜åŒ–
2. æ—¨åœ¨æ”¹å–„æ¨¡å‹çš„è®­ç»ƒæ•ˆæœå’Œæ”¶æ•›æ€§èƒ½
3. æ ¹æ®æ·±åº¦å­¦ä¹ æœ€ä½³å®è·µè¿›è¡Œçš„å‚æ•°è°ƒä¼˜"""
    
    def _assess_expected_impact(self,
                              param_name: str,
                              param_type: ParameterType,
                              old_value: Any,
                              new_value: Any,
                              training_metrics: Dict[str, Any]) -> str:
        """è¯„ä¼°é¢„æœŸå½±å“"""
        
        if param_name == 'learning_rate':
            if isinstance(old_value, (int, float)) and isinstance(new_value, (int, float)):
                if new_value < old_value:
                    return """é¢„æœŸå½±å“ï¼š
1. è®­ç»ƒæ”¶æ•›æ›´ç¨³å®šï¼Œå‡å°‘æŸå¤±éœ‡è¡
2. å¯èƒ½éœ€è¦æ›´å¤šepochæ‰èƒ½æ”¶æ•›ï¼Œä½†æœ€ç»ˆæ€§èƒ½å¯èƒ½æ›´å¥½
3. é™ä½è¿‡æ‹Ÿåˆé£é™©ï¼Œæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›
4. è®­ç»ƒæ—¶é—´å¯èƒ½ç•¥å¾®å¢åŠ """
        
        elif param_name == 'advanced_augmentation_enabled':
            if old_value and not new_value:
                return """é¢„æœŸå½±å“ï¼š
1. è®­ç»ƒè¿‡ç¨‹æ›´ç¨³å®šï¼Œå‡å°‘æ•°æ®å¢å¼ºå¸¦æ¥çš„å™ªå£°
2. æ¨¡å‹èƒ½æ›´ä¸“æ³¨äºå­¦ä¹ åŸºæœ¬çš„ç‰¹å¾è¡¨ç¤º
3. è®­ç»ƒé€Ÿåº¦å¯èƒ½ç•¥æœ‰æå‡
4. åœ¨æ•°æ®é‡å……è¶³çš„æƒ…å†µä¸‹ï¼Œæ€§èƒ½å½±å“è¾ƒå°"""
        
        elif param_name == 'gradient_accumulation_steps':
            if isinstance(old_value, (int, float)) and isinstance(new_value, (int, float)):
                if new_value < old_value:
                    return """é¢„æœŸå½±å“ï¼š
1. å‚æ•°æ›´æ–°æ›´é¢‘ç¹ï¼Œæ¨¡å‹é€‚åº”æ›´å¿«
2. è®­ç»ƒç¨³å®šæ€§å¯èƒ½ç•¥æœ‰ä¸‹é™ï¼Œä½†æ”¶æ•›é€Ÿåº¦æå‡
3. å†…å­˜ä½¿ç”¨å‡å°‘ï¼Œè®­ç»ƒæ•ˆç‡æé«˜
4. åœ¨æ•°æ®é‡è¾ƒå°æ—¶æ•ˆæœæ›´æ˜æ˜¾"""
        
        elif param_name == 'class_weights':
            return """é¢„æœŸå½±å“ï¼š
1. è‡ªåŠ¨å¹³è¡¡å„ç±»åˆ«çš„å­¦ä¹ æƒé‡
2. æé«˜æ¨¡å‹åœ¨å°‘æ•°ç±»åˆ«ä¸Šçš„è¯†åˆ«èƒ½åŠ›
3. æ•´ä½“å‡†ç¡®ç‡å¯èƒ½æå‡ï¼Œç‰¹åˆ«æ˜¯ç±»åˆ«ä¸å¹³è¡¡çš„æƒ…å†µä¸‹
4. è®­ç»ƒè¿‡ç¨‹æ›´åŠ å…¬å¹³ï¼Œé¿å…åå‘å¤šæ•°ç±»åˆ«"""
        
        return "é¢„æœŸå°†æ”¹å–„æ¨¡å‹çš„è®­ç»ƒæ•ˆæœå’Œæ€§èƒ½è¡¨ç°"
    
    def _assess_risks(self,
                     param_name: str,
                     param_type: ParameterType,
                     old_value: Any,
                     new_value: Any,
                     original_config: Dict[str, Any]) -> str:
        """è¯„ä¼°è°ƒæ•´é£é™©"""
        
        risks = []
        
        if param_name == 'learning_rate':
            if isinstance(old_value, (int, float)) and isinstance(new_value, (int, float)):
                if new_value < old_value:
                    risks.append("å­¦ä¹ ç‡è¿‡ä½å¯èƒ½å¯¼è‡´è®­ç»ƒè¿‡æ…¢")
                    risks.append("éœ€è¦æ›´å¤šepochæ‰èƒ½æ”¶æ•›")
        
        elif param_name == 'advanced_augmentation_enabled':
            if old_value and not new_value:
                risks.append("æ•°æ®å¢å¼ºç¦ç”¨å¯èƒ½é™ä½æ¨¡å‹æ³›åŒ–èƒ½åŠ›")
                risks.append("åœ¨æ•°æ®é‡ä¸è¶³æ—¶å¯èƒ½å½±å“æ€§èƒ½")
        
        elif param_name == 'gradient_accumulation_steps':
            if isinstance(old_value, (int, float)) and isinstance(new_value, (int, float)):
                if new_value < old_value:
                    risks.append("æœ‰æ•ˆæ‰¹æ¬¡å¤§å°å‡å°å¯èƒ½å½±å“è®­ç»ƒç¨³å®šæ€§")
                    risks.append("æ¢¯åº¦ä¼°è®¡çš„æ–¹å·®å¯èƒ½å¢åŠ ")
        
        if not risks:
            risks.append("è°ƒæ•´é£é™©è¾ƒä½ï¼Œå±äºå¸¸è§„ä¼˜åŒ–ç­–ç•¥")
        
        return "é£é™©è¯„ä¼°ï¼š\n" + "\n".join(f"- {risk}" for risk in risks)
    
    def _calculate_confidence(self,
                            param_name: str,
                            param_type: ParameterType,
                            adjustment_reason: AdjustmentReason,
                            training_metrics: Dict[str, Any]) -> float:
        """è®¡ç®—è°ƒæ•´çš„ç½®ä¿¡åº¦"""
        base_confidence = 0.7
        
        # åŸºäºè®­ç»ƒæŒ‡æ ‡è°ƒæ•´ç½®ä¿¡åº¦
        accuracy = training_metrics.get('accuracy', 0)
        loss = training_metrics.get('loss', 0)
        
        # å¦‚æœæŒ‡æ ‡å¼‚å¸¸ï¼Œæé«˜ç½®ä¿¡åº¦
        if accuracy < 0.2 or loss > 1.5:
            base_confidence += 0.2
        
        # åŸºäºè°ƒæ•´åŸå› è°ƒæ•´ç½®ä¿¡åº¦
        if adjustment_reason == AdjustmentReason.CONVERGENCE_ISSUE:
            base_confidence += 0.1
        elif adjustment_reason == AdjustmentReason.CONFLICT_RESOLUTION:
            base_confidence += 0.15
        
        # åŸºäºå‚æ•°ç±»å‹è°ƒæ•´ç½®ä¿¡åº¦
        if param_type in [ParameterType.LEARNING_RATE, ParameterType.REGULARIZATION]:
            base_confidence += 0.05
        
        return min(1.0, base_confidence)
    
    def _collect_supporting_evidence(self,
                                   param_name: str,
                                   training_metrics: Dict[str, Any],
                                   llm_analysis: Dict[str, Any]) -> List[str]:
        """æ”¶é›†æ”¯æŒè¯æ®"""
        evidence = []
        
        # ä»è®­ç»ƒæŒ‡æ ‡æ”¶é›†è¯æ®
        accuracy = training_metrics.get('accuracy', 0)
        loss = training_metrics.get('loss', 0)
        epoch = training_metrics.get('epoch', 0)
        
        if accuracy < 0.2:
            evidence.append(f"éªŒè¯å‡†ç¡®ç‡ {accuracy:.1%} è¿œä½äºé¢„æœŸ")
        if loss > 1.5:
            evidence.append(f"è®­ç»ƒæŸå¤± {loss:.3f} è¿‡é«˜")
        if epoch > 0:
            evidence.append(f"å½“å‰è®­ç»ƒè½®æ•° {epoch}")
        
        # ä»LLMåˆ†ææ”¶é›†è¯æ®
        if isinstance(llm_analysis, dict):
            if 'analysis' in llm_analysis:
                evidence.append("LLMåˆ†æç¡®è®¤éœ€è¦å‚æ•°è°ƒæ•´")
            if 'suggestions' in llm_analysis:
                evidence.append("LLMæä¾›äº†å…·ä½“çš„ä¼˜åŒ–å»ºè®®")
        
        return evidence
    
    def _generate_alternative_options(self,
                                    param_name: str,
                                    param_type: ParameterType,
                                    old_value: Any,
                                    new_value: Any) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ›¿ä»£é€‰é¡¹"""
        alternatives = []
        
        if param_name == 'learning_rate':
            if isinstance(new_value, (int, float)):
                alternatives.extend([
                    {
                        'value': new_value * 0.5,
                        'description': 'æ›´ä¿å®ˆçš„å­¦ä¹ ç‡è°ƒæ•´',
                        'pros': 'æ›´ç¨³å®šçš„è®­ç»ƒ',
                        'cons': 'æ”¶æ•›å¯èƒ½æ›´æ…¢'
                    },
                    {
                        'value': new_value * 2,
                        'description': 'æ›´æ¿€è¿›çš„å­¦ä¹ ç‡è°ƒæ•´',
                        'pros': 'å¯èƒ½æ›´å¿«æ”¶æ•›',
                        'cons': 'è®­ç»ƒå¯èƒ½ä¸ç¨³å®š'
                    }
                ])
        
        elif param_name == 'advanced_augmentation_enabled':
            alternatives.extend([
                {
                    'value': True,
                    'description': 'ä¿æŒæ•°æ®å¢å¼ºï¼Œä½†åªå¯ç”¨ä¸€ç§',
                    'pros': 'ä¿æŒæ•°æ®å¢å¼ºçš„å¥½å¤„',
                    'cons': 'éœ€è¦è¿›ä¸€æ­¥é…ç½®'
                }
            ])
        
        return alternatives
    
    def _generate_implementation_notes(self,
                                     param_name: str,
                                     param_type: ParameterType,
                                     new_value: Any) -> str:
        """ç”Ÿæˆå®ç°è¯´æ˜"""
        if param_name == 'learning_rate':
            return "å­¦ä¹ ç‡è°ƒæ•´å°†ç«‹å³ç”Ÿæ•ˆï¼Œå»ºè®®ç›‘æ§å‰å‡ ä¸ªepochçš„æ”¶æ•›æƒ…å†µ"
        elif param_name == 'advanced_augmentation_enabled':
            return "æ•°æ®å¢å¼ºè®¾ç½®å°†åœ¨ä¸‹æ¬¡è®­ç»ƒå¼€å§‹æ—¶ç”Ÿæ•ˆ"
        elif param_name == 'gradient_accumulation_steps':
            return "æ¢¯åº¦ç´¯ç§¯æ­¥æ•°è°ƒæ•´å°†å½±å“å†…å­˜ä½¿ç”¨å’Œè®­ç»ƒé€Ÿåº¦"
        elif param_name == 'class_weights':
            return "ç±»åˆ«æƒé‡å°†æ ¹æ®æ•°æ®é›†è‡ªåŠ¨è®¡ç®—ï¼Œæ— éœ€æ‰‹åŠ¨è®¾ç½®"
        
        return "å‚æ•°è°ƒæ•´å°†åœ¨ä¸‹æ¬¡è®­ç»ƒè¿­ä»£ä¸­ç”Ÿæ•ˆ"
    
    def _load_explanation_templates(self) -> Dict[str, Any]:
        """åŠ è½½è§£é‡Šæ¨¡æ¿"""
        return {
            'learning_rate': {
                'convergence_issue': "å­¦ä¹ ç‡è¿‡é«˜å¯¼è‡´æ”¶æ•›å›°éš¾",
                'stability_issue': "å­¦ä¹ ç‡è¿‡é«˜å¯¼è‡´è®­ç»ƒä¸ç¨³å®š",
                'optimization': "å­¦ä¹ ç‡ä¼˜åŒ–ä»¥æå‡æ€§èƒ½"
            },
            'data_augmentation': {
                'conflict_resolution': "è§£å†³æ•°æ®å¢å¼ºå†²çª",
                'optimization': "ä¼˜åŒ–æ•°æ®å¢å¼ºç­–ç•¥"
            }
        }
    
    def _load_parameter_constraints(self) -> Dict[str, Dict[str, Any]]:
        """åŠ è½½å‚æ•°çº¦æŸ"""
        return {
            'learning_rate': {'min': 1e-6, 'max': 0.1, 'recommended': [1e-4, 1e-3]},
            'batch_size': {'min': 1, 'max': 256, 'recommended': [16, 32, 64]},
            'weight_decay': {'min': 0, 'max': 0.01, 'recommended': [1e-4, 1e-3]}
        }
    
    def _load_performance_benchmarks(self) -> Dict[str, Dict[str, float]]:
        """åŠ è½½æ€§èƒ½åŸºå‡†"""
        return {
            'accuracy': {'excellent': 0.9, 'good': 0.8, 'fair': 0.6, 'poor': 0.4},
            'loss': {'excellent': 0.1, 'good': 0.3, 'fair': 0.6, 'poor': 1.0}
        }
    
    def format_explanations_for_report(self, explanations: List[ParameterExplanation]) -> str:
        """æ ¼å¼åŒ–è§£é‡Šç”¨äºæŠ¥å‘Š"""
        if not explanations:
            return "æ— å‚æ•°è°ƒæ•´è§£é‡Š"
        
        content = []
        content.append("## ğŸ” å‚æ•°è°ƒæ•´è¯¦ç»†è§£é‡Š")
        content.append("")
        
        for i, explanation in enumerate(explanations, 1):
            content.append(f"### {i}. {explanation.parameter_name}")
            content.append("")
            
            # åŸºæœ¬ä¿¡æ¯
            content.append(f"**å‚æ•°ç±»å‹**: {explanation.parameter_type.value}")
            content.append(f"**è°ƒæ•´åŸå› **: {explanation.adjustment_reason.value}")
            content.append(f"**ç½®ä¿¡åº¦**: {explanation.confidence_level:.1%}")
            content.append("")
            
            # è¯¦ç»†ç†ç”±
            content.append("**è°ƒæ•´ç†ç”±**:")
            content.append(explanation.detailed_reason)
            content.append("")
            
            # é¢„æœŸå½±å“
            content.append("**é¢„æœŸå½±å“**:")
            content.append(explanation.expected_impact)
            content.append("")
            
            # é£é™©è¯„ä¼°
            content.append("**é£é™©è¯„ä¼°**:")
            content.append(explanation.risk_assessment)
            content.append("")
            
            # æ”¯æŒè¯æ®
            if explanation.supporting_evidence:
                content.append("**æ”¯æŒè¯æ®**:")
                for evidence in explanation.supporting_evidence:
                    content.append(f"- {evidence}")
                content.append("")
            
            # æ›¿ä»£é€‰é¡¹
            if explanation.alternative_options:
                content.append("**æ›¿ä»£é€‰é¡¹**:")
                for alt in explanation.alternative_options:
                    content.append(f"- **{alt['value']}**: {alt['description']}")
                    content.append(f"  - ä¼˜ç‚¹: {alt['pros']}")
                    content.append(f"  - ç¼ºç‚¹: {alt['cons']}")
                content.append("")
            
            # å®ç°è¯´æ˜
            content.append("**å®ç°è¯´æ˜**:")
            content.append(explanation.implementation_notes)
            content.append("")
        
        return "\n".join(content)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºè§£é‡Šå¼•æ“
    engine = ParameterExplanationEngine()
    
    # æµ‹è¯•æ•°æ®
    original_config = {
        'learning_rate': 0.001,
        'advanced_augmentation_enabled': True,
        'gradient_accumulation_steps': 4,
        'class_weights': {'åˆ’ç—•': 1.0, 'æ±¡ç‚¹': 1.0}
    }
    
    adjusted_config = {
        'learning_rate': 0.0001,
        'advanced_augmentation_enabled': False,
        'gradient_accumulation_steps': 1,
        'class_weights': 'auto'
    }
    
    training_metrics = {
        'accuracy': 0.167,
        'loss': 1.84,
        'epoch': 2
    }
    
    llm_analysis = {
        'reason': 'LLMæ™ºèƒ½åˆ†æå»ºè®®',
        'analysis': 'å½“å‰é…ç½®å­˜åœ¨å¤šä¸ªé—®é¢˜éœ€è¦è°ƒæ•´'
    }
    
    # ç”Ÿæˆè§£é‡Š
    explanations = engine.generate_parameter_explanations(
        original_config, adjusted_config, training_metrics, llm_analysis
    )
    
    # æ ¼å¼åŒ–è¾“å‡º
    report_content = engine.format_explanations_for_report(explanations)
    print(report_content)

