from PyQt5.QtWidgets import (QWidget, QVBoxLayout, QHBoxLayout, QPushButton, QLabel, 
                           QSplitter, QGroupBox, QTabWidget, QTextEdit, QLineEdit,
                           QScrollArea, QFrame, QSizePolicy, QStackedWidget, QComboBox,
                           QProgressBar, QMessageBox)
from PyQt5.QtCore import Qt, pyqtSignal, QTimer, QThread, pyqtSlot
from PyQt5.QtGui import QFont, QTextCursor, QColor, QPalette
import os
import sys
import json
import time
from datetime import datetime
from .base_tab import BaseTab

# å¯¼å…¥Markdownæ¸²æŸ“å™¨
from .components.chat.markdown_renderer import render_markdown

# å¯¼å…¥LLMæ¡†æ¶
try:
    from src.llm.llm_framework import LLMFramework
    from src.llm.model_adapters import create_llm_adapter
    from src.ui.components.model_analysis.model_selection_dialog import ModelSelectionDialog
    LLM_AVAILABLE = True
except ImportError as e:
    print(f"LLMæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    LLM_AVAILABLE = False


class LLMChatThread(QThread):
    """LLMèŠå¤©å¤„ç†çº¿ç¨‹"""
    
    # å®šä¹‰ä¿¡å·
    chat_finished = pyqtSignal(str)  # èŠå¤©å®Œæˆï¼Œè¿”å›AIå›å¤
    chat_error = pyqtSignal(str)     # èŠå¤©å‡ºé”™
    analysis_finished = pyqtSignal(str)  # åˆ†æå®Œæˆ
    analysis_error = pyqtSignal(str)     # åˆ†æå‡ºé”™
    
    def __init__(self, llm_framework, parent=None):
        super().__init__(parent)
        self.llm_framework = llm_framework
        self.task_type = ""
        self.user_message = ""
        self.training_context = {}
        self.task_params = {}
        
    def set_chat_task(self, user_message, training_context=None):
        """è®¾ç½®èŠå¤©ä»»åŠ¡"""
        self.task_type = "chat"
        self.user_message = user_message
        self.training_context = training_context or {}
        
    def set_analysis_task(self, task_type, params=None):
        """è®¾ç½®åˆ†æä»»åŠ¡"""
        self.task_type = task_type
        self.task_params = params or {}
        
    def run(self):
        """æ‰§è¡Œä»»åŠ¡"""
        try:
            if not self.llm_framework:
                self.chat_error.emit("LLMæ¡†æ¶æœªåˆå§‹åŒ–")
                return
                
            if self.task_type == "chat":
                self._handle_chat()
            elif self.task_type == "analyze_training":
                self._handle_training_analysis()
            elif self.task_type == "get_suggestions":
                self._handle_suggestions()
            elif self.task_type == "diagnose_issues":
                self._handle_diagnosis()
            elif self.task_type == "compare_models":
                self._handle_model_comparison()
            else:
                self.chat_error.emit(f"æœªçŸ¥çš„ä»»åŠ¡ç±»å‹: {self.task_type}")
                
        except Exception as e:
            if self.task_type == "chat":
                self.chat_error.emit(f"å¤„ç†èŠå¤©è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")
            else:
                self.analysis_error.emit(f"å¤„ç†åˆ†æè¯·æ±‚æ—¶å‡ºé”™: {str(e)}")
    
    def _handle_chat(self):
        """å¤„ç†èŠå¤©è¯·æ±‚"""
        # è·å–è®­ç»ƒé…ç½®ä¸Šä¸‹æ–‡
        config_context = ""
        if hasattr(self.llm_framework, 'analysis_engine'):
            config_context = self.llm_framework.analysis_engine._get_training_config_context()
        
        # æ„å»ºå¢å¼ºçš„ç”¨æˆ·æ¶ˆæ¯ï¼ŒåŒ…å«è®­ç»ƒé…ç½®ä¿¡æ¯
        enhanced_message = f"""
{config_context}

## ç”¨æˆ·é—®é¢˜
{self.user_message}

è¯·åŸºäºä»¥ä¸Šè®­ç»ƒé…ç½®ä¿¡æ¯ï¼Œé’ˆå¯¹ç”¨æˆ·çš„å…·ä½“é—®é¢˜è¿›è¡Œä¸“ä¸šå›ç­”ã€‚å¦‚æœç”¨æˆ·çš„é—®é¢˜ä¸è®­ç»ƒç›¸å…³ï¼Œè¯·ç»“åˆè®­ç»ƒé…ç½®å‚æ•°è¿›è¡Œåˆ†æå’Œå»ºè®®ã€‚
"""
        
        # å…ˆæ›´æ–°è®­ç»ƒä¸Šä¸‹æ–‡åˆ°LLMæ¡†æ¶ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        if hasattr(self.llm_framework, 'analysis_engine') and self.training_context:
            self.llm_framework.analysis_engine.prompt_builder.add_context({
                'type': 'training_context',
                'data': self.training_context
            })
        
        # è°ƒç”¨LLMæ¡†æ¶è¿›è¡Œå¯¹è¯
        result = self.llm_framework.chat_with_training_context(enhanced_message)
        
        # å¤„ç†è¿”å›ç»“æœ
        if isinstance(result, dict):
            if 'error' in result:
                self.chat_error.emit(result['error'])
            else:
                response_text = result.get('response', 'æŠ±æ­‰ï¼Œæ²¡æœ‰æ”¶åˆ°æœ‰æ•ˆå›å¤')
                self.chat_finished.emit(response_text)
        else:
            self.chat_finished.emit(str(result))
    
    def _handle_training_analysis(self):
        """å¤„ç†è®­ç»ƒåˆ†æè¯·æ±‚"""
        # ä½¿ç”¨çœŸå®è®­ç»ƒæ•°æ®è¿›è¡Œåˆ†æ
        try:
            # å°è¯•è·å–çœŸå®è®­ç»ƒæ•°æ®
            result = self.llm_framework.analyze_real_training_metrics()
            
            # å¦‚æœæ²¡æœ‰çœŸå®æ•°æ®ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®
            if result.get('error') and 'æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒæ•°æ®' in str(result.get('error', '')):
                # æ¨¡æ‹Ÿå½“å‰è®­ç»ƒæŒ‡æ ‡ï¼ˆä»…ä½œä¸ºåå¤‡æ–¹æ¡ˆï¼‰
                current_metrics = {
                    'epoch': 15,
                    'train_loss': 0.234,
                    'val_loss': 0.287,
                    'train_accuracy': 0.894,
                    'val_accuracy': 0.856,
                    'learning_rate': 0.001,
                    'gpu_memory_used': 6.2,
                    'gpu_memory_total': 8.0
                }
                result = self.llm_framework.analyze_training_metrics(current_metrics)
                
                # æ·»åŠ æç¤ºè¯´æ˜è¿™æ˜¯æ¨¡æ‹Ÿæ•°æ®
                if isinstance(result, dict) and 'combined_insights' in result:
                    result['combined_insights'] = "âš ï¸ **æ³¨æ„ï¼šå½“å‰ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œåˆ†æ**\n\n" + result['combined_insights']
                    
        except Exception as e:
            # å¦‚æœå‡ºç°å¼‚å¸¸ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºåå¤‡
            current_metrics = {
                'epoch': 15,
                'train_loss': 0.234,
                'val_loss': 0.287,
                'train_accuracy': 0.894,
                'val_accuracy': 0.856,
                'learning_rate': 0.001,
                'gpu_memory_used': 6.2,
                'gpu_memory_total': 8.0
            }
            result = self.llm_framework.analyze_training_metrics(current_metrics)
        
        # å¤„ç†è¿”å›ç»“æœ
        if isinstance(result, dict):
            if 'error' in result:
                self.analysis_error.emit(result['error'])
            else:
                # å°è¯•è·å–åˆ†æå†…å®¹
                combined_insights = result.get('combined_insights', '')
                llm_analysis = result.get('llm_analysis', '')
                response_text = combined_insights or llm_analysis or 'åˆ†æå®Œæˆï¼Œä½†æœªè·å¾—æœ‰æ•ˆç»“æœ'
                
                # å¦‚æœæœ‰å»ºè®®ï¼Œä¹Ÿæ˜¾ç¤ºå‡ºæ¥
                recommendations = result.get('recommendations')
                if recommendations:
                    response_text += f"\n\nå»ºè®®: {recommendations}"
                
                self.analysis_finished.emit(response_text)
        else:
            self.analysis_finished.emit(str(result))
    
    def _handle_suggestions(self):
        """å¤„ç†å»ºè®®è¯·æ±‚"""
        # ä½¿ç”¨çœŸå®è®­ç»ƒæ•°æ®è¿›è¡Œå»ºè®®ç”Ÿæˆ
        try:
            # å°è¯•è·å–åŸºäºçœŸå®æ•°æ®çš„å»ºè®®
            result = self.llm_framework.get_real_hyperparameter_suggestions()
            
            # å¦‚æœæ²¡æœ‰çœŸå®æ•°æ®ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®
            if result.get('error') and 'æ— æ³•è·å–çœŸå®è®­ç»ƒæ•°æ®' in str(result.get('error', '')):
                # æ¨¡æ‹Ÿè®­ç»ƒå†å²ï¼ˆä»…ä½œä¸ºåå¤‡æ–¹æ¡ˆï¼‰
                current_metrics = {'train_loss': 0.234, 'val_loss': 0.287, 'accuracy': 0.856}
                current_params = {'batch_size': 32, 'learning_rate': 0.001}
                result = self.llm_framework.get_hyperparameter_suggestions(
                    current_metrics, current_params
                )
                
                # æ·»åŠ æç¤ºè¯´æ˜è¿™æ˜¯æ¨¡æ‹Ÿæ•°æ®
                if isinstance(result, dict) and 'llm_suggestions' in result:
                    result['llm_suggestions'] = "âš ï¸ **æ³¨æ„ï¼šå½“å‰ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œå»ºè®®ç”Ÿæˆ**\n\n" + result['llm_suggestions']
                    
        except Exception as e:
            # å¦‚æœå‡ºç°å¼‚å¸¸ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºåå¤‡
            current_metrics = {'train_loss': 0.234, 'val_loss': 0.287, 'accuracy': 0.856}
            current_params = {'batch_size': 32, 'learning_rate': 0.001}
            result = self.llm_framework.get_hyperparameter_suggestions(
                current_metrics, current_params
            )
        
        # å¤„ç†è¿”å›ç»“æœ
        if isinstance(result, dict):
            if 'error' in result:
                self.analysis_error.emit(result['error'])
            else:
                # å°è¯•è·å–å»ºè®®å†…å®¹
                llm_suggestions = result.get('llm_suggestions', '')
                rule_suggestions = result.get('rule_suggestions', [])
                response_text = llm_suggestions or 'å·²ç”Ÿæˆä¼˜åŒ–å»ºè®®'
                
                if rule_suggestions:
                    response_text += f"\n\nè§„åˆ™å»ºè®®: {rule_suggestions}"
                
                self.analysis_finished.emit(response_text)
        else:
            self.analysis_finished.emit(str(result))
    
    def _handle_diagnosis(self):
        """å¤„ç†è¯Šæ–­è¯·æ±‚"""
        # ä½¿ç”¨çœŸå®è®­ç»ƒæ•°æ®è¿›è¡Œé—®é¢˜è¯Šæ–­
        try:
            # å°è¯•è·å–åŸºäºçœŸå®æ•°æ®çš„è¯Šæ–­
            result = self.llm_framework.diagnose_real_training_problems()
            
            # å¦‚æœæ²¡æœ‰çœŸå®æ•°æ®ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®
            if result.get('error') and 'æ— æ³•è·å–çœŸå®è®­ç»ƒæ•°æ®' in str(result.get('error', '')):
                # æ¨¡æ‹Ÿé—®é¢˜æŒ‡æ ‡ï¼ˆä»…ä½œä¸ºåå¤‡æ–¹æ¡ˆï¼‰
                problem_metrics = {
                    'train_loss': 0.1,
                    'val_loss': 0.8,  # æ˜æ˜¾çš„è¿‡æ‹Ÿåˆ
                    'gradient_norm': 1e-8,  # æ¢¯åº¦æ¶ˆå¤±
                    'epoch': 20
                }
                result = self.llm_framework.diagnose_training_problems(problem_metrics)
                
                # æ·»åŠ æç¤ºè¯´æ˜è¿™æ˜¯æ¨¡æ‹Ÿæ•°æ®
                if isinstance(result, dict) and 'llm_diagnosis' in result:
                    result['llm_diagnosis'] = "âš ï¸ **æ³¨æ„ï¼šå½“å‰ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œé—®é¢˜è¯Šæ–­**\n\n" + result['llm_diagnosis']
                    
        except Exception as e:
            # å¦‚æœå‡ºç°å¼‚å¸¸ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºåå¤‡
            problem_metrics = {
                'train_loss': 0.1,
                'val_loss': 0.8,  # æ˜æ˜¾çš„è¿‡æ‹Ÿåˆ
                'gradient_norm': 1e-8,  # æ¢¯åº¦æ¶ˆå¤±
                'epoch': 20
            }
            result = self.llm_framework.diagnose_training_problems(problem_metrics)
        
        # å¤„ç†è¿”å›ç»“æœ
        if isinstance(result, dict):
            if 'error' in result:
                self.analysis_error.emit(result['error'])
            else:
                # å°è¯•è·å–è¯Šæ–­å†…å®¹
                llm_diagnosis = result.get('llm_diagnosis', '')
                rule_diagnosis = result.get('rule_diagnosis', '')
                response_text = llm_diagnosis or rule_diagnosis or 'è¯Šæ–­å®Œæˆï¼Œä½†æœªå‘ç°æ˜æ˜¾é—®é¢˜'
                
                # æ·»åŠ æ¨èè¡ŒåŠ¨
                recommended_actions = result.get('recommended_actions')
                if recommended_actions:
                    response_text += f"\n\næ¨èè¡ŒåŠ¨: {recommended_actions}"
                
                self.analysis_finished.emit(response_text)
        else:
            self.analysis_finished.emit(str(result))
    
    def _handle_model_comparison(self):
        """å¤„ç†æ¨¡å‹å¯¹æ¯”è¯·æ±‚"""
        # ä½¿ç”¨ä¼ å…¥çš„çœŸå®æ¨¡å‹æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤æ¨¡æ‹Ÿæ•°æ®
        if self.task_params and isinstance(self.task_params, list) and len(self.task_params) > 0:
            model_results = self.task_params
        else:
            # é»˜è®¤æ¨¡æ‹Ÿæ•°æ®ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
            model_results = [
                {
                    'model_name': 'ResNet50',
                    'accuracy': 0.892,
                    'val_loss': 0.234,
                    'params': 25557032,
                    'inference_time': 0.05
                },
                {
                    'model_name': 'EfficientNet-B0',
                    'accuracy': 0.900,
                    'val_loss': 0.198,
                    'params': 5288548,
                    'inference_time': 0.03
                },
                {
                    'model_name': 'MobileNetV2',
                    'accuracy': 0.875,
                    'val_loss': 0.267,
                    'params': 3504872,
                    'inference_time': 0.02
                }
            ]
        
        result = self.llm_framework.analysis_engine.compare_models(model_results)
        
        # å¤„ç†è¿”å›ç»“æœ
        if isinstance(result, dict):
            if 'error' in result:
                self.analysis_error.emit(result['error'])
            else:
                # å°è¯•è·å–å¯¹æ¯”åˆ†æå†…å®¹
                llm_comparison = result.get('llm_comparison', '')
                rule_comparison = result.get('rule_comparison', '')
                response_text = llm_comparison or rule_comparison or 'æ¨¡å‹å¯¹æ¯”å®Œæˆ'
                
                # æ·»åŠ æœ€ä½³æ¨¡å‹æ¨è
                best_model = result.get('best_model')
                if best_model:
                    response_text += f"\n\næ¨èæ¨¡å‹: {best_model}"
                
                self.analysis_finished.emit(response_text)
        else:
            self.analysis_finished.emit(str(result))


class LLMChatWidget(QWidget):
    """LLMèŠå¤©ç•Œé¢ç»„ä»¶"""
    
    # å®šä¹‰ä¿¡å·
    status_updated = pyqtSignal(str)
    analysis_requested = pyqtSignal(dict)
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self.llm_framework = None
        self.chat_history = []
        self.training_context = {}
        self.chat_thread = None  # èŠå¤©çº¿ç¨‹
        self.init_ui()
        self.init_llm_framework()
    
    def init_ui(self):
        """åˆå§‹åŒ–èŠå¤©ç•Œé¢"""
        layout = QVBoxLayout(self)
        layout.setContentsMargins(10, 10, 10, 10)
        layout.setSpacing(10)
        
        # æ ‡é¢˜
        title_label = QLabel("AIè®­ç»ƒåŠ©æ‰‹")
        title_label.setFont(QFont('å¾®è½¯é›…é»‘', 12, QFont.Bold))
        title_label.setAlignment(Qt.AlignCenter)
        layout.addWidget(title_label)
        
        # LLMé€‚é…å™¨é€‰æ‹©å’Œé‡æ–°åŠ è½½æŒ‰é’®
        adapter_layout = QHBoxLayout()
        adapter_layout.addWidget(QLabel("AIæ¨¡å‹:"))
        self.adapter_combo = QComboBox()
        self.adapter_combo.addItems(["æ¨¡æ‹Ÿé€‚é…å™¨", "OpenAI GPT-4", "DeepSeek", "æœ¬åœ°Ollama", "è‡ªå®šä¹‰API"])
        self.adapter_combo.currentTextChanged.connect(self.switch_adapter)
        adapter_layout.addWidget(self.adapter_combo)
        
        # æ·»åŠ é‡æ–°åŠ è½½é…ç½®æŒ‰é’®
        self.reload_config_btn = QPushButton("ğŸ”„ é‡æ–°åŠ è½½é…ç½®")
        self.reload_config_btn.setToolTip("é‡æ–°åŠ è½½AIè®¾ç½®é…ç½®")
        self.reload_config_btn.clicked.connect(self.reload_ai_config)
        self.reload_config_btn.setStyleSheet("""
            QPushButton {
                background-color: #007bff;
                color: white;
                border: none;
                padding: 5px 10px;
                border-radius: 4px;
                font-size: 10px;
            }
            QPushButton:hover {
                background-color: #0056b3;
            }
            QPushButton:pressed {
                background-color: #004085;
            }
        """)
        adapter_layout.addWidget(self.reload_config_btn)
        
        adapter_layout.addStretch()
        layout.addLayout(adapter_layout)
        
        # èŠå¤©å†å²æ˜¾ç¤ºåŒºåŸŸ
        self.chat_display = QTextEdit()
        self.chat_display.setReadOnly(True)
        self.chat_display.setMinimumHeight(300)
        self.chat_display.setStyleSheet("""
            QTextEdit {
                background-color: #f8f9fa;
                border: 1px solid #dee2e6;
                border-radius: 8px;
                padding: 10px;
                font-family: 'Microsoft YaHei', Arial, sans-serif;
                font-size: 10pt;
            }
        """)
        layout.addWidget(self.chat_display)
        
        # å¿«æ·æ“ä½œæŒ‰é’®
        quick_actions_group = QGroupBox("å¿«æ·æ“ä½œ")
        quick_layout = QHBoxLayout()
        
        self.analyze_btn = QPushButton("ğŸ” åˆ†æå½“å‰è®­ç»ƒçŠ¶æ€")
        self.analyze_btn.clicked.connect(self.analyze_training)
        quick_layout.addWidget(self.analyze_btn)
        
        self.suggest_btn = QPushButton("ğŸ’¡ è·å–ä¼˜åŒ–å»ºè®®")
        self.suggest_btn.clicked.connect(self.get_suggestions)
        quick_layout.addWidget(self.suggest_btn)
        
        self.diagnose_btn = QPushButton("ğŸ”§ è¯Šæ–­è®­ç»ƒé—®é¢˜")
        self.diagnose_btn.clicked.connect(self.diagnose_issues)
        quick_layout.addWidget(self.diagnose_btn)
        
        self.compare_btn = QPushButton("ğŸ“Š æ¨¡å‹å¯¹æ¯”åˆ†æ")
        self.compare_btn.clicked.connect(self.compare_models)
        quick_layout.addWidget(self.compare_btn)
        
        quick_actions_group.setLayout(quick_layout)
        layout.addWidget(quick_actions_group)
        
        # æ¶ˆæ¯è¾“å…¥åŒºåŸŸ
        input_layout = QHBoxLayout()
        self.message_input = QLineEdit()
        self.message_input.setPlaceholderText("è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œä¾‹å¦‚ï¼šä¸ºä»€ä¹ˆéªŒè¯æŸå¤±åœ¨å¢åŠ ï¼Ÿ")
        self.message_input.returnPressed.connect(self.send_message)
        input_layout.addWidget(self.message_input)
        
        self.send_btn = QPushButton("å‘é€")
        self.send_btn.clicked.connect(self.send_message)
        input_layout.addWidget(self.send_btn)
        
        layout.addLayout(input_layout)
        
        # çŠ¶æ€æŒ‡ç¤ºå™¨
        self.status_label = QLabel("AIåŠ©æ‰‹å·²å°±ç»ª")
        self.status_label.setStyleSheet("color: #28a745; font-weight: bold;")
        layout.addWidget(self.status_label)
        
        # è¿›åº¦æ¡
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        layout.addWidget(self.progress_bar)
    
    def init_llm_framework(self):
        """åˆå§‹åŒ–LLMæ¡†æ¶"""
        if not LLM_AVAILABLE:
            self.add_system_message("âŒ LLMæ¨¡å—ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥å®‰è£…")
            self.set_ui_enabled(False)
            return
            
        try:
            # åŠ è½½AIè®¾ç½®é…ç½®
            ai_config = self.load_ai_config()
            
            # æ ¹æ®é…ç½®åˆå§‹åŒ–é€‚é…å™¨
            default_adapter = ai_config.get('general', {}).get('default_adapter', 'mock')
            
            if default_adapter == 'openai':
                openai_config = ai_config.get('openai', {})
                api_key = openai_config.get('api_key', '')
                if api_key:
                    self.llm_framework = LLMFramework('openai', openai_config)
                    self.adapter_combo.setCurrentText("OpenAI GPT-4")
                    self.add_system_message("âœ… AIåŠ©æ‰‹å·²å¯åŠ¨ï¼Œä½¿ç”¨OpenAI GPT-4")
                else:
                    # æ²¡æœ‰APIå¯†é’¥ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿé€‚é…å™¨
                    self.llm_framework = LLMFramework('mock')
                    self.adapter_combo.setCurrentText("æ¨¡æ‹Ÿé€‚é…å™¨")
                    self.add_system_message("âš ï¸ æœªé…ç½®OpenAI APIå¯†é’¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿé€‚é…å™¨")
            elif default_adapter == 'deepseek':
                deepseek_config = ai_config.get('deepseek', {})
                api_key = deepseek_config.get('api_key', '')
                if api_key:
                    self.llm_framework = LLMFramework('deepseek', deepseek_config)
                    self.adapter_combo.setCurrentText("DeepSeek")
                    self.add_system_message("âœ… AIåŠ©æ‰‹å·²å¯åŠ¨ï¼Œä½¿ç”¨DeepSeek")
                else:
                    # æ²¡æœ‰APIå¯†é’¥ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿé€‚é…å™¨
                    self.llm_framework = LLMFramework('mock')
                    self.adapter_combo.setCurrentText("æ¨¡æ‹Ÿé€‚é…å™¨")
                    self.add_system_message("âš ï¸ æœªé…ç½®DeepSeek APIå¯†é’¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿé€‚é…å™¨")
            elif default_adapter == 'local':
                ollama_config = ai_config.get('ollama', {})
                self.llm_framework = LLMFramework('local', ollama_config)
                self.adapter_combo.setCurrentText("æœ¬åœ°Ollama")
                self.add_system_message("âœ… AIåŠ©æ‰‹å·²å¯åŠ¨ï¼Œä½¿ç”¨æœ¬åœ°Ollama")
            elif default_adapter == 'custom':
                custom_config = ai_config.get('custom_api', {})
                api_key = custom_config.get('api_key', '')
                base_url = custom_config.get('base_url', '')
                if api_key and base_url:
                    self.llm_framework = LLMFramework('custom', custom_config)
                    self.adapter_combo.setCurrentText("è‡ªå®šä¹‰API")
                    api_name = custom_config.get('name', 'è‡ªå®šä¹‰API')
                    self.add_system_message(f"âœ… AIåŠ©æ‰‹å·²å¯åŠ¨ï¼Œä½¿ç”¨{api_name}")
                else:
                    # æ²¡æœ‰é…ç½®ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿé€‚é…å™¨
                    self.llm_framework = LLMFramework('mock')
                    self.adapter_combo.setCurrentText("æ¨¡æ‹Ÿé€‚é…å™¨")
                    self.add_system_message("âš ï¸ æœªé…ç½®è‡ªå®šä¹‰APIï¼Œä½¿ç”¨æ¨¡æ‹Ÿé€‚é…å™¨")
            else:
                # é»˜è®¤ä½¿ç”¨æ¨¡æ‹Ÿé€‚é…å™¨
                self.llm_framework = LLMFramework('mock')
                self.adapter_combo.setCurrentText("æ¨¡æ‹Ÿé€‚é…å™¨")
                self.add_system_message("âœ… AIåŠ©æ‰‹å·²å¯åŠ¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿé€‚é…å™¨")
            
            # å¯åŠ¨æ¡†æ¶
            self.llm_framework.start()
            self.status_label.setText("AIåŠ©æ‰‹å·²å°±ç»ª")
            self.status_label.setStyleSheet("color: #28a745; font-weight: bold;")
            
        except Exception as e:
            # åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿé€‚é…å™¨
            try:
                self.llm_framework = LLMFramework('mock')
                self.llm_framework.start()
                self.adapter_combo.setCurrentText("æ¨¡æ‹Ÿé€‚é…å™¨")
                self.add_system_message(f"âš ï¸ é…ç½®çš„é€‚é…å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                self.add_system_message("âœ… å·²å›é€€åˆ°æ¨¡æ‹Ÿé€‚é…å™¨")
                self.status_label.setText("AIåŠ©æ‰‹å·²å°±ç»ª")
                self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
            except Exception as fallback_error:
                self.add_system_message(f"âŒ LLMæ¡†æ¶åˆå§‹åŒ–å¤±è´¥: {str(fallback_error)}")
                self.set_ui_enabled(False)
    
    def switch_adapter(self, adapter_name):
        """åˆ‡æ¢LLMé€‚é…å™¨"""
        if not self.llm_framework:
            return
            
        try:
            self.status_label.setText("æ­£åœ¨åˆ‡æ¢AIæ¨¡å‹...")
            self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
            
            # åŠ è½½AIè®¾ç½®é…ç½®
            ai_config = self.load_ai_config()
            
            if adapter_name == "æ¨¡æ‹Ÿé€‚é…å™¨":
                adapter_type = 'mock'
                adapter_config = {}
            elif adapter_name == "OpenAI GPT-4":
                adapter_type = 'openai'
                openai_config = ai_config.get('openai', {})
                adapter_config = {
                    'api_key': openai_config.get('api_key', ''),
                    'model': openai_config.get('model', 'gpt-4'),
                    'base_url': openai_config.get('base_url', '') or None,
                    'temperature': openai_config.get('temperature', 0.7),
                    'max_tokens': openai_config.get('max_tokens', 1000)
                }
                
                # æ£€æŸ¥APIå¯†é’¥
                if not adapter_config['api_key']:
                    self.add_system_message("âŒ æœªé…ç½®OpenAI APIå¯†é’¥ï¼Œè¯·åœ¨è®¾ç½®ä¸­é…ç½®")
                    self.status_label.setText("é…ç½®ç¼ºå¤±")
                    self.status_label.setStyleSheet("color: #dc3545; font-weight: bold;")
                    return
                    
            elif adapter_name == "DeepSeek":
                adapter_type = 'deepseek'
                deepseek_config = ai_config.get('deepseek', {})
                adapter_config = {
                    'api_key': deepseek_config.get('api_key', ''),
                    'model': deepseek_config.get('model', 'deepseek-coder'),
                    'base_url': deepseek_config.get('base_url', '') or None,
                    'temperature': deepseek_config.get('temperature', 0.7),
                    'max_tokens': deepseek_config.get('max_tokens', 1000)
                }
                if not adapter_config['api_key']:
                    self.add_system_message("âŒ æœªé…ç½®DeepSeek APIå¯†é’¥ï¼Œè¯·åœ¨è®¾ç½®ä¸­é…ç½®")
                    self.status_label.setText("é…ç½®ç¼ºå¤±")
                    self.status_label.setStyleSheet("color: #dc3545; font-weight: bold;")
                    return
                    
            elif adapter_name == "æœ¬åœ°Ollama":
                adapter_type = 'local'
                ollama_config = ai_config.get('ollama', {})
                adapter_config = {
                    'model_name': ollama_config.get('model', 'llama2'),
                    'base_url': ollama_config.get('base_url', 'http://localhost:11434'),
                    'temperature': ollama_config.get('temperature', 0.7),
                    'num_predict': ollama_config.get('num_predict', 1000),
                    'timeout': ollama_config.get('timeout', 120)
                }
            elif adapter_name == "è‡ªå®šä¹‰API":
                adapter_type = 'custom'
                custom_config = ai_config.get('custom_api', {})
                adapter_config = {
                    'api_key': custom_config.get('api_key', ''),
                    'model': custom_config.get('model', 'custom-model'),
                    'base_url': custom_config.get('base_url', ''),
                    'provider_type': custom_config.get('provider_type', 'OpenAIå…¼å®¹'),
                    'temperature': custom_config.get('temperature', 0.7),
                    'max_tokens': custom_config.get('max_tokens', 1000)
                }
                
                # æ£€æŸ¥APIå¯†é’¥å’ŒåŸºç¡€URL
                if not adapter_config['api_key'] or not adapter_config['base_url']:
                    self.add_system_message("âŒ æœªé…ç½®è‡ªå®šä¹‰APIå¯†é’¥æˆ–åŸºç¡€URLï¼Œè¯·åœ¨è®¾ç½®ä¸­é…ç½®")
                    self.status_label.setText("é…ç½®ç¼ºå¤±")
                    self.status_label.setStyleSheet("color: #dc3545; font-weight: bold;")
                    return
            else:
                return
                
            self.llm_framework.switch_adapter(adapter_type, adapter_config)
            success = True
            
            if success:
                self.add_system_message(f"âœ… å·²åˆ‡æ¢åˆ°: {adapter_name}")
                if adapter_name == "OpenAI GPT-4":
                    model_name = adapter_config.get('model', 'gpt-4')
                    self.add_system_message(f"   ä½¿ç”¨æ¨¡å‹: {model_name}")
                elif adapter_name == "DeepSeek":
                    model_name = adapter_config.get('model', 'deepseek-coder')
                    self.add_system_message(f"   ä½¿ç”¨æ¨¡å‹: {model_name}")
                elif adapter_name == "æœ¬åœ°Ollama":
                    model_name = adapter_config.get('model_name', 'llama2')
                    base_url = adapter_config.get('base_url', 'localhost:11434')
                    self.add_system_message(f"   ä½¿ç”¨æ¨¡å‹: {model_name}")
                    self.add_system_message(f"   æœåŠ¡å™¨: {base_url}")
                elif adapter_name == "è‡ªå®šä¹‰API":
                    model_name = adapter_config.get('model', 'custom-model')
                    base_url = adapter_config.get('base_url', '')
                    api_name = custom_config.get('name', 'è‡ªå®šä¹‰API')
                    self.add_system_message(f"   ä½¿ç”¨æ¨¡å‹: {model_name}")
                    self.add_system_message(f"   APIåœ°å€: {base_url}")
                    self.add_system_message(f"   APIåç§°: {api_name}")
                    
                self.status_label.setText("AIåŠ©æ‰‹å·²å°±ç»ª")
                self.status_label.setStyleSheet("color: #28a745; font-weight: bold;")
            else:
                self.add_system_message(f"âŒ åˆ‡æ¢åˆ° {adapter_name} å¤±è´¥")
                self.status_label.setText("åˆ‡æ¢å¤±è´¥")
                self.status_label.setStyleSheet("color: #dc3545; font-weight: bold;")
                
        except Exception as e:
            self.add_system_message(f"âŒ åˆ‡æ¢é€‚é…å™¨æ—¶å‡ºé”™: {str(e)}")
            self.status_label.setText("åˆ‡æ¢å‡ºé”™")
            self.status_label.setStyleSheet("color: #dc3545; font-weight: bold;")
    
    def set_ui_enabled(self, enabled):
        """è®¾ç½®UIç»„ä»¶å¯ç”¨çŠ¶æ€"""
        self.analyze_btn.setEnabled(enabled)
        self.suggest_btn.setEnabled(enabled)
        self.diagnose_btn.setEnabled(enabled)
        self.compare_btn.setEnabled(enabled)
        self.send_btn.setEnabled(enabled)
        self.message_input.setEnabled(enabled)
    
    def add_system_message(self, message):
        """æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        
        # ä½¿ç”¨Markdownæ¸²æŸ“å™¨å¤„ç†æ¶ˆæ¯å†…å®¹
        try:
            rendered_content = render_markdown(message)
        except Exception as e:
            # å¦‚æœMarkdownæ¸²æŸ“å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬
            print(f"Markdownæ¸²æŸ“å¤±è´¥: {e}")
            rendered_content = message
        
        formatted_message = f"<div style='color: #6c757d; font-size: 9pt; margin: 5px 0;'>[{timestamp}] {rendered_content}</div>"
        self.chat_display.append(formatted_message)
    
    def add_user_message(self, message):
        """æ·»åŠ ç”¨æˆ·æ¶ˆæ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        formatted_message = f"""
        <div style='margin: 10px 0; padding: 8px; background-color: #e3f2fd; color: #000000; border: 1px solid #2196f3; border-radius: 10px; text-align: right;'>
            <span style='color: #6c757d; font-size: 11px; font-weight: normal;'>æ‚¨ [{timestamp}]:</span><br>
            <span style='color: #000000; font-style: italic;'>{message}</span>
        </div>
        """
        self.chat_display.append(formatted_message)
    
    def add_ai_message(self, message):
        """æ·»åŠ AIå“åº”æ¶ˆæ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        
        # ä½¿ç”¨Markdownæ¸²æŸ“å™¨å¤„ç†æ¶ˆæ¯å†…å®¹
        try:
            rendered_content = render_markdown(message)
        except Exception as e:
            # å¦‚æœMarkdownæ¸²æŸ“å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬
            print(f"Markdownæ¸²æŸ“å¤±è´¥: {e}")
            rendered_content = message
        
        formatted_message = f"""
        <div style='margin: 10px 0; padding: 12px; background-color: #f8f9fa; color: #000000; border: 1px solid #dee2e6; border-radius: 10px;'>
            <span style='color: #6c757d; font-size: 11px; font-weight: normal;'>AIåŠ©æ‰‹ [{timestamp}]:</span><br>
            <div style='color: #000000; margin-top: 8px; line-height: 1.6;'>{rendered_content}</div>
        </div>
        """
        self.chat_display.append(formatted_message)
        
        # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
        cursor = self.chat_display.textCursor()
        cursor.movePosition(QTextCursor.End)
        self.chat_display.setTextCursor(cursor)
    
    def send_message(self):
        """å‘é€ç”¨æˆ·æ¶ˆæ¯"""
        message = self.message_input.text().strip()
        if not message or not self.llm_framework:
            return
            
        # æ£€æŸ¥æ˜¯å¦æœ‰çº¿ç¨‹æ­£åœ¨è¿è¡Œ
        if self.chat_thread and self.chat_thread.isRunning():
            QMessageBox.information(self, "æç¤º", "AIæ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨ç­‰...")
            return
            
        self.message_input.clear()
        self.add_user_message(message)
        
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ç”¨äºèŠå¤©å†å²
        self._last_user_message = message
        
        # æ˜¾ç¤ºè¿›åº¦
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 0)  # ä¸ç¡®å®šè¿›åº¦
        self.status_label.setText("AIæ­£åœ¨æ€è€ƒ...")
        self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
        
        # ç¦ç”¨UIæ§ä»¶
        self.set_ui_enabled(False)
        
        # åˆ›å»ºå¹¶å¯åŠ¨èŠå¤©çº¿ç¨‹
        self.chat_thread = LLMChatThread(self.llm_framework)
        self.chat_thread.set_chat_task(message, self.training_context)
        
        # è¿æ¥ä¿¡å·
        self.chat_thread.chat_finished.connect(self.on_chat_finished)
        self.chat_thread.chat_error.connect(self.on_chat_error)
        
        # å¯åŠ¨çº¿ç¨‹
        self.chat_thread.start()
    
    def analyze_training(self):
        """åˆ†æå½“å‰è®­ç»ƒçŠ¶æ€"""
        if not self.llm_framework:
            return
            
        # æ£€æŸ¥æ˜¯å¦æœ‰çº¿ç¨‹æ­£åœ¨è¿è¡Œ
        if self.chat_thread and self.chat_thread.isRunning():
            QMessageBox.information(self, "æç¤º", "AIæ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨ç­‰...")
            return
        
        self.add_user_message("è¯·åˆ†æå½“å‰è®­ç»ƒçŠ¶æ€")
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 0)
        self.status_label.setText("æ­£åœ¨åˆ†æè®­ç»ƒçŠ¶æ€...")
        self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
        
        # ç¦ç”¨UIæ§ä»¶
        self.set_ui_enabled(False)
        
        # åˆ›å»ºå¹¶å¯åŠ¨åˆ†æçº¿ç¨‹
        self.chat_thread = LLMChatThread(self.llm_framework)
        self.chat_thread.set_analysis_task("analyze_training")
        
        # è¿æ¥ä¿¡å·
        self.chat_thread.analysis_finished.connect(self.on_analysis_finished)
        self.chat_thread.analysis_error.connect(self.on_analysis_error)
        
        # å¯åŠ¨çº¿ç¨‹
        self.chat_thread.start()
    
    def get_suggestions(self):
        """è·å–ä¼˜åŒ–å»ºè®®"""
        if not self.llm_framework:
            return
            
        # æ£€æŸ¥æ˜¯å¦æœ‰çº¿ç¨‹æ­£åœ¨è¿è¡Œ
        if self.chat_thread and self.chat_thread.isRunning():
            QMessageBox.information(self, "æç¤º", "AIæ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨ç­‰...")
            return
        
        self.add_user_message("è¯·ç»™å‡ºè¶…å‚æ•°ä¼˜åŒ–å»ºè®®")
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 0)
        self.status_label.setText("æ­£åœ¨ç”Ÿæˆä¼˜åŒ–å»ºè®®...")
        self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
        
        # ç¦ç”¨UIæ§ä»¶
        self.set_ui_enabled(False)
        
        # åˆ›å»ºå¹¶å¯åŠ¨åˆ†æçº¿ç¨‹
        self.chat_thread = LLMChatThread(self.llm_framework)
        self.chat_thread.set_analysis_task("get_suggestions")
        
        # è¿æ¥ä¿¡å·
        self.chat_thread.analysis_finished.connect(self.on_analysis_finished)
        self.chat_thread.analysis_error.connect(self.on_analysis_error)
        
        # å¯åŠ¨çº¿ç¨‹
        self.chat_thread.start()
    
    def diagnose_issues(self):
        """è¯Šæ–­è®­ç»ƒé—®é¢˜"""
        if not self.llm_framework:
            return
            
        # æ£€æŸ¥æ˜¯å¦æœ‰çº¿ç¨‹æ­£åœ¨è¿è¡Œ
        if self.chat_thread and self.chat_thread.isRunning():
            QMessageBox.information(self, "æç¤º", "AIæ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨ç­‰...")
            return
        
        self.add_user_message("è¯·è¯Šæ–­è®­ç»ƒä¸­çš„é—®é¢˜")
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 0)
        self.status_label.setText("æ­£åœ¨è¯Šæ–­é—®é¢˜...")
        self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
        
        # ç¦ç”¨UIæ§ä»¶
        self.set_ui_enabled(False)
        
        # åˆ›å»ºå¹¶å¯åŠ¨åˆ†æçº¿ç¨‹
        self.chat_thread = LLMChatThread(self.llm_framework)
        self.chat_thread.set_analysis_task("diagnose_issues")
        
        # è¿æ¥ä¿¡å·
        self.chat_thread.analysis_finished.connect(self.on_analysis_finished)
        self.chat_thread.analysis_error.connect(self.on_analysis_error)
        
        # å¯åŠ¨çº¿ç¨‹
        self.chat_thread.start()
    
    def compare_models(self):
        """æ¨¡å‹å¯¹æ¯”åˆ†æ - å¼•å¯¼ç”¨æˆ·åˆ°æ¨¡å‹è¯„ä¼°Tabè¿›è¡Œå®é™…è¯„ä¼°"""
        # æ˜¾ç¤ºå¼•å¯¼å¯¹è¯æ¡†
        reply = QMessageBox.question(
            self, "æ¨¡å‹å¯¹æ¯”åˆ†æ", 
            "æ¨¡å‹å¯¹æ¯”åˆ†æéœ€è¦ä½¿ç”¨çœŸå®çš„æµ‹è¯•æ•°æ®é›†å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚\n\n"
            "ç³»ç»Ÿå°†å¼•å¯¼æ‚¨åˆ‡æ¢åˆ°ã€Œæ¨¡å‹è¯„ä¼°ä¸å¯è§†åŒ–ã€æ ‡ç­¾é¡µè¿›è¡Œä»¥ä¸‹æ“ä½œï¼š\n"
            "1. é€‰æ‹©è¦å¯¹æ¯”çš„å¤šä¸ªæ¨¡å‹\n"
            "2. è®¾ç½®æµ‹è¯•é›†æ•°æ®ç›®å½•\n" 
            "3. æ‰§è¡Œæ¨¡å‹è¯„ä¼°è·å¾—çœŸå®æ€§èƒ½æ•°æ®\n"
            "4. ä½¿ç”¨AIåˆ†æè¯„ä¼°ç»“æœ\n\n"
            "æ˜¯å¦ç°åœ¨åˆ‡æ¢åˆ°æ¨¡å‹è¯„ä¼°é¡µé¢ï¼Ÿ",
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.Yes
        )
        
        if reply == QMessageBox.Yes:
            # åˆ‡æ¢åˆ°æ¨¡å‹è¯„ä¼°Tab
            self.switch_to_evaluation_tab()
            
            # åœ¨èŠå¤©ç•Œé¢æ˜¾ç¤ºå¼•å¯¼ä¿¡æ¯
            self.add_ai_message(
                "å·²ä¸ºæ‚¨åˆ‡æ¢åˆ°æ¨¡å‹è¯„ä¼°é¡µé¢ã€‚è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤è¿›è¡Œæ¨¡å‹å¯¹æ¯”åˆ†æï¼š\n\n"
                "ğŸ“‹ æ“ä½œæ­¥éª¤ï¼š\n"
                "1. é€‰æ‹©ã€Œæ¨¡å‹ç›®å½•ã€- åŒ…å«è¦å¯¹æ¯”çš„æ¨¡å‹æ–‡ä»¶\n"
                "2. é€‰æ‹©ã€Œæµ‹è¯•é›†ç›®å½•ã€- ç”¨äºè¯„ä¼°çš„æµ‹è¯•æ•°æ®\n"
                "3. è®¾ç½®ã€Œæ¨¡å‹ç±»å‹ã€å’Œã€Œæ¨¡å‹æ¶æ„ã€\n"
                "4. åœ¨æ¨¡å‹åˆ—è¡¨ä¸­é€‰æ‹©å¤šä¸ªè¦å¯¹æ¯”çš„æ¨¡å‹\n"
                "5. ç‚¹å‡»ã€Œå¯¹æ¯”é€‰ä¸­æ¨¡å‹ã€è¿›è¡Œè¯„ä¼°\n"
                "6. è¯„ä¼°å®Œæˆåï¼Œç‚¹å‡»ã€ŒAIç»“æœåˆ†æã€è·å¾—æ™ºèƒ½åˆ†ææŠ¥å‘Š\n\n"
                                 "ğŸ’¡ æç¤ºï¼šç¡®ä¿é€‰æ‹©çš„æ¨¡å‹ç±»å‹å’Œæ¶æ„ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼Œä»¥è·å¾—å‡†ç¡®çš„è¯„ä¼°ç»“æœã€‚"
             )
    
    def switch_to_evaluation_tab(self):
        """åˆ‡æ¢åˆ°æ¨¡å‹è¯„ä¼°Tab"""
        # é€šè¿‡parenté“¾æŸ¥æ‰¾ä¸»çª—å£
        main_window = None
        widget = self.parent()
        while widget and not hasattr(widget, 'tabs'):
            widget = widget.parent()
        main_window = widget
        
        if main_window and hasattr(main_window, 'tabs'):
            # è·å–ä¸»çª—å£çš„æ ‡ç­¾é¡µæ§ä»¶
            tab_widget = main_window.tabs
            
            # æŸ¥æ‰¾æ¨¡å‹è¯„ä¼°ä¸å¯è§†åŒ–æ ‡ç­¾é¡µçš„ç´¢å¼•
            for i in range(tab_widget.count()):
                tab_text = tab_widget.tabText(i)
                if "æ¨¡å‹è¯„ä¼°ä¸å¯è§†åŒ–" in tab_text:
                    tab_widget.setCurrentIndex(i)
                    
                    # è¿›ä¸€æ­¥åˆ‡æ¢åˆ°æ¨¡å‹è¯„ä¼°å­æ ‡ç­¾é¡µ
                    evaluation_tab = tab_widget.widget(i)
                    if hasattr(evaluation_tab, 'switch_view'):
                        # åˆ‡æ¢åˆ°æ¨¡å‹è¯„ä¼°å­æ ‡ç­¾é¡µï¼ˆç´¢å¼•3ï¼‰
                        evaluation_tab.switch_view(3)
                    break
        else:
            QMessageBox.warning(self, "é”™è¯¯", "æ— æ³•æ‰¾åˆ°ä¸»çª—å£ï¼Œæ— æ³•åˆ‡æ¢åˆ°æ¨¡å‹è¯„ä¼°é¡µé¢")
        
    def on_models_selected_for_comparison(self, models_data):
        """å¤„ç†ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹æ•°æ®"""
        if not models_data or len(models_data) < 2:
            QMessageBox.warning(self, "è­¦å‘Š", "éœ€è¦è‡³å°‘é€‰æ‹©2ä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”")
            return
            
        # æ˜¾ç¤ºç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹ä¿¡æ¯
        model_names = [model['model_name'] for model in models_data]
        user_message = f"è¯·å¯¹æ¯”åˆ†æä»¥ä¸‹ {len(models_data)} ä¸ªæ¨¡å‹ï¼š{', '.join(model_names)}"
        self.add_user_message(user_message)
        
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 0)
        self.status_label.setText("æ­£åœ¨å¯¹æ¯”æ¨¡å‹...")
        self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
        
        # ç¦ç”¨UIæ§ä»¶
        self.set_ui_enabled(False)
        
        # åˆ›å»ºå¹¶å¯åŠ¨åˆ†æçº¿ç¨‹ï¼Œä¼ å…¥çœŸå®çš„æ¨¡å‹æ•°æ®
        self.chat_thread = LLMChatThread(self.llm_framework)
        self.chat_thread.set_analysis_task("compare_models", models_data)
        
        # è¿æ¥ä¿¡å·
        self.chat_thread.analysis_finished.connect(self.on_analysis_finished)
        self.chat_thread.analysis_error.connect(self.on_analysis_error)
        
        # å¯åŠ¨çº¿ç¨‹
        self.chat_thread.start()
    
    def on_chat_finished(self, response_text):
        """èŠå¤©å®Œæˆå¤„ç†"""
        self.add_ai_message(response_text)
        
        # æ›´æ–°èŠå¤©å†å²
        if hasattr(self, '_last_user_message'):
            self.chat_history.append({
                'user': self._last_user_message,
                'ai': response_text,
                'timestamp': datetime.now().isoformat()
            })
        
        self._reset_ui_state()
    
    def on_chat_error(self, error_message):
        """èŠå¤©é”™è¯¯å¤„ç†"""
        self.add_ai_message(f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {error_message}")
        self._reset_ui_state()
    
    def start_ai_analysis_with_data(self, analysis_data):
        """ä½¿ç”¨çœŸå®è¯„ä¼°æ•°æ®å¯åŠ¨AIåˆ†æ"""
        if not self.llm_framework:
            return
            
        # æ£€æŸ¥æ˜¯å¦æœ‰çº¿ç¨‹æ­£åœ¨è¿è¡Œ
        if self.chat_thread and self.chat_thread.isRunning():
            QMessageBox.information(self, "æç¤º", "AIæ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨ç­‰...")
            return
        
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 0)
        self.status_label.setText("æ­£åœ¨åˆ†ææ¨¡å‹è¯„ä¼°ç»“æœ...")
        self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
        
        # ç¦ç”¨UIæ§ä»¶
        self.set_ui_enabled(False)
        
        # åˆ›å»ºå¹¶å¯åŠ¨åˆ†æçº¿ç¨‹ï¼Œä¼ å…¥çœŸå®çš„è¯„ä¼°æ•°æ®
        self.chat_thread = LLMChatThread(self.llm_framework)
        self.chat_thread.set_analysis_task("compare_models", analysis_data)
        
        # è¿æ¥ä¿¡å·
        self.chat_thread.analysis_finished.connect(self.on_analysis_finished)
        self.chat_thread.analysis_error.connect(self.on_analysis_error)
        
        # å¯åŠ¨çº¿ç¨‹
        self.chat_thread.start()

    def on_analysis_finished(self, response_text):
        """åˆ†æå®Œæˆå¤„ç†"""
        self.add_ai_message(response_text)
        self._reset_ui_state()
    
    def on_analysis_error(self, error_message):
        """åˆ†æé”™è¯¯å¤„ç†"""
        self.add_ai_message(f"åˆ†ææ—¶å‡ºç°é”™è¯¯: {error_message}")
        self._reset_ui_state()
    
    def _reset_ui_state(self):
        """é‡ç½®UIçŠ¶æ€"""
        self.progress_bar.setVisible(False)
        self.status_label.setText("AIåŠ©æ‰‹å·²å°±ç»ª")
        self.status_label.setStyleSheet("color: #28a745; font-weight: bold;")
        
        # é‡æ–°å¯ç”¨UIæ§ä»¶
        self.set_ui_enabled(True)
    
    def update_training_context(self, context):
        """æ›´æ–°è®­ç»ƒä¸Šä¸‹æ–‡"""
        self.training_context.update(context)
    
    def load_ai_config(self):
        """åŠ è½½AIè®¾ç½®é…ç½®"""
        import json
        import os
        
        config_file = "setting/ai_config.json"
        default_config = {
            'openai': {
                'api_key': '',
                'base_url': '',
                'model': 'gpt-4',
                'temperature': 0.7,
                'max_tokens': 1000
            },
            'ollama': {
                'base_url': 'http://localhost:11434',
                'model': 'llama2',
                'temperature': 0.7,
                'num_predict': 1000
            },
            'deepseek': {
                'api_key': '',
                'base_url': '',
                'model': 'deepseek-coder',
                'temperature': 0.7,
                'max_tokens': 1000
            },
            'custom_api': {
                'name': '',
                'api_key': '',
                'base_url': '',
                'model': 'custom-model',
                'provider_type': 'OpenAIå…¼å®¹',
                'temperature': 0.7,
                'max_tokens': 1000
            },
            'general': {
                'default_adapter': 'mock',
                'request_timeout': 60,
                'max_retries': 3,
                'enable_cache': True,
                'enable_streaming': False
            }
        }
        
        try:
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    # åˆå¹¶é»˜è®¤é…ç½®ï¼Œç¡®ä¿æ‰€æœ‰å¿…éœ€çš„é”®éƒ½å­˜åœ¨
                    for key in default_config:
                        if key not in config:
                            config[key] = default_config[key]
                        elif isinstance(default_config[key], dict):
                            for subkey in default_config[key]:
                                if subkey not in config[key]:
                                    config[key][subkey] = default_config[key][subkey]
                    return config
            else:
                return default_config
        except Exception as e:
            print(f"åŠ è½½AIé…ç½®å¤±è´¥: {str(e)}")
            return default_config
    
    def reload_ai_config(self):
        """é‡æ–°åŠ è½½AIé…ç½®"""
        try:
            self.add_system_message("ğŸ”„ æ­£åœ¨é‡æ–°åŠ è½½AIé…ç½®...")
            self.status_label.setText("æ­£åœ¨é‡æ–°åŠ è½½é…ç½®...")
            self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
            
            # é‡æ–°åˆå§‹åŒ–LLMæ¡†æ¶
            self.init_llm_framework()
            
            self.add_system_message("âœ… AIé…ç½®é‡æ–°åŠ è½½å®Œæˆ")
            self.status_label.setText("AIåŠ©æ‰‹å·²å°±ç»ª")
            self.status_label.setStyleSheet("color: #28a745; font-weight: bold;")
            
        except Exception as e:
            self.add_system_message(f"âŒ é‡æ–°åŠ è½½AIé…ç½®å¤±è´¥: {str(e)}")
            self.status_label.setText("é…ç½®åŠ è½½å¤±è´¥")
            self.status_label.setStyleSheet("color: #dc3545; font-weight: bold;")


class AnalysisPanelWidget(QWidget):
    """æ™ºèƒ½åˆ†æé¢æ¿ç»„ä»¶"""
    
    status_updated = pyqtSignal(str)
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self.analysis_results = {}
        self.init_ui()
    
    def init_ui(self):
        """åˆå§‹åŒ–åˆ†æé¢æ¿ç•Œé¢"""
        layout = QVBoxLayout(self)
        layout.setContentsMargins(10, 10, 10, 10)
        layout.setSpacing(10)
        
        # æ ‡é¢˜
        title_label = QLabel("æ™ºèƒ½åˆ†æé¢æ¿")
        title_label.setFont(QFont('å¾®è½¯é›…é»‘', 12, QFont.Bold))
        title_label.setAlignment(Qt.AlignCenter)
        layout.addWidget(title_label)
        
        # åˆ›å»ºåˆ†æç»“æœæ ‡ç­¾é¡µ
        self.analysis_tabs = QTabWidget()
        
        # è®­ç»ƒçŠ¶æ€åˆ†æ
        self.training_status_widget = self.create_training_status_widget()
        self.analysis_tabs.addTab(self.training_status_widget, "è®­ç»ƒçŠ¶æ€")
        
        # æ€§èƒ½åˆ†æ
        self.performance_widget = self.create_performance_widget()
        self.analysis_tabs.addTab(self.performance_widget, "æ€§èƒ½åˆ†æ")
        
        # é—®é¢˜è¯Šæ–­
        self.diagnosis_widget = self.create_diagnosis_widget()
        self.analysis_tabs.addTab(self.diagnosis_widget, "é—®é¢˜è¯Šæ–­")
        
        # ä¼˜åŒ–å»ºè®®
        self.suggestions_widget = self.create_suggestions_widget()
        self.analysis_tabs.addTab(self.suggestions_widget, "ä¼˜åŒ–å»ºè®®")
        
        layout.addWidget(self.analysis_tabs)
        
        # åˆ·æ–°æŒ‰é’®
        refresh_btn = QPushButton("ğŸ”„ åˆ·æ–°åˆ†æ")
        refresh_btn.clicked.connect(self.refresh_analysis)
        layout.addWidget(refresh_btn)
    
    def create_training_status_widget(self):
        """åˆ›å»ºè®­ç»ƒçŠ¶æ€åˆ†æç»„ä»¶"""
        widget = QWidget()
        layout = QVBoxLayout(widget)
        
        self.status_display = QTextEdit()
        self.status_display.setReadOnly(True)
        self.status_display.setMaximumHeight(200)
        self.status_display.setPlaceholderText("è®­ç»ƒçŠ¶æ€åˆ†æå°†åœ¨è¿™é‡Œæ˜¾ç¤º...")
        layout.addWidget(self.status_display)
        
        return widget
    
    def create_performance_widget(self):
        """åˆ›å»ºæ€§èƒ½åˆ†æç»„ä»¶"""
        widget = QWidget()
        layout = QVBoxLayout(widget)
        
        self.performance_display = QTextEdit()
        self.performance_display.setReadOnly(True)
        self.performance_display.setMaximumHeight(200)
        self.performance_display.setPlaceholderText("æ€§èƒ½åˆ†æç»“æœå°†åœ¨è¿™é‡Œæ˜¾ç¤º...")
        layout.addWidget(self.performance_display)
        
        return widget
    
    def create_diagnosis_widget(self):
        """åˆ›å»ºé—®é¢˜è¯Šæ–­ç»„ä»¶"""
        widget = QWidget()
        layout = QVBoxLayout(widget)
        
        self.diagnosis_display = QTextEdit()
        self.diagnosis_display.setReadOnly(True)
        self.diagnosis_display.setMaximumHeight(200)
        self.diagnosis_display.setPlaceholderText("é—®é¢˜è¯Šæ–­ç»“æœå°†åœ¨è¿™é‡Œæ˜¾ç¤º...")
        layout.addWidget(self.diagnosis_display)
        
        return widget
    
    def create_suggestions_widget(self):
        """åˆ›å»ºä¼˜åŒ–å»ºè®®ç»„ä»¶"""
        widget = QWidget()
        layout = QVBoxLayout(widget)
        
        self.suggestions_display = QTextEdit()
        self.suggestions_display.setReadOnly(True)
        self.suggestions_display.setMaximumHeight(200)
        self.suggestions_display.setPlaceholderText("ä¼˜åŒ–å»ºè®®å°†åœ¨è¿™é‡Œæ˜¾ç¤º...")
        layout.addWidget(self.suggestions_display)
        
        return widget
    
    def refresh_analysis(self):
        """åˆ·æ–°åˆ†æç»“æœ - ä½¿ç”¨çœŸå®è®­ç»ƒæ•°æ®"""
        self.status_updated.emit("æ­£åœ¨è·å–çœŸå®è®­ç»ƒæ•°æ®...")
        
        try:
            # è·å–å®æ—¶æŒ‡æ ‡é‡‡é›†å™¨
            from src.training_components.real_time_metrics_collector import get_global_metrics_collector
            collector = get_global_metrics_collector()
            
            # è·å–çœŸå®è®­ç»ƒæ•°æ®
            real_data = collector.get_current_training_data_for_ai()
            
            if "error" in real_data:
                # å¦‚æœæ²¡æœ‰çœŸå®æ•°æ®ï¼Œæ˜¾ç¤ºæç¤ºä¿¡æ¯
                error_msg = real_data["error"]
                self.status_display.setText(f"âš ï¸ æ— æ³•è·å–è®­ç»ƒæ•°æ®\nğŸ“ åŸå› : {error_msg}\nğŸ’¡ è¯·ç¡®ä¿è®­ç»ƒæ­£åœ¨è¿›è¡Œä¸­")
                self.performance_display.setText("ğŸ“Š æ€§èƒ½æ•°æ®ä¸å¯ç”¨\nğŸ”„ è¯·å¯åŠ¨è®­ç»ƒåå†æ¬¡åˆ·æ–°")
                self.diagnosis_display.setText("ğŸ” è¯Šæ–­åŠŸèƒ½éœ€è¦è®­ç»ƒæ•°æ®\nâ³ ç­‰å¾…è®­ç»ƒå¼€å§‹...")
                self.suggestions_display.setText("ğŸ’­ ä¼˜åŒ–å»ºè®®éœ€è¦åŸºäºçœŸå®æ•°æ®\nğŸš€ å¼€å§‹è®­ç»ƒåå°†æä¾›ä¸ªæ€§åŒ–å»ºè®®")
                self.status_updated.emit(f"æ•°æ®è·å–å¤±è´¥: {error_msg}")
                return
            
            # è§£æçœŸå®æ•°æ®
            current_metrics = real_data.get("current_metrics", {})
            training_trends = real_data.get("training_trends", {})
            training_status = real_data.get("training_status", "unknown")
            session_id = real_data.get("session_id", "unknown")
            total_points = real_data.get("total_data_points", 0)
            duration = real_data.get("collection_duration", 0)
            
            # 1. è®­ç»ƒçŠ¶æ€åˆ†æ
            self._update_training_status_display(current_metrics, training_trends, training_status, session_id)
            
            # 2. æ€§èƒ½åˆ†æ
            self._update_performance_display(current_metrics, training_trends, total_points, duration)
            
            # 3. é—®é¢˜è¯Šæ–­
            self._update_diagnosis_display(current_metrics, training_trends)
            
            # 4. ä¼˜åŒ–å»ºè®®
            self._update_suggestions_display(current_metrics, training_trends)
            
            self.status_updated.emit(f"åˆ†æç»“æœå·²æ›´æ–° (åŸºäº{total_points}ä¸ªçœŸå®æ•°æ®ç‚¹)")
            
        except ImportError:
            # å¦‚æœæ— æ³•å¯¼å…¥é‡‡é›†å™¨ï¼Œæ˜¾ç¤ºæ¨¡å—ä¸å¯ç”¨ä¿¡æ¯
            self.status_display.setText("âŒ å®æ—¶æ•°æ®é‡‡é›†æ¨¡å—ä¸å¯ç”¨\nğŸ“¦ è¯·æ£€æŸ¥training_componentsæ¨¡å—")
            self.performance_display.setText("âš ï¸ æ€§èƒ½ç›‘æ§åŠŸèƒ½æœªå¯ç”¨")
            self.diagnosis_display.setText("ğŸ”§ è¯Šæ–­åŠŸèƒ½éœ€è¦æ•°æ®é‡‡é›†æ”¯æŒ")
            self.suggestions_display.setText("ğŸ’¡ å»ºè®®åŠŸèƒ½éœ€è¦çœŸå®è®­ç»ƒæ•°æ®")
            self.status_updated.emit("æ•°æ®é‡‡é›†æ¨¡å—ä¸å¯ç”¨")
            
        except Exception as e:
            # å…¶ä»–å¼‚å¸¸å¤„ç†
            error_msg = str(e)
            self.status_display.setText(f"âŒ æ•°æ®è·å–å¼‚å¸¸\nğŸ“ é”™è¯¯: {error_msg}")
            self.performance_display.setText("âš ï¸ æ€§èƒ½æ•°æ®è·å–å¤±è´¥")
            self.diagnosis_display.setText("ğŸ”§ è¯Šæ–­åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨")
            self.suggestions_display.setText("ğŸ’¡ ä¼˜åŒ–å»ºè®®æš‚æ—¶ä¸å¯ç”¨")
            self.status_updated.emit(f"åˆ†æå¼‚å¸¸: {error_msg}")
    
    def _update_training_status_display(self, current_metrics, training_trends, training_status, session_id):
        """æ›´æ–°è®­ç»ƒçŠ¶æ€æ˜¾ç¤º"""
        try:
            status_text = f"ğŸ“Š è®­ç»ƒä¼šè¯: {session_id}\n"
            status_text += f"ğŸ”„ çŠ¶æ€: {training_status}\n"
            
            # å½“å‰æŒ‡æ ‡
            if current_metrics:
                epoch = current_metrics.get('epoch', 'N/A')
                phase = current_metrics.get('phase', 'N/A')
                loss = current_metrics.get('loss', 'N/A')
                accuracy = current_metrics.get('accuracy', 'N/A')
                
                status_text += f"ğŸ“ˆ å½“å‰Epoch: {epoch}\n"
                status_text += f"ğŸ¯ è®­ç»ƒé˜¶æ®µ: {phase}\n"
                
                if isinstance(loss, (int, float)):
                    status_text += f"ğŸ“‰ æŸå¤±å€¼: {loss:.4f}\n"
                else:
                    status_text += f"ğŸ“‰ æŸå¤±å€¼: {loss}\n"
                    
                if isinstance(accuracy, (int, float)):
                    status_text += f"ğŸ¯ å‡†ç¡®ç‡: {accuracy:.1%}\n"
                else:
                    status_text += f"ğŸ¯ å‡†ç¡®ç‡: {accuracy}\n"
            
            # è¶‹åŠ¿åˆ†æ
            train_losses = training_trends.get('train_losses', [])
            val_losses = training_trends.get('val_losses', [])
            train_accs = training_trends.get('train_accuracies', [])
            val_accs = training_trends.get('val_accuracies', [])
            
            if train_losses and len(train_losses) >= 2:
                loss_trend = "ğŸ“ˆ ä¸Šå‡" if train_losses[-1] > train_losses[-2] else "ğŸ“‰ ä¸‹é™"
                status_text += f"ğŸ“Š è®­ç»ƒæŸå¤±è¶‹åŠ¿: {loss_trend}\n"
                
            if val_losses and len(val_losses) >= 2:
                val_trend = "ğŸ“ˆ ä¸Šå‡" if val_losses[-1] > val_losses[-2] else "ğŸ“‰ ä¸‹é™"
                status_text += f"ğŸ“Š éªŒè¯æŸå¤±è¶‹åŠ¿: {val_trend}\n"
                
            # æ”¶æ•›çŠ¶æ€åˆ¤æ–­
            if train_losses and val_losses and len(train_losses) >= 3:
                recent_train = train_losses[-3:]
                recent_val = val_losses[-3:]
                
                train_stable = max(recent_train) - min(recent_train) < 0.01
                val_stable = max(recent_val) - min(recent_val) < 0.01
                
                if train_stable and val_stable:
                    status_text += "âœ… æ”¶æ•›çŠ¶æ€: ç¨³å®š\n"
                elif train_stable:
                    status_text += "âš ï¸ æ”¶æ•›çŠ¶æ€: è®­ç»ƒç¨³å®šï¼ŒéªŒè¯æ³¢åŠ¨\n"
                else:
                    status_text += "ğŸ”„ æ”¶æ•›çŠ¶æ€: æŒç»­å­¦ä¹ ä¸­\n"
            
            self.status_display.setText(status_text.strip())
            
        except Exception as e:
            self.status_display.setText(f"âŒ è®­ç»ƒçŠ¶æ€åˆ†æå¤±è´¥: {str(e)}")
    
    def _update_performance_display(self, current_metrics, training_trends, total_points, duration):
        """æ›´æ–°æ€§èƒ½åˆ†ææ˜¾ç¤º"""
        try:
            perf_text = f"ğŸ“Š æ•°æ®é‡‡é›†ç‚¹æ•°: {total_points}\n"
            perf_text += f"â±ï¸ é‡‡é›†æŒç»­æ—¶é—´: {duration:.1f}ç§’\n"
            
            # è®¡ç®—æ•°æ®é‡‡é›†é¢‘ç‡
            if duration > 0:
                frequency = total_points / duration
                perf_text += f"ğŸ“ˆ æ•°æ®é‡‡é›†é¢‘ç‡: {frequency:.2f} ç‚¹/ç§’\n"
            
            # è®­ç»ƒé€Ÿåº¦åˆ†æ
            train_losses = training_trends.get('train_losses', [])
            val_losses = training_trends.get('val_losses', [])
            epochs = training_trends.get('epochs', [])
            
            if epochs and len(epochs) >= 2:
                epoch_span = max(epochs) - min(epochs) + 1
                if duration > 0:
                    epoch_speed = epoch_span / (duration / 3600)  # epoch/å°æ—¶
                    perf_text += f"ğŸš€ è®­ç»ƒé€Ÿåº¦: {epoch_speed:.2f} epoch/å°æ—¶\n"
            
            # æŸå¤±å˜åŒ–ç‡
            if train_losses and len(train_losses) >= 2:
                loss_change = abs(train_losses[-1] - train_losses[0])
                improvement_rate = loss_change / len(train_losses)
                perf_text += f"ğŸ“‰ è®­ç»ƒæŸå¤±æ”¹å–„ç‡: {improvement_rate:.4f}/step\n"
            
            if val_losses and len(val_losses) >= 2:
                val_change = abs(val_losses[-1] - val_losses[0])
                val_improvement = val_change / len(val_losses)
                perf_text += f"ğŸ“Š éªŒè¯æŸå¤±å˜åŒ–ç‡: {val_improvement:.4f}/step\n"
            
            # æ•°æ®è´¨é‡è¯„ä¼°
            if train_losses and val_losses:
                data_quality = "ğŸŸ¢ ä¼˜ç§€" if len(train_losses) > 10 and len(val_losses) > 5 else "ğŸŸ¡ ä¸€èˆ¬"
                perf_text += f"ğŸ¯ æ•°æ®è´¨é‡: {data_quality}\n"
            
            self.performance_display.setText(perf_text.strip())
            
        except Exception as e:
            self.performance_display.setText(f"âŒ æ€§èƒ½åˆ†æå¤±è´¥: {str(e)}")
    
    def _update_diagnosis_display(self, current_metrics, training_trends):
        """æ›´æ–°é—®é¢˜è¯Šæ–­æ˜¾ç¤º"""
        try:
            diagnosis_text = ""
            issues_found = []
            
            train_losses = training_trends.get('train_losses', [])
            val_losses = training_trends.get('val_losses', [])
            train_accs = training_trends.get('train_accuracies', [])
            val_accs = training_trends.get('val_accuracies', [])
            
            # è¿‡æ‹Ÿåˆæ£€æµ‹
            if train_losses and val_losses and len(train_losses) >= 3 and len(val_losses) >= 3:
                avg_train_loss = sum(train_losses[-3:]) / 3
                avg_val_loss = sum(val_losses[-3:]) / 3
                
                if avg_val_loss > avg_train_loss * 1.5:
                    issues_found.append("âš ï¸ æ£€æµ‹åˆ°è¿‡æ‹Ÿåˆè¶‹åŠ¿")
                    issues_found.append("ğŸ’¡ å»ºè®®: å¢åŠ æ­£åˆ™åŒ–æˆ–å‡å°‘æ¨¡å‹å¤æ‚åº¦")
                elif avg_val_loss < avg_train_loss * 0.8:
                    issues_found.append("âš ï¸ å¯èƒ½å­˜åœ¨æ¬ æ‹Ÿåˆ")
                    issues_found.append("ğŸ’¡ å»ºè®®: å¢åŠ æ¨¡å‹å¤æ‚åº¦æˆ–å‡å°‘æ­£åˆ™åŒ–")
            
            # å­¦ä¹ åœæ»æ£€æµ‹
            if train_losses and len(train_losses) >= 5:
                recent_losses = train_losses[-5:]
                loss_variance = max(recent_losses) - min(recent_losses)
                if loss_variance < 0.001:
                    issues_found.append("âš ï¸ è®­ç»ƒå¯èƒ½å·²åœæ»")
                    issues_found.append("ğŸ’¡ å»ºè®®: è°ƒæ•´å­¦ä¹ ç‡æˆ–ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨")
            
            # æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±æ£€æµ‹ï¼ˆé€šè¿‡æŸå¤±å˜åŒ–åˆ¤æ–­ï¼‰
            if train_losses and len(train_losses) >= 2:
                loss_change = abs(train_losses[-1] - train_losses[-2])
                if loss_change > 1.0:
                    issues_found.append("âš ï¸ å¯èƒ½å­˜åœ¨æ¢¯åº¦çˆ†ç‚¸")
                    issues_found.append("ğŸ’¡ å»ºè®®: é™ä½å­¦ä¹ ç‡æˆ–ä½¿ç”¨æ¢¯åº¦è£å‰ª")
                elif loss_change < 1e-6:
                    issues_found.append("âš ï¸ å¯èƒ½å­˜åœ¨æ¢¯åº¦æ¶ˆå¤±")
                    issues_found.append("ğŸ’¡ å»ºè®®: æ£€æŸ¥ç½‘ç»œç»“æ„æˆ–ä½¿ç”¨æ®‹å·®è¿æ¥")
            
            # å‡†ç¡®ç‡å¼‚å¸¸æ£€æµ‹
            if train_accs and val_accs and len(train_accs) >= 2 and len(val_accs) >= 2:
                train_acc_trend = train_accs[-1] - train_accs[-2]
                val_acc_trend = val_accs[-1] - val_accs[-2]
                
                if train_acc_trend > 0.1 and val_acc_trend < -0.05:
                    issues_found.append("âš ï¸ è®­ç»ƒå‡†ç¡®ç‡ä¸Šå‡ä½†éªŒè¯å‡†ç¡®ç‡ä¸‹é™")
                    issues_found.append("ğŸ’¡ å»ºè®®: æ£€æŸ¥æ•°æ®åˆ†å¸ƒæˆ–å¢åŠ æ•°æ®å¢å¼º")
            
            if not issues_found:
                diagnosis_text = "âœ… æœªå‘ç°æ˜æ˜¾è®­ç»ƒé—®é¢˜\nğŸ“ˆ è®­ç»ƒè¿›å±•æ­£å¸¸\nğŸ¯ ç»§ç»­å½“å‰è®­ç»ƒç­–ç•¥"
            else:
                diagnosis_text = "\n".join(issues_found)
            
            self.diagnosis_display.setText(diagnosis_text)
            
        except Exception as e:
            self.diagnosis_display.setText(f"âŒ é—®é¢˜è¯Šæ–­å¤±è´¥: {str(e)}")
    
    def _update_suggestions_display(self, current_metrics, training_trends):
        """æ›´æ–°ä¼˜åŒ–å»ºè®®æ˜¾ç¤º"""
        try:
            suggestions = []
            
            train_losses = training_trends.get('train_losses', [])
            val_losses = training_trends.get('val_losses', [])
            train_accs = training_trends.get('train_accuracies', [])
            val_accs = training_trends.get('val_accuracies', [])
            
            # åŸºäºæŸå¤±è¶‹åŠ¿çš„å»ºè®®
            if train_losses and len(train_losses) >= 3:
                recent_trend = sum(train_losses[-3:]) / 3 - sum(train_losses[-6:-3]) / 3 if len(train_losses) >= 6 else 0
                
                if recent_trend > 0.01:
                    suggestions.append("ğŸ“‰ è®­ç»ƒæŸå¤±ä¸Šå‡ï¼Œå»ºè®®é™ä½å­¦ä¹ ç‡")
                elif recent_trend < -0.05:
                    suggestions.append("ğŸš€ è®­ç»ƒè¿›å±•è‰¯å¥½ï¼Œå¯è€ƒè™‘é€‚å½“æé«˜å­¦ä¹ ç‡")
                else:
                    suggestions.append("âš–ï¸ è®­ç»ƒæŸå¤±ç¨³å®šï¼Œä¿æŒå½“å‰å­¦ä¹ ç‡")
            
            # åŸºäºè¿‡æ‹Ÿåˆé£é™©çš„å»ºè®®
            if train_losses and val_losses and len(train_losses) >= 2 and len(val_losses) >= 2:
                train_val_gap = val_losses[-1] - train_losses[-1]
                
                if train_val_gap > 0.2:
                    suggestions.append("ğŸ›¡ï¸ è¿‡æ‹Ÿåˆé£é™©è¾ƒé«˜ï¼Œå»ºè®®å¢åŠ Dropoutæˆ–æ­£åˆ™åŒ–")
                elif train_val_gap < 0.05:
                    suggestions.append("ğŸ¯ æ³›åŒ–èƒ½åŠ›è‰¯å¥½ï¼Œå¯è€ƒè™‘å¢åŠ æ¨¡å‹å¤æ‚åº¦")
            
            # åŸºäºå‡†ç¡®ç‡çš„å»ºè®®
            if val_accs and len(val_accs) >= 1:
                current_val_acc = val_accs[-1]
                
                if current_val_acc < 0.7:
                    suggestions.append("ğŸ“Š éªŒè¯å‡†ç¡®ç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®è´¨é‡æˆ–æ¨¡å‹æ¶æ„")
                elif current_val_acc > 0.9:
                    suggestions.append("ğŸ‰ éªŒè¯å‡†ç¡®ç‡ä¼˜ç§€ï¼Œå¯è€ƒè™‘è¿›è¡Œæ¨¡å‹å‹ç¼©æˆ–éƒ¨ç½²")
            
            # è®­ç»ƒæ—¶é—´å»ºè®®
            current_epoch = current_metrics.get('epoch', 0)
            if isinstance(current_epoch, (int, float)) and current_epoch > 0:
                if current_epoch < 10:
                    suggestions.append("â° è®­ç»ƒåˆæœŸï¼Œå»ºè®®å¯†åˆ‡è§‚å¯ŸæŸå¤±å˜åŒ–")
                elif current_epoch > 50:
                    suggestions.append("â³ è®­ç»ƒæ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®è¯„ä¼°æ˜¯å¦éœ€è¦æ—©åœ")
            
            # æ•°æ®å¢å¼ºå»ºè®®
            if train_losses and val_losses and len(train_losses) >= 5:
                train_stability = max(train_losses[-5:]) - min(train_losses[-5:])
                if train_stability < 0.01:
                    suggestions.append("ğŸ”„ è®­ç»ƒç¨³å®šï¼Œå¯è€ƒè™‘å¢åŠ æ•°æ®å¢å¼ºå¤šæ ·æ€§")
            
            if not suggestions:
                suggestions.append("ğŸ“‹ åŸºäºå½“å‰æ•°æ®æš‚æ— ç‰¹å®šå»ºè®®")
                suggestions.append("ğŸ’¡ ç»§ç»­ç›‘æ§è®­ç»ƒè¿›å±•")
            
            suggestions_text = "\n".join(f"{i+1}. {suggestion}" for i, suggestion in enumerate(suggestions))
            self.suggestions_display.setText(suggestions_text)
            
        except Exception as e:
            self.suggestions_display.setText(f"âŒ ä¼˜åŒ–å»ºè®®ç”Ÿæˆå¤±è´¥: {str(e)}")


class ModelFactoryTab(BaseTab):
    """æ¨¡å‹å·¥å‚æ ‡ç­¾é¡µ - é›†æˆLLMæ™ºèƒ½åˆ†æåŠŸèƒ½"""
    
    # å®šä¹‰ä¿¡å·
    llm_analysis_requested = pyqtSignal(dict)
    training_context_updated = pyqtSignal(dict)
    
    def __init__(self, parent=None, main_window=None):
        super().__init__(parent, main_window)
        self.main_window = main_window
        self.current_analysis = {}
        self.init_ui()
        
        # ä½¿ç”¨æ–°çš„æ™ºèƒ½é…ç½®ç³»ç»Ÿ
        config = self.get_config_from_manager()
        if config:
            self.apply_config(config)
    
    def init_ui(self):
        """åˆå§‹åŒ–ç”¨æˆ·ç•Œé¢"""
        # åˆ›å»ºä¸»å¸ƒå±€
        main_layout = QVBoxLayout(self.scroll_content)
        main_layout.setContentsMargins(10, 10, 10, 10)
        main_layout.setSpacing(10)
        

        
        # åˆ›å»ºå‚ç›´åˆ†å‰²å™¨
        main_splitter = QSplitter(Qt.Vertical)
        main_splitter.setChildrenCollapsible(False)
        
        # ä¸ŠåŠéƒ¨åˆ†ï¼šLLMèŠå¤©å’Œåˆ†æé¢æ¿ - ä½¿ç”¨æ°´å¹³åˆ†å‰²å™¨
        upper_splitter = QSplitter(Qt.Horizontal)
        upper_splitter.setChildrenCollapsible(False)
        
        # å·¦ä¾§ï¼šLLMèŠå¤©ç•Œé¢
        left_widget = QWidget()
        left_layout = QVBoxLayout(left_widget)
        left_layout.setContentsMargins(5, 5, 5, 5)
        
        self.chat_widget = LLMChatWidget()
        self.chat_widget.status_updated.connect(self.update_status)
        self.chat_widget.analysis_requested.connect(self.handle_analysis_request)
        left_layout.addWidget(self.chat_widget)
        
        upper_splitter.addWidget(left_widget)
        
        # å³ä¾§ï¼šåˆ†æé¢æ¿å’Œç³»ç»ŸçŠ¶æ€
        right_widget = QWidget()
        right_layout = QVBoxLayout(right_widget)
        right_layout.setContentsMargins(5, 5, 5, 5)
        
        # åˆ†æé¢æ¿
        self.analysis_panel = AnalysisPanelWidget()
        self.analysis_panel.status_updated.connect(self.update_status)
        right_layout.addWidget(self.analysis_panel)
        
        # ç³»ç»ŸçŠ¶æ€é¢æ¿
        status_group = QGroupBox("ç³»ç»ŸçŠ¶æ€")
        status_layout = QVBoxLayout()
        
        self.system_status_display = QTextEdit()
        self.system_status_display.setReadOnly(True)
        self.system_status_display.setMaximumHeight(150)
        self.system_status_display.setPlaceholderText("ç³»ç»ŸçŠ¶æ€ä¿¡æ¯å°†åœ¨è¿™é‡Œæ˜¾ç¤º...")
        status_layout.addWidget(self.system_status_display)
        
        # ç³»ç»Ÿæ§åˆ¶æŒ‰é’®
        control_layout = QHBoxLayout()
        
        self.health_check_btn = QPushButton("ğŸ¥ å¥åº·æ£€æŸ¥")
        self.health_check_btn.clicked.connect(self.perform_health_check)
        control_layout.addWidget(self.health_check_btn)
        
        self.stats_btn = QPushButton("ğŸ“Š ç³»ç»Ÿç»Ÿè®¡")
        self.stats_btn.clicked.connect(self.show_system_stats)
        control_layout.addWidget(self.stats_btn)
        
        self.clear_btn = QPushButton("ğŸ—‘ï¸ æ¸…ç©ºå†å²")
        self.clear_btn.clicked.connect(self.clear_chat_history)
        control_layout.addWidget(self.clear_btn)
        
        status_layout.addLayout(control_layout)
        status_group.setLayout(status_layout)
        right_layout.addWidget(status_group)
        
        upper_splitter.addWidget(right_widget)
        
        main_splitter.addWidget(upper_splitter)
        
        # è®¾ç½®æ°´å¹³åˆ†å‰²å™¨çš„åˆå§‹æ¯”ä¾‹ (èŠå¤©ç•Œé¢60%, åˆ†æé¢æ¿40%)
        upper_splitter.setSizes([600, 400])
        
        # ä¸‹åŠéƒ¨åˆ†ï¼šBatchåˆ†æè§¦å‘æ§ä»¶å’Œå®æ—¶æ•°æ®æµç›‘æ§
        lower_widget = QWidget()
        lower_layout = QVBoxLayout(lower_widget)
        lower_layout.setContentsMargins(5, 5, 5, 5)
        
        # åˆ›å»ºæ°´å¹³åˆ†å‰²å™¨ç”¨äºä¸‹åŠéƒ¨åˆ†
        lower_splitter = QSplitter(Qt.Horizontal)
        lower_splitter.setChildrenCollapsible(False)
        
        # å·¦ä¾§ï¼šBatchåˆ†æè§¦å‘æ§ä»¶
        left_lower_widget = QWidget()
        left_lower_layout = QVBoxLayout(left_lower_widget)
        left_lower_layout.setContentsMargins(5, 5, 5, 5)
        
        # å¯¼å…¥å¹¶åˆ›å»ºBatchåˆ†æè§¦å‘æ§ä»¶
        try:
            from src.ui.components.model_analysis.batch_analysis_trigger_widget import BatchAnalysisTriggerWidget
            self.batch_analysis_trigger = BatchAnalysisTriggerWidget()
            self.batch_analysis_trigger.status_updated.connect(self.update_status)
            self.batch_analysis_trigger.analysis_triggered.connect(self.handle_batch_analysis_triggered)
            left_lower_layout.addWidget(self.batch_analysis_trigger)
            
            # ä»AIè®¾ç½®åŠ è½½é…ç½®
            self.load_batch_analysis_config()
        except ImportError as e:
            # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            error_label = QLabel(f"âš ï¸ Batchåˆ†æè§¦å‘æ§ä»¶åŠ è½½å¤±è´¥: {str(e)}")
            error_label.setStyleSheet("color: #dc3545; padding: 20px; border: 1px solid #dc3545; border-radius: 5px;")
            error_label.setAlignment(Qt.AlignCenter)
            left_lower_layout.addWidget(error_label)
        
        lower_splitter.addWidget(left_lower_widget)
        
        # å³ä¾§ï¼šå®æ—¶æ•°æ®æµç›‘æ§
        right_lower_widget = QWidget()
        right_lower_layout = QVBoxLayout(right_lower_widget)
        right_lower_layout.setContentsMargins(5, 5, 5, 5)
        
        # å¯¼å…¥å¹¶åˆ›å»ºå®æ—¶æ•°æ®æµç›‘æ§æ§ä»¶
        try:
            from src.ui.components.model_analysis.real_time_stream_monitor import RealTimeStreamMonitor
            self.stream_monitor = RealTimeStreamMonitor()
            right_lower_layout.addWidget(self.stream_monitor)
        except ImportError as e:
            # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            error_label = QLabel(f"âš ï¸ å®æ—¶æ•°æ®æµç›‘æ§æ§ä»¶åŠ è½½å¤±è´¥: {str(e)}")
            error_label.setStyleSheet("color: #dc3545; padding: 20px; border: 1px solid #dc3545; border-radius: 5px;")
            error_label.setAlignment(Qt.AlignCenter)
            right_lower_layout.addWidget(error_label)
        
        lower_splitter.addWidget(right_lower_widget)
        
        # è®¾ç½®ä¸‹åŠéƒ¨åˆ†åˆ†å‰²å™¨çš„æ¯”ä¾‹ (Batchåˆ†æè§¦å‘æ§ä»¶40%, å®æ—¶ç›‘æ§60%)
        lower_splitter.setSizes([400, 600])
        
        lower_layout.addWidget(lower_splitter)
        main_splitter.addWidget(lower_widget)
        
        # è®¾ç½®åˆ†å‰²å™¨æ¯”ä¾‹ (ä¸ŠåŠéƒ¨åˆ†70%, ä¸‹åŠéƒ¨åˆ†30%)
        main_splitter.setSizes([700, 300])
        
        main_layout.addWidget(main_splitter)
        
        # åˆå§‹åŒ–ç³»ç»ŸçŠ¶æ€
        self.update_system_status()
    
    def handle_analysis_request(self, request_data):
        """å¤„ç†åˆ†æè¯·æ±‚"""
        self.llm_analysis_requested.emit(request_data)
        self.update_status("æ­£åœ¨å¤„ç†åˆ†æè¯·æ±‚...")
    
    def handle_batch_analysis_triggered(self, analysis_data):
        """å¤„ç†Batchåˆ†æè§¦å‘äº‹ä»¶"""
        try:
            # æ›´æ–°çŠ¶æ€
            trigger_type = analysis_data.get('trigger_type', 'unknown')
            batch_count = analysis_data.get('batch_count', 0)
            analysis_count = analysis_data.get('analysis_count', 0)
            
            self.update_status(f"Batchåˆ†æè§¦å‘: {trigger_type} (Batch {batch_count}, ç¬¬{analysis_count}æ¬¡)")
            
            # å¦‚æœæœ‰èŠå¤©ç»„ä»¶ï¼Œè‡ªåŠ¨å‘é€åˆ†æè¯·æ±‚
            if hasattr(self, 'chat_widget') and self.chat_widget:
                # æ„å»ºåˆ†ææç¤º
                metrics = analysis_data.get('metrics', {})
                analysis_prompt = self._build_batch_analysis_prompt(analysis_data)
                
                # å‘é€åˆ°èŠå¤©ç»„ä»¶è¿›è¡ŒAIåˆ†æ
                self.chat_widget.add_user_message(analysis_prompt)
                self.chat_widget.analyze_training()
                
        except Exception as e:
            self.update_status(f"å¤„ç†Batchåˆ†æè§¦å‘æ—¶å‡ºé”™: {str(e)}")
    
    def _build_batch_analysis_prompt(self, analysis_data):
        """æ„å»ºBatchåˆ†ææç¤º"""
        trigger_type = analysis_data.get('trigger_type', 'unknown')
        batch_count = analysis_data.get('batch_count', 0)
        epoch = analysis_data.get('epoch', 0)
        phase = analysis_data.get('phase', '')
        analysis_count = analysis_data.get('analysis_count', 0)
        metrics = analysis_data.get('metrics', {})
        
        prompt = f"""
## ğŸ¯ Batchåˆ†æè¯·æ±‚ (ç¬¬{analysis_count}æ¬¡)

**è§¦å‘ä¿¡æ¯:**
- è§¦å‘ç±»å‹: {trigger_type}
- å½“å‰Epoch: {epoch}
- å½“å‰Phase: {phase}
- å½“å‰Batch: {batch_count}

**è®­ç»ƒæŒ‡æ ‡:**
{self._format_metrics_for_prompt(metrics)}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œå¯¹å½“å‰è®­ç»ƒçŠ¶æ€è¿›è¡Œä¸“ä¸šåˆ†æï¼ŒåŒ…æ‹¬ï¼š
1. è®­ç»ƒè¿›å±•è¯„ä¼°
2. æ½œåœ¨é—®é¢˜è¯Šæ–­
3. ä¼˜åŒ–å»ºè®®
4. ä¸‹ä¸€æ­¥é¢„æµ‹

è¯·æä¾›è¯¦ç»†ã€ä¸“ä¸šçš„åˆ†ææŠ¥å‘Šã€‚
"""
        return prompt
    
    def _format_metrics_for_prompt(self, metrics):
        """æ ¼å¼åŒ–æŒ‡æ ‡ç”¨äºæç¤º"""
        if not metrics:
            return "æš‚æ— è¯¦ç»†æŒ‡æ ‡æ•°æ®"
            
        formatted = []
        for key, value in metrics.items():
            if isinstance(value, (int, float)):
                formatted.append(f"- {key}: {value}")
            else:
                formatted.append(f"- {key}: {value}")
                
        return "\n".join(formatted) if formatted else "æš‚æ— è¯¦ç»†æŒ‡æ ‡æ•°æ®"
    
    def update_training_context(self, context):
        """æ›´æ–°è®­ç»ƒä¸Šä¸‹æ–‡"""
        if hasattr(self, 'chat_widget'):
            self.chat_widget.update_training_context(context)
        self.training_context_updated.emit(context)
    
    def perform_health_check(self):
        """æ‰§è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥"""
        if not LLM_AVAILABLE:
            self.system_status_display.setText("âŒ LLMæ¨¡å—ä¸å¯ç”¨")
            return
            
        try:
            if hasattr(self.chat_widget, 'llm_framework') and self.chat_widget.llm_framework:
                health_status = self.chat_widget.llm_framework.get_system_health()
                self.system_status_display.setText(f"âœ… ç³»ç»Ÿå¥åº·çŠ¶æ€: {health_status}")
            else:
                self.system_status_display.setText("âš ï¸ LLMæ¡†æ¶æœªåˆå§‹åŒ–")
        except Exception as e:
            self.system_status_display.setText(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")
    
    def show_system_stats(self):
        """æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        if not LLM_AVAILABLE:
            self.system_status_display.setText("âŒ LLMæ¨¡å—ä¸å¯ç”¨")
            return
            
        try:
            if hasattr(self.chat_widget, 'llm_framework') and self.chat_widget.llm_framework:
                stats = self.chat_widget.llm_framework.get_framework_stats()
                
                # è·å–æ€§èƒ½ç»Ÿè®¡æ•°æ®
                perf_stats = stats.get('performance_stats', {})
                adapter_info = stats.get('adapter_info', {})
                engine_stats = stats.get('engine_stats', {})
                
                # è®¡ç®—æˆåŠŸç‡
                total_requests = perf_stats.get('total_requests', 0)
                successful_requests = perf_stats.get('successful_requests', 0)
                success_rate = (successful_requests / total_requests * 100) if total_requests > 0 else 0
                
                # è·å–å¹³å‡å“åº”æ—¶é—´
                avg_response_time = perf_stats.get('average_response_time', 0)
                
                # è·å–é€‚é…å™¨ä¿¡æ¯
                adapter_type = adapter_info.get('type', 'Unknown')
                adapter_available = adapter_info.get('available', False)
                
                # è·å–å¼•æ“ç»Ÿè®¡
                analyses_performed = engine_stats.get('analyses_performed', 0)
                metrics_processed = engine_stats.get('metrics_processed', 0)
                
                # è·å–è¯·æ±‚ç±»å‹ç»Ÿè®¡
                request_types = perf_stats.get('request_types', {})
                
                # è®¡ç®—è¿è¡Œæ—¶é—´
                start_time = perf_stats.get('start_time', time.time())
                uptime_seconds = time.time() - start_time
                uptime_hours = uptime_seconds / 3600
                
                stats_text = f"""
ğŸ“Š æ¡†æ¶ç»Ÿè®¡ä¿¡æ¯:
â€¢ æ¡†æ¶çŠ¶æ€: {stats.get('framework_status', 'Unknown')}
â€¢ è¿è¡Œæ—¶é—´: {uptime_hours:.1f}å°æ—¶
â€¢ æ€»è¯·æ±‚æ•°: {total_requests}
â€¢ æˆåŠŸè¯·æ±‚æ•°: {successful_requests}
â€¢ å¤±è´¥è¯·æ±‚æ•°: {perf_stats.get('failed_requests', 0)}
â€¢ æˆåŠŸç‡: {success_rate:.1f}%
â€¢ å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}ç§’

ğŸ“ˆ è¯·æ±‚ç±»å‹åˆ†å¸ƒ:
â€¢ æŒ‡æ ‡åˆ†æ: {request_types.get('analyze_metrics', 0)}æ¬¡
â€¢ è·å–å»ºè®®: {request_types.get('get_suggestions', 0)}æ¬¡
â€¢ é—®é¢˜è¯Šæ–­: {request_types.get('diagnose_issues', 0)}æ¬¡
â€¢ å¯¹è¯äº¤äº’: {request_types.get('chat', 0)}æ¬¡
â€¢ æ¨¡å‹å¯¹æ¯”: {request_types.get('compare_models', 0)}æ¬¡

ğŸ”§ é€‚é…å™¨ä¿¡æ¯:
â€¢ ç±»å‹: {adapter_type}
â€¢ çŠ¶æ€: {'å¯ç”¨' if adapter_available else 'ä¸å¯ç”¨'}
â€¢ æ¨¡å‹: {adapter_info.get('model_name', 'Unknown')}

ğŸ“Š å¼•æ“ç»Ÿè®¡:
â€¢ å·²æ‰§è¡Œåˆ†æ: {analyses_performed}æ¬¡
â€¢ å·²å¤„ç†æŒ‡æ ‡: {metrics_processed}æ¡
                """.strip()
                self.system_status_display.setText(stats_text)
            else:
                self.system_status_display.setText("âš ï¸ LLMæ¡†æ¶æœªåˆå§‹åŒ–")
        except Exception as e:
            self.system_status_display.setText(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
    
    def clear_chat_history(self):
        """æ¸…ç©ºèŠå¤©å†å²"""
        if hasattr(self.chat_widget, 'chat_display'):
            self.chat_widget.chat_display.clear()
            self.chat_widget.chat_history.clear()
            self.chat_widget.add_system_message("èŠå¤©å†å²å·²æ¸…ç©º")
    
    def update_system_status(self):
        """æ›´æ–°ç³»ç»ŸçŠ¶æ€æ˜¾ç¤º"""
        if LLM_AVAILABLE:
            status_text = """
ğŸŸ¢ AIæ¨¡å‹å·¥å‚å·²å¯åŠ¨
ğŸ“¡ æ•°æ®æµæœåŠ¡: å°±ç»ª
ğŸ¤– LLMæ¡†æ¶: å·²åŠ è½½
ğŸ’¬ èŠå¤©æœåŠ¡: æ­£å¸¸
ğŸ“Š åˆ†æå¼•æ“: å¾…å‘½
            """.strip()
        else:
            status_text = """
ğŸ”´ AIæ¨¡å‹å·¥å‚å¯åŠ¨å¼‚å¸¸
âŒ LLMæ¡†æ¶: æœªåŠ è½½
âš ï¸ è¯·æ£€æŸ¥ä¾èµ–å®‰è£…
            """.strip()
        
        self.system_status_display.setText(status_text)
    
    def on_training_started(self, training_info):
        """è®­ç»ƒå¼€å§‹æ—¶æ›´æ–°ä¸Šä¸‹æ–‡"""
        context = {
            'training_active': True,
            'model_type': training_info.get('model_type', 'unknown'),
            'dataset': training_info.get('dataset', 'unknown'),
            'start_time': datetime.now().isoformat()
        }
        self.update_training_context(context)
        
        # é€šçŸ¥Batchåˆ†æè§¦å‘æ§ä»¶è®­ç»ƒå·²å¼€å§‹
        if hasattr(self, 'batch_analysis_trigger'):
            self.batch_analysis_trigger.on_training_started(training_info)
    
    def on_training_progress(self, metrics):
        """è®­ç»ƒè¿›åº¦æ›´æ–°æ—¶æ›´æ–°ä¸Šä¸‹æ–‡"""
        context = {
            'current_metrics': metrics,
            'last_update': datetime.now().isoformat()
        }
        self.update_training_context(context)
        
        # æ›´æ–°Batchåˆ†æè§¦å‘æ§ä»¶
        if hasattr(self, 'batch_analysis_trigger'):
            self.batch_analysis_trigger.update_training_progress(metrics)
    
    def on_training_completed(self, results):
        """è®­ç»ƒå®Œæˆæ—¶æ›´æ–°ä¸Šä¸‹æ–‡"""
        context = {
            'training_active': False,
            'final_results': results,
            'completion_time': datetime.now().isoformat()
        }
        self.update_training_context(context)
        
        # é€šçŸ¥Batchåˆ†æè§¦å‘æ§ä»¶è®­ç»ƒå·²å®Œæˆ
        if hasattr(self, 'batch_analysis_trigger'):
            self.batch_analysis_trigger.on_training_completed(results)
    
    def on_training_stopped(self):
        """è®­ç»ƒåœæ­¢æ—¶æ›´æ–°ä¸Šä¸‹æ–‡"""
        context = {
            'training_active': False,
            'stop_time': datetime.now().isoformat()
        }
        self.update_training_context(context)
        
        # é€šçŸ¥Batchåˆ†æè§¦å‘æ§ä»¶è®­ç»ƒå·²åœæ­¢
        if hasattr(self, 'batch_analysis_trigger'):
            self.batch_analysis_trigger.on_training_stopped()
    
    def reload_ai_config(self):
        """é‡æ–°åŠ è½½AIé…ç½®"""
        try:
            self.add_system_message("ğŸ”„ æ­£åœ¨é‡æ–°åŠ è½½AIé…ç½®...")
            self.status_label.setText("æ­£åœ¨é‡æ–°åŠ è½½é…ç½®...")
            self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
            
            # é‡æ–°åˆå§‹åŒ–LLMæ¡†æ¶
            self.init_llm_framework()
            
            self.add_system_message("âœ… AIé…ç½®é‡æ–°åŠ è½½å®Œæˆ")
            self.status_label.setText("AIåŠ©æ‰‹å·²å°±ç»ª")
            self.status_label.setStyleSheet("color: #28a745; font-weight: bold;")
            
        except Exception as e:
            self.add_system_message(f"âŒ é‡æ–°åŠ è½½AIé…ç½®å¤±è´¥: {str(e)}")
            self.status_label.setText("é…ç½®åŠ è½½å¤±è´¥")
            self.status_label.setStyleSheet("color: #dc3545; font-weight: bold;")
    
    def update_ai_adapter_from_settings(self, ai_config):
        """ä»è®¾ç½®æ›´æ–°AIé€‚é…å™¨é…ç½®"""
        if hasattr(self, 'chat_widget') and self.chat_widget and hasattr(self.chat_widget, 'llm_framework'):
            try:
                default_adapter = ai_config.get('general', {}).get('default_adapter', 'mock')
                
                # æ›´æ–°ä¸‹æ‹‰æ¡†æ˜¾ç¤º
                if default_adapter == 'openai':
                    self.chat_widget.adapter_combo.setCurrentText("OpenAI GPT-4")
                elif default_adapter == 'local':
                    self.chat_widget.adapter_combo.setCurrentText("æœ¬åœ°Ollama")
                elif default_adapter == 'deepseek':
                    self.chat_widget.adapter_combo.setCurrentText("DeepSeek")
                elif default_adapter == 'custom':
                    self.chat_widget.adapter_combo.setCurrentText("è‡ªå®šä¹‰API")
                else:
                    self.chat_widget.adapter_combo.setCurrentText("æ¨¡æ‹Ÿé€‚é…å™¨")
                
                # åˆ‡æ¢é€‚é…å™¨
                self.chat_widget.switch_adapter(self.chat_widget.adapter_combo.currentText())
                
            except Exception as e:
                print(f"æ›´æ–°AIé€‚é…å™¨é…ç½®æ—¶å‡ºé”™: {str(e)}")
        
        # æ›´æ–°Batchåˆ†æè§¦å‘æ§ä»¶é…ç½®
        self.load_batch_analysis_config()
    
    def load_batch_analysis_config(self):
        """ä»AIè®¾ç½®åŠ è½½Batchåˆ†æé…ç½®"""
        try:
            # ä»é…ç½®ç®¡ç†å™¨è·å–AIé…ç½®
            from src.utils.config_manager import config_manager
            ai_config = config_manager.get_ai_config()
            
            if ai_config and hasattr(self, 'batch_analysis_trigger'):
                self.batch_analysis_trigger.update_config_from_ai_settings(ai_config)
                
        except Exception as e:
            print(f"åŠ è½½Batchåˆ†æé…ç½®æ—¶å‡ºé”™: {str(e)}") 