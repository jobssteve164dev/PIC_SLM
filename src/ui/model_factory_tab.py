from PyQt5.QtWidgets import (QWidget, QVBoxLayout, QHBoxLayout, QPushButton, QLabel, 
                           QSplitter, QGroupBox, QTabWidget, QTextEdit, QLineEdit,
                           QScrollArea, QFrame, QSizePolicy, QStackedWidget, QComboBox,
                           QProgressBar, QMessageBox)
from PyQt5.QtCore import Qt, pyqtSignal, QTimer, QThread, pyqtSlot
from PyQt5.QtGui import QFont, QTextCursor, QColor, QPalette
import os
import sys
import json
from datetime import datetime
from .base_tab import BaseTab

# å¯¼å…¥LLMæ¡†æ¶
try:
    from src.llm.llm_framework import LLMFramework
    from src.llm.model_adapters import create_llm_adapter
    from src.ui.components.model_analysis.model_selection_dialog import ModelSelectionDialog
    LLM_AVAILABLE = True
except ImportError as e:
    print(f"LLMæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    LLM_AVAILABLE = False


class LLMChatThread(QThread):
    """LLMèŠå¤©å¤„ç†çº¿ç¨‹"""
    
    # å®šä¹‰ä¿¡å·
    chat_finished = pyqtSignal(str)  # èŠå¤©å®Œæˆï¼Œè¿”å›AIå›å¤
    chat_error = pyqtSignal(str)     # èŠå¤©å‡ºé”™
    analysis_finished = pyqtSignal(str)  # åˆ†æå®Œæˆ
    analysis_error = pyqtSignal(str)     # åˆ†æå‡ºé”™
    
    def __init__(self, llm_framework, parent=None):
        super().__init__(parent)
        self.llm_framework = llm_framework
        self.task_type = ""
        self.user_message = ""
        self.training_context = {}
        self.task_params = {}
        
    def set_chat_task(self, user_message, training_context=None):
        """è®¾ç½®èŠå¤©ä»»åŠ¡"""
        self.task_type = "chat"
        self.user_message = user_message
        self.training_context = training_context or {}
        
    def set_analysis_task(self, task_type, params=None):
        """è®¾ç½®åˆ†æä»»åŠ¡"""
        self.task_type = task_type
        self.task_params = params or {}
        
    def run(self):
        """æ‰§è¡Œä»»åŠ¡"""
        try:
            if not self.llm_framework:
                self.chat_error.emit("LLMæ¡†æ¶æœªåˆå§‹åŒ–")
                return
                
            if self.task_type == "chat":
                self._handle_chat()
            elif self.task_type == "analyze_training":
                self._handle_training_analysis()
            elif self.task_type == "get_suggestions":
                self._handle_suggestions()
            elif self.task_type == "diagnose_issues":
                self._handle_diagnosis()
            elif self.task_type == "compare_models":
                self._handle_model_comparison()
            else:
                self.chat_error.emit(f"æœªçŸ¥çš„ä»»åŠ¡ç±»å‹: {self.task_type}")
                
        except Exception as e:
            if self.task_type == "chat":
                self.chat_error.emit(f"å¤„ç†èŠå¤©è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")
            else:
                self.analysis_error.emit(f"å¤„ç†åˆ†æè¯·æ±‚æ—¶å‡ºé”™: {str(e)}")
    
    def _handle_chat(self):
        """å¤„ç†èŠå¤©è¯·æ±‚"""
        # å…ˆæ›´æ–°è®­ç»ƒä¸Šä¸‹æ–‡åˆ°LLMæ¡†æ¶ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        if hasattr(self.llm_framework, 'analysis_engine') and self.training_context:
            self.llm_framework.analysis_engine.prompt_builder.add_context({
                'type': 'training_context',
                'data': self.training_context
            })
        
        # è°ƒç”¨LLMæ¡†æ¶è¿›è¡Œå¯¹è¯
        result = self.llm_framework.chat_with_training_context(self.user_message)
        
        # å¤„ç†è¿”å›ç»“æœ
        if isinstance(result, dict):
            if 'error' in result:
                self.chat_error.emit(result['error'])
            else:
                response_text = result.get('response', 'æŠ±æ­‰ï¼Œæ²¡æœ‰æ”¶åˆ°æœ‰æ•ˆå›å¤')
                self.chat_finished.emit(response_text)
        else:
            self.chat_finished.emit(str(result))
    
    def _handle_training_analysis(self):
        """å¤„ç†è®­ç»ƒåˆ†æè¯·æ±‚"""
        # æ¨¡æ‹Ÿå½“å‰è®­ç»ƒæŒ‡æ ‡
        current_metrics = {
            'epoch': 15,
            'train_loss': 0.234,
            'val_loss': 0.287,
            'train_accuracy': 0.894,
            'val_accuracy': 0.856,
            'learning_rate': 0.001,
            'gpu_memory_used': 6.2,
            'gpu_memory_total': 8.0
        }
        
        result = self.llm_framework.analyze_training_metrics(current_metrics)
        
        # å¤„ç†è¿”å›ç»“æœ
        if isinstance(result, dict):
            if 'error' in result:
                self.analysis_error.emit(result['error'])
            else:
                # å°è¯•è·å–åˆ†æå†…å®¹
                combined_insights = result.get('combined_insights', '')
                llm_analysis = result.get('llm_analysis', '')
                response_text = combined_insights or llm_analysis or 'åˆ†æå®Œæˆï¼Œä½†æœªè·å¾—æœ‰æ•ˆç»“æœ'
                
                # å¦‚æœæœ‰å»ºè®®ï¼Œä¹Ÿæ˜¾ç¤ºå‡ºæ¥
                recommendations = result.get('recommendations')
                if recommendations:
                    response_text += f"\n\nå»ºè®®: {recommendations}"
                
                self.analysis_finished.emit(response_text)
        else:
            self.analysis_finished.emit(str(result))
    
    def _handle_suggestions(self):
        """å¤„ç†å»ºè®®è¯·æ±‚"""
        # æ¨¡æ‹Ÿè®­ç»ƒå†å²
        current_metrics = {'train_loss': 0.234, 'val_loss': 0.287, 'accuracy': 0.856}
        current_params = {'batch_size': 32, 'learning_rate': 0.001}
        
        result = self.llm_framework.get_hyperparameter_suggestions(
            current_metrics, current_params
        )
        
        # å¤„ç†è¿”å›ç»“æœ
        if isinstance(result, dict):
            if 'error' in result:
                self.analysis_error.emit(result['error'])
            else:
                # å°è¯•è·å–å»ºè®®å†…å®¹
                llm_suggestions = result.get('llm_suggestions', '')
                rule_suggestions = result.get('rule_suggestions', [])
                response_text = llm_suggestions or 'å·²ç”Ÿæˆä¼˜åŒ–å»ºè®®'
                
                if rule_suggestions:
                    response_text += f"\n\nè§„åˆ™å»ºè®®: {rule_suggestions}"
                
                self.analysis_finished.emit(response_text)
        else:
            self.analysis_finished.emit(str(result))
    
    def _handle_diagnosis(self):
        """å¤„ç†è¯Šæ–­è¯·æ±‚"""
        # æ¨¡æ‹Ÿé—®é¢˜æŒ‡æ ‡
        problem_metrics = {
            'train_loss': 0.1,
            'val_loss': 0.8,  # æ˜æ˜¾çš„è¿‡æ‹Ÿåˆ
            'gradient_norm': 1e-8,  # æ¢¯åº¦æ¶ˆå¤±
            'epoch': 20
        }
        
        result = self.llm_framework.diagnose_training_problems(problem_metrics)
        
        # å¤„ç†è¿”å›ç»“æœ
        if isinstance(result, dict):
            if 'error' in result:
                self.analysis_error.emit(result['error'])
            else:
                # å°è¯•è·å–è¯Šæ–­å†…å®¹
                llm_diagnosis = result.get('llm_diagnosis', '')
                rule_diagnosis = result.get('rule_diagnosis', '')
                response_text = llm_diagnosis or rule_diagnosis or 'è¯Šæ–­å®Œæˆï¼Œä½†æœªå‘ç°æ˜æ˜¾é—®é¢˜'
                
                # æ·»åŠ æ¨èè¡ŒåŠ¨
                recommended_actions = result.get('recommended_actions')
                if recommended_actions:
                    response_text += f"\n\næ¨èè¡ŒåŠ¨: {recommended_actions}"
                
                self.analysis_finished.emit(response_text)
        else:
            self.analysis_finished.emit(str(result))
    
    def _handle_model_comparison(self):
        """å¤„ç†æ¨¡å‹å¯¹æ¯”è¯·æ±‚"""
        # ä½¿ç”¨ä¼ å…¥çš„çœŸå®æ¨¡å‹æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤æ¨¡æ‹Ÿæ•°æ®
        if self.task_params and isinstance(self.task_params, list) and len(self.task_params) > 0:
            model_results = self.task_params
        else:
            # é»˜è®¤æ¨¡æ‹Ÿæ•°æ®ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
            model_results = [
                {
                    'model_name': 'ResNet50',
                    'accuracy': 0.892,
                    'val_loss': 0.234,
                    'params': 25557032,
                    'inference_time': 0.05
                },
                {
                    'model_name': 'EfficientNet-B0',
                    'accuracy': 0.900,
                    'val_loss': 0.198,
                    'params': 5288548,
                    'inference_time': 0.03
                },
                {
                    'model_name': 'MobileNetV2',
                    'accuracy': 0.875,
                    'val_loss': 0.267,
                    'params': 3504872,
                    'inference_time': 0.02
                }
            ]
        
        result = self.llm_framework.analysis_engine.compare_models(model_results)
        
        # å¤„ç†è¿”å›ç»“æœ
        if isinstance(result, dict):
            if 'error' in result:
                self.analysis_error.emit(result['error'])
            else:
                # å°è¯•è·å–å¯¹æ¯”åˆ†æå†…å®¹
                llm_comparison = result.get('llm_comparison', '')
                rule_comparison = result.get('rule_comparison', '')
                response_text = llm_comparison or rule_comparison or 'æ¨¡å‹å¯¹æ¯”å®Œæˆ'
                
                # æ·»åŠ æœ€ä½³æ¨¡å‹æ¨è
                best_model = result.get('best_model')
                if best_model:
                    response_text += f"\n\næ¨èæ¨¡å‹: {best_model}"
                
                self.analysis_finished.emit(response_text)
        else:
            self.analysis_finished.emit(str(result))


class LLMChatWidget(QWidget):
    """LLMèŠå¤©ç•Œé¢ç»„ä»¶"""
    
    # å®šä¹‰ä¿¡å·
    status_updated = pyqtSignal(str)
    analysis_requested = pyqtSignal(dict)
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self.llm_framework = None
        self.chat_history = []
        self.training_context = {}
        self.chat_thread = None  # èŠå¤©çº¿ç¨‹
        self.init_ui()
        self.init_llm_framework()
    
    def init_ui(self):
        """åˆå§‹åŒ–èŠå¤©ç•Œé¢"""
        layout = QVBoxLayout(self)
        layout.setContentsMargins(10, 10, 10, 10)
        layout.setSpacing(10)
        
        # æ ‡é¢˜
        title_label = QLabel("AIè®­ç»ƒåŠ©æ‰‹")
        title_label.setFont(QFont('å¾®è½¯é›…é»‘', 12, QFont.Bold))
        title_label.setAlignment(Qt.AlignCenter)
        layout.addWidget(title_label)
        
        # LLMé€‚é…å™¨é€‰æ‹©
        adapter_layout = QHBoxLayout()
        adapter_layout.addWidget(QLabel("AIæ¨¡å‹:"))
        self.adapter_combo = QComboBox()
        self.adapter_combo.addItems(["æ¨¡æ‹Ÿé€‚é…å™¨", "OpenAI GPT-4", "DeepSeek", "æœ¬åœ°Ollama"])
        self.adapter_combo.currentTextChanged.connect(self.switch_adapter)
        adapter_layout.addWidget(self.adapter_combo)
        adapter_layout.addStretch()
        layout.addLayout(adapter_layout)
        
        # èŠå¤©å†å²æ˜¾ç¤ºåŒºåŸŸ
        self.chat_display = QTextEdit()
        self.chat_display.setReadOnly(True)
        self.chat_display.setMinimumHeight(300)
        self.chat_display.setStyleSheet("""
            QTextEdit {
                background-color: #f8f9fa;
                border: 1px solid #dee2e6;
                border-radius: 8px;
                padding: 10px;
                font-family: 'Microsoft YaHei', Arial, sans-serif;
                font-size: 10pt;
            }
        """)
        layout.addWidget(self.chat_display)
        
        # å¿«æ·æ“ä½œæŒ‰é’®
        quick_actions_group = QGroupBox("å¿«æ·æ“ä½œ")
        quick_layout = QHBoxLayout()
        
        self.analyze_btn = QPushButton("ğŸ” åˆ†æå½“å‰è®­ç»ƒçŠ¶æ€")
        self.analyze_btn.clicked.connect(self.analyze_training)
        quick_layout.addWidget(self.analyze_btn)
        
        self.suggest_btn = QPushButton("ğŸ’¡ è·å–ä¼˜åŒ–å»ºè®®")
        self.suggest_btn.clicked.connect(self.get_suggestions)
        quick_layout.addWidget(self.suggest_btn)
        
        self.diagnose_btn = QPushButton("ğŸ”§ è¯Šæ–­è®­ç»ƒé—®é¢˜")
        self.diagnose_btn.clicked.connect(self.diagnose_issues)
        quick_layout.addWidget(self.diagnose_btn)
        
        self.compare_btn = QPushButton("ğŸ“Š æ¨¡å‹å¯¹æ¯”åˆ†æ")
        self.compare_btn.clicked.connect(self.compare_models)
        quick_layout.addWidget(self.compare_btn)
        
        quick_actions_group.setLayout(quick_layout)
        layout.addWidget(quick_actions_group)
        
        # æ¶ˆæ¯è¾“å…¥åŒºåŸŸ
        input_layout = QHBoxLayout()
        self.message_input = QLineEdit()
        self.message_input.setPlaceholderText("è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œä¾‹å¦‚ï¼šä¸ºä»€ä¹ˆéªŒè¯æŸå¤±åœ¨å¢åŠ ï¼Ÿ")
        self.message_input.returnPressed.connect(self.send_message)
        input_layout.addWidget(self.message_input)
        
        self.send_btn = QPushButton("å‘é€")
        self.send_btn.clicked.connect(self.send_message)
        input_layout.addWidget(self.send_btn)
        
        layout.addLayout(input_layout)
        
        # çŠ¶æ€æŒ‡ç¤ºå™¨
        self.status_label = QLabel("AIåŠ©æ‰‹å·²å°±ç»ª")
        self.status_label.setStyleSheet("color: #28a745; font-weight: bold;")
        layout.addWidget(self.status_label)
        
        # è¿›åº¦æ¡
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        layout.addWidget(self.progress_bar)
    
    def init_llm_framework(self):
        """åˆå§‹åŒ–LLMæ¡†æ¶"""
        if not LLM_AVAILABLE:
            self.add_system_message("âŒ LLMæ¨¡å—ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥å®‰è£…")
            self.set_ui_enabled(False)
            return
            
        try:
            # åŠ è½½AIè®¾ç½®é…ç½®
            ai_config = self.load_ai_config()
            
            # æ ¹æ®é…ç½®åˆå§‹åŒ–é€‚é…å™¨
            default_adapter = ai_config.get('general', {}).get('default_adapter', 'mock')
            
            if default_adapter == 'openai':
                openai_config = ai_config.get('openai', {})
                api_key = openai_config.get('api_key', '')
                if api_key:
                    self.llm_framework = LLMFramework('openai', openai_config)
                    self.adapter_combo.setCurrentText("OpenAI GPT-4")
                    self.add_system_message("âœ… AIåŠ©æ‰‹å·²å¯åŠ¨ï¼Œä½¿ç”¨OpenAI GPT-4")
                else:
                    # æ²¡æœ‰APIå¯†é’¥ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿé€‚é…å™¨
                    self.llm_framework = LLMFramework('mock')
                    self.adapter_combo.setCurrentText("æ¨¡æ‹Ÿé€‚é…å™¨")
                    self.add_system_message("âš ï¸ æœªé…ç½®OpenAI APIå¯†é’¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿé€‚é…å™¨")
            elif default_adapter == 'deepseek':
                deepseek_config = ai_config.get('deepseek', {})
                api_key = deepseek_config.get('api_key', '')
                if api_key:
                    self.llm_framework = LLMFramework('deepseek', deepseek_config)
                    self.adapter_combo.setCurrentText("DeepSeek")
                    self.add_system_message("âœ… AIåŠ©æ‰‹å·²å¯åŠ¨ï¼Œä½¿ç”¨DeepSeek")
                else:
                    # æ²¡æœ‰APIå¯†é’¥ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿé€‚é…å™¨
                    self.llm_framework = LLMFramework('mock')
                    self.adapter_combo.setCurrentText("æ¨¡æ‹Ÿé€‚é…å™¨")
                    self.add_system_message("âš ï¸ æœªé…ç½®DeepSeek APIå¯†é’¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿé€‚é…å™¨")
            elif default_adapter == 'local':
                ollama_config = ai_config.get('ollama', {})
                self.llm_framework = LLMFramework('local', ollama_config)
                self.adapter_combo.setCurrentText("æœ¬åœ°Ollama")
                self.add_system_message("âœ… AIåŠ©æ‰‹å·²å¯åŠ¨ï¼Œä½¿ç”¨æœ¬åœ°Ollama")
            else:
                # é»˜è®¤ä½¿ç”¨æ¨¡æ‹Ÿé€‚é…å™¨
                self.llm_framework = LLMFramework('mock')
                self.adapter_combo.setCurrentText("æ¨¡æ‹Ÿé€‚é…å™¨")
                self.add_system_message("âœ… AIåŠ©æ‰‹å·²å¯åŠ¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿé€‚é…å™¨")
            
            # å¯åŠ¨æ¡†æ¶
            self.llm_framework.start()
            self.status_label.setText("AIåŠ©æ‰‹å·²å°±ç»ª")
            self.status_label.setStyleSheet("color: #28a745; font-weight: bold;")
            
        except Exception as e:
            # åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ°æ¨¡æ‹Ÿé€‚é…å™¨
            try:
                self.llm_framework = LLMFramework('mock')
                self.llm_framework.start()
                self.adapter_combo.setCurrentText("æ¨¡æ‹Ÿé€‚é…å™¨")
                self.add_system_message(f"âš ï¸ é…ç½®çš„é€‚é…å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                self.add_system_message("âœ… å·²å›é€€åˆ°æ¨¡æ‹Ÿé€‚é…å™¨")
                self.status_label.setText("AIåŠ©æ‰‹å·²å°±ç»ª")
                self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
            except Exception as fallback_error:
                self.add_system_message(f"âŒ LLMæ¡†æ¶åˆå§‹åŒ–å¤±è´¥: {str(fallback_error)}")
                self.set_ui_enabled(False)
    
    def switch_adapter(self, adapter_name):
        """åˆ‡æ¢LLMé€‚é…å™¨"""
        if not self.llm_framework:
            return
            
        try:
            self.status_label.setText("æ­£åœ¨åˆ‡æ¢AIæ¨¡å‹...")
            self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
            
            # åŠ è½½AIè®¾ç½®é…ç½®
            ai_config = self.load_ai_config()
            
            if adapter_name == "æ¨¡æ‹Ÿé€‚é…å™¨":
                adapter_type = 'mock'
                adapter_config = {}
            elif adapter_name == "OpenAI GPT-4":
                adapter_type = 'openai'
                openai_config = ai_config.get('openai', {})
                adapter_config = {
                    'api_key': openai_config.get('api_key', ''),
                    'model': openai_config.get('model', 'gpt-4'),
                    'base_url': openai_config.get('base_url', '') or None,
                    'temperature': openai_config.get('temperature', 0.7),
                    'max_tokens': openai_config.get('max_tokens', 1000)
                }
                
                # æ£€æŸ¥APIå¯†é’¥
                if not adapter_config['api_key']:
                    self.add_system_message("âŒ æœªé…ç½®OpenAI APIå¯†é’¥ï¼Œè¯·åœ¨è®¾ç½®ä¸­é…ç½®")
                    self.status_label.setText("é…ç½®ç¼ºå¤±")
                    self.status_label.setStyleSheet("color: #dc3545; font-weight: bold;")
                    return
                    
            elif adapter_name == "DeepSeek":
                adapter_type = 'deepseek'
                deepseek_config = ai_config.get('deepseek', {})
                adapter_config = {
                    'api_key': deepseek_config.get('api_key', ''),
                    'model': deepseek_config.get('model', 'deepseek-coder'),
                    'base_url': deepseek_config.get('base_url', '') or None,
                    'temperature': deepseek_config.get('temperature', 0.7),
                    'max_tokens': deepseek_config.get('max_tokens', 1000)
                }
                if not adapter_config['api_key']:
                    self.add_system_message("âŒ æœªé…ç½®DeepSeek APIå¯†é’¥ï¼Œè¯·åœ¨è®¾ç½®ä¸­é…ç½®")
                    self.status_label.setText("é…ç½®ç¼ºå¤±")
                    self.status_label.setStyleSheet("color: #dc3545; font-weight: bold;")
                    return
                    
            elif adapter_name == "æœ¬åœ°Ollama":
                adapter_type = 'local'
                ollama_config = ai_config.get('ollama', {})
                adapter_config = {
                    'model_name': ollama_config.get('model', 'llama2'),
                    'base_url': ollama_config.get('base_url', 'http://localhost:11434'),
                    'temperature': ollama_config.get('temperature', 0.7),
                    'num_predict': ollama_config.get('num_predict', 1000),
                    'timeout': ollama_config.get('timeout', 120)
                }
            else:
                return
                
            self.llm_framework.switch_adapter(adapter_type, adapter_config)
            success = True
            
            if success:
                self.add_system_message(f"âœ… å·²åˆ‡æ¢åˆ°: {adapter_name}")
                if adapter_name == "OpenAI GPT-4":
                    model_name = adapter_config.get('model', 'gpt-4')
                    self.add_system_message(f"   ä½¿ç”¨æ¨¡å‹: {model_name}")
                elif adapter_name == "DeepSeek":
                    model_name = adapter_config.get('model', 'deepseek-coder')
                    self.add_system_message(f"   ä½¿ç”¨æ¨¡å‹: {model_name}")
                elif adapter_name == "æœ¬åœ°Ollama":
                    model_name = adapter_config.get('model_name', 'llama2')
                    base_url = adapter_config.get('base_url', 'localhost:11434')
                    self.add_system_message(f"   ä½¿ç”¨æ¨¡å‹: {model_name}")
                    self.add_system_message(f"   æœåŠ¡å™¨: {base_url}")
                    
                self.status_label.setText("AIåŠ©æ‰‹å·²å°±ç»ª")
                self.status_label.setStyleSheet("color: #28a745; font-weight: bold;")
            else:
                self.add_system_message(f"âŒ åˆ‡æ¢åˆ° {adapter_name} å¤±è´¥")
                self.status_label.setText("åˆ‡æ¢å¤±è´¥")
                self.status_label.setStyleSheet("color: #dc3545; font-weight: bold;")
                
        except Exception as e:
            self.add_system_message(f"âŒ åˆ‡æ¢é€‚é…å™¨æ—¶å‡ºé”™: {str(e)}")
            self.status_label.setText("åˆ‡æ¢å‡ºé”™")
            self.status_label.setStyleSheet("color: #dc3545; font-weight: bold;")
    
    def set_ui_enabled(self, enabled):
        """è®¾ç½®UIç»„ä»¶å¯ç”¨çŠ¶æ€"""
        self.analyze_btn.setEnabled(enabled)
        self.suggest_btn.setEnabled(enabled)
        self.diagnose_btn.setEnabled(enabled)
        self.compare_btn.setEnabled(enabled)
        self.send_btn.setEnabled(enabled)
        self.message_input.setEnabled(enabled)
    
    def add_system_message(self, message):
        """æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        formatted_message = f"<div style='color: #6c757d; font-size: 9pt; margin: 5px 0;'>[{timestamp}] {message}</div>"
        self.chat_display.append(formatted_message)
    
    def add_user_message(self, message):
        """æ·»åŠ ç”¨æˆ·æ¶ˆæ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        formatted_message = f"""
        <div style='margin: 10px 0; padding: 8px; background-color: #e3f2fd; color: #000000; border: 1px solid #2196f3; border-radius: 10px; text-align: right;'>
            <span style='color: #6c757d; font-size: 11px; font-weight: normal;'>æ‚¨ [{timestamp}]:</span><br>
            <span style='color: #000000; font-style: italic;'>{message}</span>
        </div>
        """
        self.chat_display.append(formatted_message)
    
    def add_ai_message(self, message):
        """æ·»åŠ AIå“åº”æ¶ˆæ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        formatted_message = f"""
        <div style='margin: 10px 0; padding: 8px; background-color: #f8f9fa; color: #000000; border: 1px solid #dee2e6; border-radius: 10px;'>
            <span style='color: #6c757d; font-size: 11px; font-weight: normal;'>AIåŠ©æ‰‹ [{timestamp}]:</span><br>
            <span style='color: #000000; font-weight: bold;'>{message}</span>
        </div>
        """
        self.chat_display.append(formatted_message)
        
        # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
        cursor = self.chat_display.textCursor()
        cursor.movePosition(QTextCursor.End)
        self.chat_display.setTextCursor(cursor)
    
    def send_message(self):
        """å‘é€ç”¨æˆ·æ¶ˆæ¯"""
        message = self.message_input.text().strip()
        if not message or not self.llm_framework:
            return
            
        # æ£€æŸ¥æ˜¯å¦æœ‰çº¿ç¨‹æ­£åœ¨è¿è¡Œ
        if self.chat_thread and self.chat_thread.isRunning():
            QMessageBox.information(self, "æç¤º", "AIæ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨ç­‰...")
            return
            
        self.message_input.clear()
        self.add_user_message(message)
        
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ç”¨äºèŠå¤©å†å²
        self._last_user_message = message
        
        # æ˜¾ç¤ºè¿›åº¦
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 0)  # ä¸ç¡®å®šè¿›åº¦
        self.status_label.setText("AIæ­£åœ¨æ€è€ƒ...")
        self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
        
        # ç¦ç”¨UIæ§ä»¶
        self.set_ui_enabled(False)
        
        # åˆ›å»ºå¹¶å¯åŠ¨èŠå¤©çº¿ç¨‹
        self.chat_thread = LLMChatThread(self.llm_framework)
        self.chat_thread.set_chat_task(message, self.training_context)
        
        # è¿æ¥ä¿¡å·
        self.chat_thread.chat_finished.connect(self.on_chat_finished)
        self.chat_thread.chat_error.connect(self.on_chat_error)
        
        # å¯åŠ¨çº¿ç¨‹
        self.chat_thread.start()
    
    def analyze_training(self):
        """åˆ†æå½“å‰è®­ç»ƒçŠ¶æ€"""
        if not self.llm_framework:
            return
            
        # æ£€æŸ¥æ˜¯å¦æœ‰çº¿ç¨‹æ­£åœ¨è¿è¡Œ
        if self.chat_thread and self.chat_thread.isRunning():
            QMessageBox.information(self, "æç¤º", "AIæ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨ç­‰...")
            return
        
        self.add_user_message("è¯·åˆ†æå½“å‰è®­ç»ƒçŠ¶æ€")
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 0)
        self.status_label.setText("æ­£åœ¨åˆ†æè®­ç»ƒçŠ¶æ€...")
        self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
        
        # ç¦ç”¨UIæ§ä»¶
        self.set_ui_enabled(False)
        
        # åˆ›å»ºå¹¶å¯åŠ¨åˆ†æçº¿ç¨‹
        self.chat_thread = LLMChatThread(self.llm_framework)
        self.chat_thread.set_analysis_task("analyze_training")
        
        # è¿æ¥ä¿¡å·
        self.chat_thread.analysis_finished.connect(self.on_analysis_finished)
        self.chat_thread.analysis_error.connect(self.on_analysis_error)
        
        # å¯åŠ¨çº¿ç¨‹
        self.chat_thread.start()
    
    def get_suggestions(self):
        """è·å–ä¼˜åŒ–å»ºè®®"""
        if not self.llm_framework:
            return
            
        # æ£€æŸ¥æ˜¯å¦æœ‰çº¿ç¨‹æ­£åœ¨è¿è¡Œ
        if self.chat_thread and self.chat_thread.isRunning():
            QMessageBox.information(self, "æç¤º", "AIæ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨ç­‰...")
            return
        
        self.add_user_message("è¯·ç»™å‡ºè¶…å‚æ•°ä¼˜åŒ–å»ºè®®")
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 0)
        self.status_label.setText("æ­£åœ¨ç”Ÿæˆä¼˜åŒ–å»ºè®®...")
        self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
        
        # ç¦ç”¨UIæ§ä»¶
        self.set_ui_enabled(False)
        
        # åˆ›å»ºå¹¶å¯åŠ¨åˆ†æçº¿ç¨‹
        self.chat_thread = LLMChatThread(self.llm_framework)
        self.chat_thread.set_analysis_task("get_suggestions")
        
        # è¿æ¥ä¿¡å·
        self.chat_thread.analysis_finished.connect(self.on_analysis_finished)
        self.chat_thread.analysis_error.connect(self.on_analysis_error)
        
        # å¯åŠ¨çº¿ç¨‹
        self.chat_thread.start()
    
    def diagnose_issues(self):
        """è¯Šæ–­è®­ç»ƒé—®é¢˜"""
        if not self.llm_framework:
            return
            
        # æ£€æŸ¥æ˜¯å¦æœ‰çº¿ç¨‹æ­£åœ¨è¿è¡Œ
        if self.chat_thread and self.chat_thread.isRunning():
            QMessageBox.information(self, "æç¤º", "AIæ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨ç­‰...")
            return
        
        self.add_user_message("è¯·è¯Šæ–­è®­ç»ƒä¸­çš„é—®é¢˜")
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 0)
        self.status_label.setText("æ­£åœ¨è¯Šæ–­é—®é¢˜...")
        self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
        
        # ç¦ç”¨UIæ§ä»¶
        self.set_ui_enabled(False)
        
        # åˆ›å»ºå¹¶å¯åŠ¨åˆ†æçº¿ç¨‹
        self.chat_thread = LLMChatThread(self.llm_framework)
        self.chat_thread.set_analysis_task("diagnose_issues")
        
        # è¿æ¥ä¿¡å·
        self.chat_thread.analysis_finished.connect(self.on_analysis_finished)
        self.chat_thread.analysis_error.connect(self.on_analysis_error)
        
        # å¯åŠ¨çº¿ç¨‹
        self.chat_thread.start()
    
    def compare_models(self):
        """æ¨¡å‹å¯¹æ¯”åˆ†æ - å¼•å¯¼ç”¨æˆ·åˆ°æ¨¡å‹è¯„ä¼°Tabè¿›è¡Œå®é™…è¯„ä¼°"""
        # æ˜¾ç¤ºå¼•å¯¼å¯¹è¯æ¡†
        reply = QMessageBox.question(
            self, "æ¨¡å‹å¯¹æ¯”åˆ†æ", 
            "æ¨¡å‹å¯¹æ¯”åˆ†æéœ€è¦ä½¿ç”¨çœŸå®çš„æµ‹è¯•æ•°æ®é›†å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚\n\n"
            "ç³»ç»Ÿå°†å¼•å¯¼æ‚¨åˆ‡æ¢åˆ°ã€Œæ¨¡å‹è¯„ä¼°ä¸å¯è§†åŒ–ã€æ ‡ç­¾é¡µè¿›è¡Œä»¥ä¸‹æ“ä½œï¼š\n"
            "1. é€‰æ‹©è¦å¯¹æ¯”çš„å¤šä¸ªæ¨¡å‹\n"
            "2. è®¾ç½®æµ‹è¯•é›†æ•°æ®ç›®å½•\n" 
            "3. æ‰§è¡Œæ¨¡å‹è¯„ä¼°è·å¾—çœŸå®æ€§èƒ½æ•°æ®\n"
            "4. ä½¿ç”¨AIåˆ†æè¯„ä¼°ç»“æœ\n\n"
            "æ˜¯å¦ç°åœ¨åˆ‡æ¢åˆ°æ¨¡å‹è¯„ä¼°é¡µé¢ï¼Ÿ",
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.Yes
        )
        
        if reply == QMessageBox.Yes:
            # åˆ‡æ¢åˆ°æ¨¡å‹è¯„ä¼°Tab
            self.switch_to_evaluation_tab()
            
            # åœ¨èŠå¤©ç•Œé¢æ˜¾ç¤ºå¼•å¯¼ä¿¡æ¯
            self.add_ai_message(
                "å·²ä¸ºæ‚¨åˆ‡æ¢åˆ°æ¨¡å‹è¯„ä¼°é¡µé¢ã€‚è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤è¿›è¡Œæ¨¡å‹å¯¹æ¯”åˆ†æï¼š\n\n"
                "ğŸ“‹ æ“ä½œæ­¥éª¤ï¼š\n"
                "1. é€‰æ‹©ã€Œæ¨¡å‹ç›®å½•ã€- åŒ…å«è¦å¯¹æ¯”çš„æ¨¡å‹æ–‡ä»¶\n"
                "2. é€‰æ‹©ã€Œæµ‹è¯•é›†ç›®å½•ã€- ç”¨äºè¯„ä¼°çš„æµ‹è¯•æ•°æ®\n"
                "3. è®¾ç½®ã€Œæ¨¡å‹ç±»å‹ã€å’Œã€Œæ¨¡å‹æ¶æ„ã€\n"
                "4. åœ¨æ¨¡å‹åˆ—è¡¨ä¸­é€‰æ‹©å¤šä¸ªè¦å¯¹æ¯”çš„æ¨¡å‹\n"
                "5. ç‚¹å‡»ã€Œå¯¹æ¯”é€‰ä¸­æ¨¡å‹ã€è¿›è¡Œè¯„ä¼°\n"
                "6. è¯„ä¼°å®Œæˆåï¼Œç‚¹å‡»ã€ŒAIç»“æœåˆ†æã€è·å¾—æ™ºèƒ½åˆ†ææŠ¥å‘Š\n\n"
                                 "ğŸ’¡ æç¤ºï¼šç¡®ä¿é€‰æ‹©çš„æ¨¡å‹ç±»å‹å’Œæ¶æ„ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼Œä»¥è·å¾—å‡†ç¡®çš„è¯„ä¼°ç»“æœã€‚"
             )
    
    def switch_to_evaluation_tab(self):
        """åˆ‡æ¢åˆ°æ¨¡å‹è¯„ä¼°Tab"""
        # é€šè¿‡parenté“¾æŸ¥æ‰¾ä¸»çª—å£
        main_window = None
        widget = self.parent()
        while widget and not hasattr(widget, 'tabs'):
            widget = widget.parent()
        main_window = widget
        
        if main_window and hasattr(main_window, 'tabs'):
            # è·å–ä¸»çª—å£çš„æ ‡ç­¾é¡µæ§ä»¶
            tab_widget = main_window.tabs
            
            # æŸ¥æ‰¾æ¨¡å‹è¯„ä¼°æ ‡ç­¾é¡µçš„ç´¢å¼•
            for i in range(tab_widget.count()):
                tab_text = tab_widget.tabText(i)
                if "è¯„ä¼°" in tab_text or "Evaluation" in tab_text:
                    tab_widget.setCurrentIndex(i)
                    break
        else:
            QMessageBox.warning(self, "é”™è¯¯", "æ— æ³•æ‰¾åˆ°ä¸»çª—å£ï¼Œæ— æ³•åˆ‡æ¢åˆ°æ¨¡å‹è¯„ä¼°é¡µé¢")
        
    def on_models_selected_for_comparison(self, models_data):
        """å¤„ç†ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹æ•°æ®"""
        if not models_data or len(models_data) < 2:
            QMessageBox.warning(self, "è­¦å‘Š", "éœ€è¦è‡³å°‘é€‰æ‹©2ä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”")
            return
            
        # æ˜¾ç¤ºç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹ä¿¡æ¯
        model_names = [model['model_name'] for model in models_data]
        user_message = f"è¯·å¯¹æ¯”åˆ†æä»¥ä¸‹ {len(models_data)} ä¸ªæ¨¡å‹ï¼š{', '.join(model_names)}"
        self.add_user_message(user_message)
        
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 0)
        self.status_label.setText("æ­£åœ¨å¯¹æ¯”æ¨¡å‹...")
        self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
        
        # ç¦ç”¨UIæ§ä»¶
        self.set_ui_enabled(False)
        
        # åˆ›å»ºå¹¶å¯åŠ¨åˆ†æçº¿ç¨‹ï¼Œä¼ å…¥çœŸå®çš„æ¨¡å‹æ•°æ®
        self.chat_thread = LLMChatThread(self.llm_framework)
        self.chat_thread.set_analysis_task("compare_models", models_data)
        
        # è¿æ¥ä¿¡å·
        self.chat_thread.analysis_finished.connect(self.on_analysis_finished)
        self.chat_thread.analysis_error.connect(self.on_analysis_error)
        
        # å¯åŠ¨çº¿ç¨‹
        self.chat_thread.start()
    
    def on_chat_finished(self, response_text):
        """èŠå¤©å®Œæˆå¤„ç†"""
        self.add_ai_message(response_text)
        
        # æ›´æ–°èŠå¤©å†å²
        if hasattr(self, '_last_user_message'):
            self.chat_history.append({
                'user': self._last_user_message,
                'ai': response_text,
                'timestamp': datetime.now().isoformat()
            })
        
        self._reset_ui_state()
    
    def on_chat_error(self, error_message):
        """èŠå¤©é”™è¯¯å¤„ç†"""
        self.add_ai_message(f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {error_message}")
        self._reset_ui_state()
    
    def start_ai_analysis_with_data(self, analysis_data):
        """ä½¿ç”¨çœŸå®è¯„ä¼°æ•°æ®å¯åŠ¨AIåˆ†æ"""
        if not self.llm_framework:
            return
            
        # æ£€æŸ¥æ˜¯å¦æœ‰çº¿ç¨‹æ­£åœ¨è¿è¡Œ
        if self.chat_thread and self.chat_thread.isRunning():
            QMessageBox.information(self, "æç¤º", "AIæ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨ç­‰...")
            return
        
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 0)
        self.status_label.setText("æ­£åœ¨åˆ†ææ¨¡å‹è¯„ä¼°ç»“æœ...")
        self.status_label.setStyleSheet("color: #ffc107; font-weight: bold;")
        
        # ç¦ç”¨UIæ§ä»¶
        self.set_ui_enabled(False)
        
        # åˆ›å»ºå¹¶å¯åŠ¨åˆ†æçº¿ç¨‹ï¼Œä¼ å…¥çœŸå®çš„è¯„ä¼°æ•°æ®
        self.chat_thread = LLMChatThread(self.llm_framework)
        self.chat_thread.set_analysis_task("compare_models", analysis_data)
        
        # è¿æ¥ä¿¡å·
        self.chat_thread.analysis_finished.connect(self.on_analysis_finished)
        self.chat_thread.analysis_error.connect(self.on_analysis_error)
        
        # å¯åŠ¨çº¿ç¨‹
        self.chat_thread.start()

    def on_analysis_finished(self, response_text):
        """åˆ†æå®Œæˆå¤„ç†"""
        self.add_ai_message(response_text)
        self._reset_ui_state()
    
    def on_analysis_error(self, error_message):
        """åˆ†æé”™è¯¯å¤„ç†"""
        self.add_ai_message(f"åˆ†ææ—¶å‡ºç°é”™è¯¯: {error_message}")
        self._reset_ui_state()
    
    def _reset_ui_state(self):
        """é‡ç½®UIçŠ¶æ€"""
        self.progress_bar.setVisible(False)
        self.status_label.setText("AIåŠ©æ‰‹å·²å°±ç»ª")
        self.status_label.setStyleSheet("color: #28a745; font-weight: bold;")
        
        # é‡æ–°å¯ç”¨UIæ§ä»¶
        self.set_ui_enabled(True)
    
    def update_training_context(self, context):
        """æ›´æ–°è®­ç»ƒä¸Šä¸‹æ–‡"""
        self.training_context.update(context)
    
    def load_ai_config(self):
        """åŠ è½½AIè®¾ç½®é…ç½®"""
        import json
        import os
        
        config_file = "setting/ai_config.json"
        default_config = {
            'openai': {
                'api_key': '',
                'base_url': '',
                'model': 'gpt-4',
                'temperature': 0.7,
                'max_tokens': 1000
            },
            'ollama': {
                'base_url': 'http://localhost:11434',
                'model': 'llama2',
                'temperature': 0.7,
                'num_predict': 1000
            },
            'deepseek': {
                'api_key': '',
                'base_url': '',
                'model': 'deepseek-coder',
                'temperature': 0.7,
                'max_tokens': 1000
            },
            'general': {
                'default_adapter': 'mock',
                'request_timeout': 60,
                'max_retries': 3,
                'enable_cache': True,
                'enable_streaming': False
            }
        }
        
        try:
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    # åˆå¹¶é»˜è®¤é…ç½®ï¼Œç¡®ä¿æ‰€æœ‰å¿…éœ€çš„é”®éƒ½å­˜åœ¨
                    for key in default_config:
                        if key not in config:
                            config[key] = default_config[key]
                        elif isinstance(default_config[key], dict):
                            for subkey in default_config[key]:
                                if subkey not in config[key]:
                                    config[key][subkey] = default_config[key][subkey]
                    return config
            else:
                return default_config
        except Exception as e:
            print(f"åŠ è½½AIé…ç½®å¤±è´¥: {str(e)}")
            return default_config


class AnalysisPanelWidget(QWidget):
    """æ™ºèƒ½åˆ†æé¢æ¿ç»„ä»¶"""
    
    status_updated = pyqtSignal(str)
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self.analysis_results = {}
        self.init_ui()
    
    def init_ui(self):
        """åˆå§‹åŒ–åˆ†æé¢æ¿ç•Œé¢"""
        layout = QVBoxLayout(self)
        layout.setContentsMargins(10, 10, 10, 10)
        layout.setSpacing(10)
        
        # æ ‡é¢˜
        title_label = QLabel("æ™ºèƒ½åˆ†æé¢æ¿")
        title_label.setFont(QFont('å¾®è½¯é›…é»‘', 12, QFont.Bold))
        title_label.setAlignment(Qt.AlignCenter)
        layout.addWidget(title_label)
        
        # åˆ›å»ºåˆ†æç»“æœæ ‡ç­¾é¡µ
        self.analysis_tabs = QTabWidget()
        
        # è®­ç»ƒçŠ¶æ€åˆ†æ
        self.training_status_widget = self.create_training_status_widget()
        self.analysis_tabs.addTab(self.training_status_widget, "è®­ç»ƒçŠ¶æ€")
        
        # æ€§èƒ½åˆ†æ
        self.performance_widget = self.create_performance_widget()
        self.analysis_tabs.addTab(self.performance_widget, "æ€§èƒ½åˆ†æ")
        
        # é—®é¢˜è¯Šæ–­
        self.diagnosis_widget = self.create_diagnosis_widget()
        self.analysis_tabs.addTab(self.diagnosis_widget, "é—®é¢˜è¯Šæ–­")
        
        # ä¼˜åŒ–å»ºè®®
        self.suggestions_widget = self.create_suggestions_widget()
        self.analysis_tabs.addTab(self.suggestions_widget, "ä¼˜åŒ–å»ºè®®")
        
        layout.addWidget(self.analysis_tabs)
        
        # åˆ·æ–°æŒ‰é’®
        refresh_btn = QPushButton("ğŸ”„ åˆ·æ–°åˆ†æ")
        refresh_btn.clicked.connect(self.refresh_analysis)
        layout.addWidget(refresh_btn)
    
    def create_training_status_widget(self):
        """åˆ›å»ºè®­ç»ƒçŠ¶æ€åˆ†æç»„ä»¶"""
        widget = QWidget()
        layout = QVBoxLayout(widget)
        
        self.status_display = QTextEdit()
        self.status_display.setReadOnly(True)
        self.status_display.setMaximumHeight(200)
        self.status_display.setPlaceholderText("è®­ç»ƒçŠ¶æ€åˆ†æå°†åœ¨è¿™é‡Œæ˜¾ç¤º...")
        layout.addWidget(self.status_display)
        
        return widget
    
    def create_performance_widget(self):
        """åˆ›å»ºæ€§èƒ½åˆ†æç»„ä»¶"""
        widget = QWidget()
        layout = QVBoxLayout(widget)
        
        self.performance_display = QTextEdit()
        self.performance_display.setReadOnly(True)
        self.performance_display.setMaximumHeight(200)
        self.performance_display.setPlaceholderText("æ€§èƒ½åˆ†æç»“æœå°†åœ¨è¿™é‡Œæ˜¾ç¤º...")
        layout.addWidget(self.performance_display)
        
        return widget
    
    def create_diagnosis_widget(self):
        """åˆ›å»ºé—®é¢˜è¯Šæ–­ç»„ä»¶"""
        widget = QWidget()
        layout = QVBoxLayout(widget)
        
        self.diagnosis_display = QTextEdit()
        self.diagnosis_display.setReadOnly(True)
        self.diagnosis_display.setMaximumHeight(200)
        self.diagnosis_display.setPlaceholderText("é—®é¢˜è¯Šæ–­ç»“æœå°†åœ¨è¿™é‡Œæ˜¾ç¤º...")
        layout.addWidget(self.diagnosis_display)
        
        return widget
    
    def create_suggestions_widget(self):
        """åˆ›å»ºä¼˜åŒ–å»ºè®®ç»„ä»¶"""
        widget = QWidget()
        layout = QVBoxLayout(widget)
        
        self.suggestions_display = QTextEdit()
        self.suggestions_display.setReadOnly(True)
        self.suggestions_display.setMaximumHeight(200)
        self.suggestions_display.setPlaceholderText("ä¼˜åŒ–å»ºè®®å°†åœ¨è¿™é‡Œæ˜¾ç¤º...")
        layout.addWidget(self.suggestions_display)
        
        return widget
    
    def refresh_analysis(self):
        """åˆ·æ–°åˆ†æç»“æœ"""
        self.status_updated.emit("æ­£åœ¨åˆ·æ–°åˆ†æç»“æœ...")
        
        # æ¨¡æ‹Ÿåˆ†æç»“æœ
        self.status_display.setText("âœ… è®­ç»ƒçŠ¶æ€æ­£å¸¸\nğŸ“ˆ æŸå¤±å‡½æ•°æ”¶æ•›è‰¯å¥½\nğŸ¯ å‡†ç¡®ç‡ç¨³æ­¥æå‡")
        self.performance_display.setText("ğŸš€ GPUåˆ©ç”¨ç‡: 85%\nâš¡ è®­ç»ƒé€Ÿåº¦: 1.2 samples/sec\nğŸ’¾ å†…å­˜ä½¿ç”¨: 6.2GB/8GB")
        self.diagnosis_display.setText("âš ï¸ æ£€æµ‹åˆ°è½»å¾®è¿‡æ‹Ÿåˆè¶‹åŠ¿\nğŸ’¡ å»ºè®®å¢åŠ æ•°æ®å¢å¼º\nğŸ”§ å¯è€ƒè™‘è°ƒæ•´å­¦ä¹ ç‡")
        self.suggestions_display.setText("1. é™ä½å­¦ä¹ ç‡è‡³0.0005\n2. å¢åŠ Dropoutè‡³0.3\n3. ä½¿ç”¨ä½™å¼¦é€€ç«è°ƒåº¦å™¨")
        
        self.status_updated.emit("åˆ†æç»“æœå·²æ›´æ–°")


class ModelFactoryTab(BaseTab):
    """æ¨¡å‹å·¥å‚æ ‡ç­¾é¡µ - é›†æˆLLMæ™ºèƒ½åˆ†æåŠŸèƒ½"""
    
    # å®šä¹‰ä¿¡å·
    llm_analysis_requested = pyqtSignal(dict)
    training_context_updated = pyqtSignal(dict)
    
    def __init__(self, parent=None, main_window=None):
        super().__init__(parent, main_window)
        self.main_window = main_window
        self.current_analysis = {}
        self.init_ui()
        
        # ä½¿ç”¨æ–°çš„æ™ºèƒ½é…ç½®ç³»ç»Ÿ
        config = self.get_config_from_manager()
        if config:
            self.apply_config(config)
    
    def init_ui(self):
        """åˆå§‹åŒ–ç”¨æˆ·ç•Œé¢"""
        # åˆ›å»ºä¸»å¸ƒå±€
        main_layout = QVBoxLayout(self.scroll_content)
        main_layout.setContentsMargins(10, 10, 10, 10)
        main_layout.setSpacing(10)
        

        
        # åˆ›å»ºæ°´å¹³åˆ†å‰²å™¨
        main_splitter = QSplitter(Qt.Horizontal)
        main_splitter.setChildrenCollapsible(False)
        
        # å·¦ä¾§ï¼šLLMèŠå¤©ç•Œé¢
        left_widget = QWidget()
        left_widget.setMinimumWidth(400)
        left_widget.setMaximumWidth(600)
        left_layout = QVBoxLayout(left_widget)
        left_layout.setContentsMargins(5, 5, 5, 5)
        
        self.chat_widget = LLMChatWidget()
        self.chat_widget.status_updated.connect(self.update_status)
        self.chat_widget.analysis_requested.connect(self.handle_analysis_request)
        left_layout.addWidget(self.chat_widget)
        
        main_splitter.addWidget(left_widget)
        
        # å³ä¾§ï¼šåˆ†æé¢æ¿å’Œç³»ç»ŸçŠ¶æ€
        right_widget = QWidget()
        right_layout = QVBoxLayout(right_widget)
        right_layout.setContentsMargins(5, 5, 5, 5)
        
        # åˆ†æé¢æ¿
        self.analysis_panel = AnalysisPanelWidget()
        self.analysis_panel.status_updated.connect(self.update_status)
        right_layout.addWidget(self.analysis_panel)
        
        # ç³»ç»ŸçŠ¶æ€é¢æ¿
        status_group = QGroupBox("ç³»ç»ŸçŠ¶æ€")
        status_layout = QVBoxLayout()
        
        self.system_status_display = QTextEdit()
        self.system_status_display.setReadOnly(True)
        self.system_status_display.setMaximumHeight(150)
        self.system_status_display.setPlaceholderText("ç³»ç»ŸçŠ¶æ€ä¿¡æ¯å°†åœ¨è¿™é‡Œæ˜¾ç¤º...")
        status_layout.addWidget(self.system_status_display)
        
        # ç³»ç»Ÿæ§åˆ¶æŒ‰é’®
        control_layout = QHBoxLayout()
        
        self.health_check_btn = QPushButton("ğŸ¥ å¥åº·æ£€æŸ¥")
        self.health_check_btn.clicked.connect(self.perform_health_check)
        control_layout.addWidget(self.health_check_btn)
        
        self.stats_btn = QPushButton("ğŸ“Š ç³»ç»Ÿç»Ÿè®¡")
        self.stats_btn.clicked.connect(self.show_system_stats)
        control_layout.addWidget(self.stats_btn)
        
        self.clear_btn = QPushButton("ğŸ—‘ï¸ æ¸…ç©ºå†å²")
        self.clear_btn.clicked.connect(self.clear_chat_history)
        control_layout.addWidget(self.clear_btn)
        
        status_layout.addLayout(control_layout)
        status_group.setLayout(status_layout)
        right_layout.addWidget(status_group)
        
        main_splitter.addWidget(right_widget)
        
        # è®¾ç½®åˆ†å‰²å™¨æ¯”ä¾‹ (å·¦ä¾§60%, å³ä¾§40%)
        main_splitter.setSizes([600, 400])
        
        main_layout.addWidget(main_splitter)
        
        # åˆå§‹åŒ–ç³»ç»ŸçŠ¶æ€
        self.update_system_status()
    
    def handle_analysis_request(self, request_data):
        """å¤„ç†åˆ†æè¯·æ±‚"""
        self.llm_analysis_requested.emit(request_data)
        self.update_status("æ­£åœ¨å¤„ç†åˆ†æè¯·æ±‚...")
    
    def update_training_context(self, context):
        """æ›´æ–°è®­ç»ƒä¸Šä¸‹æ–‡"""
        if hasattr(self, 'chat_widget'):
            self.chat_widget.update_training_context(context)
        self.training_context_updated.emit(context)
    
    def perform_health_check(self):
        """æ‰§è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥"""
        if not LLM_AVAILABLE:
            self.system_status_display.setText("âŒ LLMæ¨¡å—ä¸å¯ç”¨")
            return
            
        try:
            if hasattr(self.chat_widget, 'llm_framework') and self.chat_widget.llm_framework:
                health_status = self.chat_widget.llm_framework.get_system_health()
                self.system_status_display.setText(f"âœ… ç³»ç»Ÿå¥åº·çŠ¶æ€: {health_status}")
            else:
                self.system_status_display.setText("âš ï¸ LLMæ¡†æ¶æœªåˆå§‹åŒ–")
        except Exception as e:
            self.system_status_display.setText(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")
    
    def show_system_stats(self):
        """æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        if not LLM_AVAILABLE:
            self.system_status_display.setText("âŒ LLMæ¨¡å—ä¸å¯ç”¨")
            return
            
        try:
            if hasattr(self.chat_widget, 'llm_framework') and self.chat_widget.llm_framework:
                stats = self.chat_widget.llm_framework.get_framework_stats()
                stats_text = f"""
ğŸ“Š æ¡†æ¶ç»Ÿè®¡ä¿¡æ¯:
â€¢ æ€»è¯·æ±‚æ•°: {stats.get('total_requests', 0)}
â€¢ æˆåŠŸç‡: {stats.get('success_rate', 0):.1f}%
â€¢ å¹³å‡å“åº”æ—¶é—´: {stats.get('avg_response_time', 0):.2f}ç§’
â€¢ å½“å‰é€‚é…å™¨: {stats.get('current_adapter', 'Unknown')}
                """.strip()
                self.system_status_display.setText(stats_text)
            else:
                self.system_status_display.setText("âš ï¸ LLMæ¡†æ¶æœªåˆå§‹åŒ–")
        except Exception as e:
            self.system_status_display.setText(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
    
    def clear_chat_history(self):
        """æ¸…ç©ºèŠå¤©å†å²"""
        if hasattr(self.chat_widget, 'chat_display'):
            self.chat_widget.chat_display.clear()
            self.chat_widget.chat_history.clear()
            self.chat_widget.add_system_message("èŠå¤©å†å²å·²æ¸…ç©º")
    
    def update_system_status(self):
        """æ›´æ–°ç³»ç»ŸçŠ¶æ€æ˜¾ç¤º"""
        if LLM_AVAILABLE:
            status_text = """
ğŸŸ¢ AIæ¨¡å‹å·¥å‚å·²å¯åŠ¨
ğŸ“¡ æ•°æ®æµæœåŠ¡: å°±ç»ª
ğŸ¤– LLMæ¡†æ¶: å·²åŠ è½½
ğŸ’¬ èŠå¤©æœåŠ¡: æ­£å¸¸
ğŸ“Š åˆ†æå¼•æ“: å¾…å‘½
            """.strip()
        else:
            status_text = """
ğŸ”´ AIæ¨¡å‹å·¥å‚å¯åŠ¨å¼‚å¸¸
âŒ LLMæ¡†æ¶: æœªåŠ è½½
âš ï¸ è¯·æ£€æŸ¥ä¾èµ–å®‰è£…
            """.strip()
        
        self.system_status_display.setText(status_text)
    
    def on_training_started(self, training_info):
        """è®­ç»ƒå¼€å§‹æ—¶æ›´æ–°ä¸Šä¸‹æ–‡"""
        context = {
            'training_active': True,
            'model_type': training_info.get('model_type', 'unknown'),
            'dataset': training_info.get('dataset', 'unknown'),
            'start_time': datetime.now().isoformat()
        }
        self.update_training_context(context)
    
    def on_training_progress(self, metrics):
        """è®­ç»ƒè¿›åº¦æ›´æ–°æ—¶æ›´æ–°ä¸Šä¸‹æ–‡"""
        context = {
            'current_metrics': metrics,
            'last_update': datetime.now().isoformat()
        }
        self.update_training_context(context)
    
    def on_training_completed(self, results):
        """è®­ç»ƒå®Œæˆæ—¶æ›´æ–°ä¸Šä¸‹æ–‡"""
        context = {
            'training_active': False,
            'final_results': results,
            'completion_time': datetime.now().isoformat()
        }
        self.update_training_context(context)
    
    def reload_ai_config(self):
        """é‡æ–°åŠ è½½AIé…ç½®å¹¶æ›´æ–°é€‚é…å™¨"""
        if hasattr(self, 'chat_widget') and self.chat_widget:
            try:
                # é‡æ–°åˆå§‹åŒ–LLMæ¡†æ¶
                self.chat_widget.init_llm_framework()
                self.update_status("AIé…ç½®å·²é‡æ–°åŠ è½½")
            except Exception as e:
                self.update_status(f"é‡æ–°åŠ è½½AIé…ç½®å¤±è´¥: {str(e)}")
    
    def update_ai_adapter_from_settings(self, ai_config):
        """ä»è®¾ç½®æ›´æ–°AIé€‚é…å™¨é…ç½®"""
        if hasattr(self, 'chat_widget') and self.chat_widget and hasattr(self.chat_widget, 'llm_framework'):
            try:
                default_adapter = ai_config.get('general', {}).get('default_adapter', 'mock')
                
                # æ›´æ–°ä¸‹æ‹‰æ¡†æ˜¾ç¤º
                if default_adapter == 'openai':
                    self.chat_widget.adapter_combo.setCurrentText("OpenAI GPT-4")
                elif default_adapter == 'local':
                    self.chat_widget.adapter_combo.setCurrentText("æœ¬åœ°Ollama")
                elif default_adapter == 'deepseek':
                    self.chat_widget.adapter_combo.setCurrentText("DeepSeek")
                else:
                    self.chat_widget.adapter_combo.setCurrentText("æ¨¡æ‹Ÿé€‚é…å™¨")
                
                # åˆ‡æ¢é€‚é…å™¨
                self.chat_widget.switch_adapter(self.chat_widget.adapter_combo.currentText())
                
            except Exception as e:
                print(f"æ›´æ–°AIé€‚é…å™¨é…ç½®æ—¶å‡ºé”™: {str(e)}") 