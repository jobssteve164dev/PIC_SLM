"""
AIè®¾ç½®ç»„ä»¶ - ç”¨äºé…ç½®Ollamaå’ŒOpenAIçš„APIè®¾ç½®å’Œæ¨¡å‹é€‰æ‹©
"""

from PyQt5.QtWidgets import (QWidget, QVBoxLayout, QHBoxLayout, QGroupBox, 
                           QLabel, QLineEdit, QPushButton, QComboBox, QSpinBox,
                           QCheckBox, QTextEdit, QTabWidget, QMessageBox,
                           QFormLayout, QDoubleSpinBox, QProgressBar)
from PyQt5.QtCore import Qt, pyqtSignal, QThread, QTimer
from PyQt5.QtGui import QFont
import json
import os
import requests
from typing import Dict, List

# å¯¼å…¥LLMç›¸å…³æ¨¡å—
try:
    from src.llm.model_adapters import create_llm_adapter
    LLM_AVAILABLE = True
except ImportError:
    LLM_AVAILABLE = False


class OllamaTestThread(QThread):
    """Ollamaè¿æ¥æµ‹è¯•çº¿ç¨‹"""
    
    test_completed = pyqtSignal(bool, str, list)  # æˆåŠŸçŠ¶æ€, æ¶ˆæ¯, å¯ç”¨æ¨¡å‹åˆ—è¡¨
    
    def __init__(self, base_url):
        super().__init__()
        self.base_url = base_url
    
    def run(self):
        try:
            # æµ‹è¯•è¿æ¥
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            if response.status_code == 200:
                data = response.json()
                models = [model['name'] for model in data.get('models', [])]
                self.test_completed.emit(True, "è¿æ¥æˆåŠŸ", models)
            else:
                self.test_completed.emit(False, f"è¿æ¥å¤±è´¥: HTTP {response.status_code}", [])
        except requests.exceptions.ConnectionError:
            self.test_completed.emit(False, "è¿æ¥å¤±è´¥: æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡", [])
        except requests.exceptions.Timeout:
            self.test_completed.emit(False, "è¿æ¥å¤±è´¥: è¯·æ±‚è¶…æ—¶", [])
        except Exception as e:
            self.test_completed.emit(False, f"è¿æ¥å¤±è´¥: {str(e)}", [])


class OpenAITestThread(QThread):
    """OpenAI APIæµ‹è¯•çº¿ç¨‹"""
    
    test_completed = pyqtSignal(bool, str, list)  # æˆåŠŸçŠ¶æ€, æ¶ˆæ¯, å¯ç”¨æ¨¡å‹åˆ—è¡¨
    
    def __init__(self, api_key, base_url=None):
        super().__init__()
        self.api_key = api_key
        self.base_url = base_url or "https://api.openai.com/v1"
    
    def run(self):
        try:
            if not LLM_AVAILABLE:
                self.test_completed.emit(False, "LLMæ¨¡å—ä¸å¯ç”¨", [])
                return
            
            # é¦–å…ˆå°è¯•è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
            models = self._fetch_available_models()
            
            if models:
                # å¦‚æœæˆåŠŸè·å–æ¨¡å‹åˆ—è¡¨ï¼Œå†æµ‹è¯•ä¸€ä¸ªç®€å•è¯·æ±‚æ¥éªŒè¯APIå¯†é’¥
                adapter = create_llm_adapter('openai', 
                                           api_key=self.api_key, 
                                           base_url=self.base_url if self.base_url != "https://api.openai.com/v1" else None)
                
                # æµ‹è¯•ç®€å•è¯·æ±‚
                response = adapter.generate_response("Hello", context={'type': 'test'})
                
                if response and not response.startswith("APIè°ƒç”¨å¤±è´¥"):
                    self.test_completed.emit(True, f"APIå¯†é’¥éªŒè¯æˆåŠŸï¼Œå‘ç° {len(models)} ä¸ªå¯ç”¨æ¨¡å‹", models)
                else:
                    # APIå¯†é’¥æ— æ•ˆï¼Œä½†å¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜ï¼Œä»è¿”å›è·å–åˆ°çš„æ¨¡å‹åˆ—è¡¨
                    self.test_completed.emit(False, "APIå¯†é’¥éªŒè¯å¤±è´¥ï¼Œä½†å·²è·å–æ¨¡å‹åˆ—è¡¨", models)
            else:
                # æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ï¼Œä½¿ç”¨é¢„å®šä¹‰åˆ—è¡¨
                fallback_models = ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo", "gpt-3.5-turbo-16k"]
                self.test_completed.emit(False, "æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹", fallback_models)
                
        except Exception as e:
            # å‘ç”Ÿå¼‚å¸¸æ—¶ä½¿ç”¨é¢„å®šä¹‰åˆ—è¡¨
            fallback_models = ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo", "gpt-3.5-turbo-16k"]
            self.test_completed.emit(False, f"æµ‹è¯•å¤±è´¥: {str(e)}", fallback_models)
    
    def _fetch_available_models(self):
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            # è°ƒç”¨OpenAIçš„models APIç«¯ç‚¹
            response = requests.get(f"{self.base_url}/models", headers=headers, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                models = []
                
                # è§£ææ¨¡å‹æ•°æ®ï¼Œåªä¿ç•™èŠå¤©æ¨¡å‹
                for model in data.get('data', []):
                    model_id = model.get('id', '')
                    # è¿‡æ»¤å‡ºå¸¸ç”¨çš„èŠå¤©æ¨¡å‹
                    if any(keyword in model_id.lower() for keyword in ['gpt-4', 'gpt-3.5', 'chatgpt']):
                        models.append(model_id)
                
                # æŒ‰æ¨¡å‹åç§°æ’åº
                models.sort(key=lambda x: (
                    0 if 'gpt-4' in x else 1 if 'gpt-3.5' in x else 2,  # ä¼˜å…ˆçº§æ’åº
                    x  # å­—æ¯æ’åº
                ))
                
                return models
            else:
                print(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: HTTP {response.status_code}")
                return []
                
        except requests.exceptions.Timeout:
            print("è·å–æ¨¡å‹åˆ—è¡¨è¶…æ—¶")
            return []
        except Exception as e:
            print(f"è·å–æ¨¡å‹åˆ—è¡¨å¼‚å¸¸: {str(e)}")
            return []


class AISettingsWidget(QWidget):
    """AIè®¾ç½®ä¸»ç»„ä»¶"""
    
    settings_changed = pyqtSignal(dict)
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self.config_file = "setting/ai_config.json"
        self.current_config = {}
        self.ollama_test_thread = None
        self.openai_test_thread = None
        
        self.init_ui()
        self.load_config()
        self._connect_signals()
    
    def init_ui(self):
        """åˆå§‹åŒ–ç”¨æˆ·ç•Œé¢"""
        layout = QVBoxLayout(self)
        layout.setContentsMargins(10, 10, 10, 10)
        layout.setSpacing(10)
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        self.tabs = QTabWidget()
        
        # OpenAIè®¾ç½®æ ‡ç­¾é¡µ
        self.openai_tab = self.create_openai_tab()
        self.tabs.addTab(self.openai_tab, "OpenAIè®¾ç½®")
        
        # Ollamaè®¾ç½®æ ‡ç­¾é¡µ
        self.ollama_tab = self.create_ollama_tab()
        self.tabs.addTab(self.ollama_tab, "Ollamaè®¾ç½®")
        
        # é€šç”¨è®¾ç½®æ ‡ç­¾é¡µ
        self.general_tab = self.create_general_tab()
        self.tabs.addTab(self.general_tab, "é€šç”¨è®¾ç½®")
        
        layout.addWidget(self.tabs)
        
        # æ·»åŠ é‡ç½®æŒ‰é’®ï¼Œå¹¶ä½¿å…¶åœ¨å·¦ä¾§
        button_layout = QHBoxLayout()
        self.reset_btn = QPushButton("ğŸ”„ é‡ç½®é»˜è®¤")
        self.reset_btn.clicked.connect(self.reset_to_defaults)
        button_layout.addWidget(self.reset_btn)
        button_layout.addStretch() # å°†æŒ‰é’®æ¨åˆ°å·¦ä¾§
        layout.addLayout(button_layout)

        # åœ¨ä¸»å¸ƒå±€åº•éƒ¨æ·»åŠ ä¸€ä¸ªå¼¹æ€§ç©ºé—´ï¼Œå°†æ‰€æœ‰å†…å®¹å‘ä¸Šæ¨
        layout.addStretch()
    
    def create_openai_tab(self):
        """åˆ›å»ºOpenAIè®¾ç½®æ ‡ç­¾é¡µ"""
        widget = QWidget()
        layout = QVBoxLayout(widget)
        
        # APIé…ç½®ç»„
        api_group = QGroupBox("APIé…ç½®")
        api_layout = QFormLayout()
        
        # APIå¯†é’¥ï¼ˆå¸¦æ˜¾ç¤º/éšè—æŒ‰é’®ï¼‰
        key_layout = QHBoxLayout()
        self.openai_api_key = QLineEdit()
        self.openai_api_key.setEchoMode(QLineEdit.Password)
        self.openai_api_key.setPlaceholderText("è¾“å…¥æ‚¨çš„OpenAI APIå¯†é’¥")
        key_layout.addWidget(self.openai_api_key)
        
        self.show_key_btn = QPushButton("ğŸ‘")
        self.show_key_btn.setMaximumWidth(30)
        self.show_key_btn.clicked.connect(self.toggle_api_key_visibility)
        key_layout.addWidget(self.show_key_btn)
        api_layout.addRow("APIå¯†é’¥:", key_layout)
        
        # è‡ªå®šä¹‰APIåŸºç¡€URL
        self.openai_base_url = QLineEdit()
        self.openai_base_url.setPlaceholderText("https://api.openai.com/v1 (é»˜è®¤)")
        api_layout.addRow("åŸºç¡€URL:", self.openai_base_url)
        
        # è¿æ¥æµ‹è¯•
        test_layout = QHBoxLayout()
        self.openai_test_btn = QPushButton("ğŸ” æµ‹è¯•è¿æ¥")
        self.openai_test_btn.clicked.connect(self.test_openai_connection)
        test_layout.addWidget(self.openai_test_btn)
        
        self.openai_test_progress = QProgressBar()
        self.openai_test_progress.setVisible(False)
        test_layout.addWidget(self.openai_test_progress)
        
        test_layout.addStretch()
        api_layout.addRow("è¿æ¥æµ‹è¯•:", test_layout)
        
        # æµ‹è¯•ç»“æœ
        self.openai_test_result = QLabel("å°šæœªæµ‹è¯•")
        self.openai_test_result.setStyleSheet("color: #6c757d;")
        api_layout.addRow("æµ‹è¯•ç»“æœ:", self.openai_test_result)
        
        api_group.setLayout(api_layout)
        layout.addWidget(api_group)
        
        # æ¨¡å‹é…ç½®ç»„
        model_group = QGroupBox("æ¨¡å‹é…ç½®")
        model_layout = QFormLayout()
        
        # æ¨¡å‹é€‰æ‹©ï¼ˆå¯ç¼–è¾‘ä¸‹æ‹‰æ¡†ï¼‰
        model_select_layout = QHBoxLayout()
        self.openai_model = QComboBox()
        self.openai_model.setEditable(True)  # å…è®¸ç”¨æˆ·è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹åç§°
        self.openai_model.setPlaceholderText("è¯·å…ˆæµ‹è¯•è¿æ¥ä»¥è·å–å¯ç”¨æ¨¡å‹ï¼Œæˆ–æ‰‹åŠ¨è¾“å…¥æ¨¡å‹åç§°")
        # åˆå§‹ä¸ºç©ºï¼Œé€šè¿‡æµ‹è¯•è¿æ¥è·å–æ¨¡å‹åˆ—è¡¨
        model_select_layout.addWidget(self.openai_model)
        
        # åˆ·æ–°æ¨¡å‹åˆ—è¡¨æŒ‰é’®
        self.refresh_models_btn = QPushButton("ğŸ”„")
        self.refresh_models_btn.setMaximumWidth(30)
        self.refresh_models_btn.setToolTip("åˆ·æ–°å¯ç”¨æ¨¡å‹åˆ—è¡¨")
        self.refresh_models_btn.clicked.connect(self.refresh_model_list)
        model_select_layout.addWidget(self.refresh_models_btn)
        
        model_layout.addRow("æ¨¡å‹åç§°:", model_select_layout)
        
        # æ·»åŠ æ¨¡å‹è¯´æ˜
        model_info = QLabel("ğŸ’¡ æç¤ºï¼šæµ‹è¯•è¿æ¥æˆåŠŸåå°†è‡ªåŠ¨è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼Œæ‚¨ä¹Ÿå¯ä»¥æ‰‹åŠ¨è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹åç§°")
        model_info.setStyleSheet("color: #6c757d; font-size: 12px;")
        model_info.setWordWrap(True)
        model_layout.addRow("", model_info)
        
        # å‚æ•°è®¾ç½®
        self.openai_temperature = QDoubleSpinBox()
        self.openai_temperature.setRange(0.0, 2.0)
        self.openai_temperature.setSingleStep(0.1)
        self.openai_temperature.setValue(0.7)
        model_layout.addRow("æ¸©åº¦ (Temperature):", self.openai_temperature)
        
        self.openai_max_tokens = QSpinBox()
        self.openai_max_tokens.setRange(1, 8192)
        self.openai_max_tokens.setValue(1000)
        model_layout.addRow("æœ€å¤§ä»¤ç‰Œæ•°:", self.openai_max_tokens)
        
        model_group.setLayout(model_layout)
        layout.addWidget(model_group)
        
        # layout.addStretch() # ç§»é™¤æ­¤è¡Œä»¥æ¶ˆé™¤ç©ºç™½
        return widget
    
    def create_ollama_tab(self):
        """åˆ›å»ºOllamaè®¾ç½®æ ‡ç­¾é¡µ"""
        widget = QWidget()
        layout = QVBoxLayout(widget)
        
        # æœåŠ¡å™¨é…ç½®ç»„
        server_group = QGroupBox("æœåŠ¡å™¨é…ç½®")
        server_layout = QFormLayout()
        
        # æœåŠ¡å™¨åœ°å€
        self.ollama_base_url = QLineEdit()
        self.ollama_base_url.setText("http://localhost:11434")
        self.ollama_base_url.setPlaceholderText("http://localhost:11434")
        server_layout.addRow("æœåŠ¡å™¨åœ°å€:", self.ollama_base_url)
        
        # è¿æ¥æµ‹è¯•
        test_layout = QHBoxLayout()
        self.ollama_test_btn = QPushButton("ğŸ” æµ‹è¯•è¿æ¥")
        self.ollama_test_btn.clicked.connect(self.test_ollama_connection)
        test_layout.addWidget(self.ollama_test_btn)
        
        self.ollama_test_progress = QProgressBar()
        self.ollama_test_progress.setVisible(False)
        test_layout.addWidget(self.ollama_test_progress)
        
        test_layout.addStretch()
        server_layout.addRow("è¿æ¥æµ‹è¯•:", test_layout)
        
        # æµ‹è¯•ç»“æœ
        self.ollama_test_result = QLabel("å°šæœªæµ‹è¯•")
        self.ollama_test_result.setStyleSheet("color: #6c757d;")
        server_layout.addRow("æµ‹è¯•ç»“æœ:", self.ollama_test_result)
        
        server_group.setLayout(server_layout)
        layout.addWidget(server_group)
        
        # æ¨¡å‹é…ç½®ç»„
        model_group = QGroupBox("æ¨¡å‹é…ç½®")
        model_layout = QFormLayout()
        
        # æ¨¡å‹é€‰æ‹©ï¼ˆå¸¦åˆ·æ–°æŒ‰é’®ï¼‰
        refresh_layout = QHBoxLayout()
        self.ollama_models = QComboBox()
        self.ollama_models.addItems(["llama2", "llama2:13b", "codellama", "mistral"])
        self.ollama_models.setEditable(True)
        refresh_layout.addWidget(self.ollama_models)
        
        self.refresh_models_btn = QPushButton("ğŸ”„")
        self.refresh_models_btn.setMaximumWidth(30)
        self.refresh_models_btn.clicked.connect(self.refresh_ollama_models)
        refresh_layout.addWidget(self.refresh_models_btn)
        model_layout.addRow("é€‰æ‹©æ¨¡å‹:", refresh_layout)
        
        # å‚æ•°è®¾ç½®
        self.ollama_temperature = QDoubleSpinBox()
        self.ollama_temperature.setRange(0.0, 2.0)
        self.ollama_temperature.setSingleStep(0.1)
        self.ollama_temperature.setValue(0.7)
        model_layout.addRow("æ¸©åº¦ (Temperature):", self.ollama_temperature)
        
        self.ollama_num_predict = QSpinBox()
        self.ollama_num_predict.setRange(1, 4096)
        self.ollama_num_predict.setValue(1000)
        model_layout.addRow("é¢„æµ‹ä»¤ç‰Œæ•°:", self.ollama_num_predict)
        
        # æ·»åŠ è¶…æ—¶è®¾ç½®
        self.ollama_timeout = QSpinBox()
        self.ollama_timeout.setRange(30, 600)  # 30ç§’åˆ°10åˆ†é’Ÿ
        self.ollama_timeout.setValue(120)  # é»˜è®¤2åˆ†é’Ÿ
        self.ollama_timeout.setSuffix(" ç§’")
        model_layout.addRow("è¯·æ±‚è¶…æ—¶:", self.ollama_timeout)
        
        # æ·»åŠ è¶…æ—¶è¯´æ˜
        timeout_info = QLabel("ğŸ’¡ æç¤ºï¼šå¤§æ¨¡å‹å“åº”å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå»ºè®®è®¾ç½®2-5åˆ†é’Ÿè¶…æ—¶")
        timeout_info.setStyleSheet("color: #6c757d; font-size: 12px;")
        timeout_info.setWordWrap(True)
        model_layout.addRow("", timeout_info)
        
        model_group.setLayout(model_layout)
        layout.addWidget(model_group)
        
        # layout.addStretch() # ç§»é™¤æ­¤è¡Œä»¥æ¶ˆé™¤ç©ºç™½
        return widget
    
    def create_general_tab(self):
        """åˆ›å»ºé€šç”¨è®¾ç½®æ ‡ç­¾é¡µ"""
        widget = QWidget()
        layout = QVBoxLayout(widget)
        
        # é»˜è®¤é€‚é…å™¨ç»„
        adapter_group = QGroupBox("é»˜è®¤é€‚é…å™¨")
        adapter_layout = QFormLayout()
        
        self.default_adapter = QComboBox()
        self.default_adapter.addItems(["æ¨¡æ‹Ÿé€‚é…å™¨", "OpenAI", "Ollama"])
        adapter_layout.addRow("é»˜è®¤ä½¿ç”¨:", self.default_adapter)
        
        adapter_group.setLayout(adapter_layout)
        layout.addWidget(adapter_group)
        
        # é«˜çº§è®¾ç½®ç»„
        advanced_group = QGroupBox("é«˜çº§è®¾ç½®")
        advanced_layout = QFormLayout()
        
        # è¯·æ±‚è¶…æ—¶
        self.request_timeout = QSpinBox()
        self.request_timeout.setRange(5, 300)
        self.request_timeout.setValue(60)
        self.request_timeout.setSuffix(" ç§’")
        advanced_layout.addRow("è¯·æ±‚è¶…æ—¶:", self.request_timeout)
        
        # é‡è¯•æ¬¡æ•°
        self.max_retries = QSpinBox()
        self.max_retries.setRange(0, 10)
        self.max_retries.setValue(3)
        advanced_layout.addRow("æœ€å¤§é‡è¯•æ¬¡æ•°:", self.max_retries)
        
        # å¯ç”¨ç¼“å­˜
        self.enable_cache = QCheckBox("å¯ç”¨å“åº”ç¼“å­˜")
        self.enable_cache.setChecked(True)
        advanced_layout.addRow("ç¼“å­˜è®¾ç½®:", self.enable_cache)
        
        # å¯ç”¨æµå¼å“åº”
        self.enable_streaming = QCheckBox("å¯ç”¨æµå¼å“åº”")
        self.enable_streaming.setChecked(False)
        advanced_layout.addRow("æµå¼å¤„ç†:", self.enable_streaming)
        
        advanced_group.setLayout(advanced_layout)
        layout.addWidget(advanced_group)
        
        # layout.addStretch() # ç§»é™¤æ­¤è¡Œä»¥æ¶ˆé™¤ç©ºç™½
        return widget
    
    def refresh_model_list(self):
        """åˆ·æ–°OpenAIæ¨¡å‹åˆ—è¡¨"""
        api_key = self.openai_api_key.text().strip()
        if not api_key:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆè¾“å…¥APIå¯†é’¥")
            return
        
        # ç¦ç”¨åˆ·æ–°æŒ‰é’®ï¼Œæ˜¾ç¤ºåŠ è½½çŠ¶æ€
        self.refresh_models_btn.setEnabled(False)
        self.refresh_models_btn.setText("â³")
        
        base_url = self.openai_base_url.text().strip() or None
        self.model_refresh_thread = OpenAITestThread(api_key, base_url)
        self.model_refresh_thread.test_completed.connect(self.on_model_refresh_completed)
        self.model_refresh_thread.start()
    
    def on_model_refresh_completed(self, success, message, models):
        """æ¨¡å‹åˆ—è¡¨åˆ·æ–°å®Œæˆå›è°ƒ"""
        self.refresh_models_btn.setEnabled(True)
        self.refresh_models_btn.setText("ğŸ”„")
        
        if models:
            # ä¿å­˜å½“å‰é€‰ä¸­çš„æ¨¡å‹
            current_model = self.openai_model.currentText()
            
            # æ›´æ–°æ¨¡å‹åˆ—è¡¨
            self.openai_model.clear()
            self.openai_model.addItems(models)
            
            # æ¢å¤ä¹‹å‰é€‰ä¸­çš„æ¨¡å‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if current_model and current_model in models:
                self.openai_model.setCurrentText(current_model)
            elif models:
                # å¦‚æœä¹‹å‰çš„æ¨¡å‹ä¸å­˜åœ¨ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ª
                self.openai_model.setCurrentText(models[0])
            
            if success:
                QMessageBox.information(self, "æˆåŠŸ", f"å·²è·å– {len(models)} ä¸ªå¯ç”¨æ¨¡å‹")
            else:
                QMessageBox.warning(self, "éƒ¨åˆ†æˆåŠŸ", f"{message}\nå·²æ›´æ–°æ¨¡å‹åˆ—è¡¨")
        else:
            QMessageBox.warning(self, "å¤±è´¥", f"æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨: {message}")

    def toggle_api_key_visibility(self):
        """åˆ‡æ¢APIå¯†é’¥æ˜¾ç¤º/éšè—"""
        if self.openai_api_key.echoMode() == QLineEdit.Password:
            self.openai_api_key.setEchoMode(QLineEdit.Normal)
            self.show_key_btn.setText("ğŸ™ˆ")
        else:
            self.openai_api_key.setEchoMode(QLineEdit.Password)
            self.show_key_btn.setText("ğŸ‘")
    
    def test_openai_connection(self):
        """æµ‹è¯•OpenAIè¿æ¥"""
        api_key = self.openai_api_key.text().strip()
        if not api_key:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆè¾“å…¥APIå¯†é’¥")
            return
        
        self.openai_test_btn.setEnabled(False)
        self.openai_test_progress.setVisible(True)
        self.openai_test_progress.setRange(0, 0)
        self.openai_test_result.setText("æ­£åœ¨æµ‹è¯•...")
        self.openai_test_result.setStyleSheet("color: #ffc107;")
        
        base_url = self.openai_base_url.text().strip() or None
        self.openai_test_thread = OpenAITestThread(api_key, base_url)
        self.openai_test_thread.test_completed.connect(self.on_openai_test_completed)
        self.openai_test_thread.start()
    
    def on_openai_test_completed(self, success, message, models):
        """OpenAIæµ‹è¯•å®Œæˆå›è°ƒ"""
        self.openai_test_btn.setEnabled(True)
        self.openai_test_progress.setVisible(False)
        
        if success:
            self.openai_test_result.setText(f"âœ… {message}")
            self.openai_test_result.setStyleSheet("color: #28a745;")
        else:
            self.openai_test_result.setText(f"âŒ {message}")
            self.openai_test_result.setStyleSheet("color: #dc3545;")
        
        # æ›´æ–°æ¨¡å‹åˆ—è¡¨ï¼ˆæ— è®ºæµ‹è¯•æˆåŠŸä¸å¦ï¼Œåªè¦æœ‰æ¨¡å‹åˆ—è¡¨å°±æ›´æ–°ï¼‰
        if models:
            current_model = self.openai_model.currentText()
            self.openai_model.clear()
            self.openai_model.addItems(models)
            
            # æ¢å¤ä¹‹å‰é€‰ä¸­çš„æ¨¡å‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if current_model and current_model in models:
                self.openai_model.setCurrentText(current_model)
            elif models:
                # å¦‚æœä¹‹å‰çš„æ¨¡å‹ä¸å­˜åœ¨ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ª
                self.openai_model.setCurrentText(models[0])
    
    def test_ollama_connection(self):
        """æµ‹è¯•Ollamaè¿æ¥"""
        base_url = self.ollama_base_url.text().strip()
        if not base_url:
            base_url = "http://localhost:11434"
        
        self.ollama_test_btn.setEnabled(False)
        self.ollama_test_progress.setVisible(True)
        self.ollama_test_progress.setRange(0, 0)
        self.ollama_test_result.setText("æ­£åœ¨æµ‹è¯•...")
        self.ollama_test_result.setStyleSheet("color: #ffc107;")
        
        self.ollama_test_thread = OllamaTestThread(base_url)
        self.ollama_test_thread.test_completed.connect(self.on_ollama_test_completed)
        self.ollama_test_thread.start()
    
    def on_ollama_test_completed(self, success, message, models):
        """Ollamaæµ‹è¯•å®Œæˆå›è°ƒ"""
        self.ollama_test_btn.setEnabled(True)
        self.ollama_test_progress.setVisible(False)
        
        if success:
            self.ollama_test_result.setText(f"âœ… {message}")
            self.ollama_test_result.setStyleSheet("color: #28a745;")
            
            # æ›´æ–°æ¨¡å‹åˆ—è¡¨
            if models:
                current_model = self.ollama_models.currentText()
                self.ollama_models.clear()
                self.ollama_models.addItems(models)
                if current_model in models:
                    self.ollama_models.setCurrentText(current_model)
        else:
            self.ollama_test_result.setText(f"âŒ {message}")
            self.ollama_test_result.setStyleSheet("color: #dc3545;")
    
    def refresh_ollama_models(self):
        """åˆ·æ–°Ollamaæ¨¡å‹åˆ—è¡¨"""
        self.test_ollama_connection()
    
    def load_config(self):
        """åŠ è½½é…ç½®"""
        try:
            if os.path.exists(self.config_file):
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    self.current_config = json.load(f)
                    self.apply_config_to_ui()
            else:
                self.reset_to_defaults()
        except Exception as e:
            print(f"åŠ è½½AIé…ç½®å¤±è´¥: {str(e)}")
            self.reset_to_defaults()
    
    def apply_config_to_ui(self):
        """å°†é…ç½®åº”ç”¨åˆ°UI"""
        config = self.current_config
        
        # OpenAIè®¾ç½®
        openai_config = config.get('openai', {})
        self.openai_api_key.setText(openai_config.get('api_key', ''))
        self.openai_base_url.setText(openai_config.get('base_url', ''))
        
        # å¤„ç†æ¨¡å‹é…ç½® - å¦‚æœæœ‰é…ç½®çš„æ¨¡å‹ï¼Œè®¾ç½®åˆ°ä¸‹æ‹‰æ¡†ä¸­
        configured_model = openai_config.get('model', '')
        if configured_model:
            # å¦‚æœä¸‹æ‹‰æ¡†ä¸­æ²¡æœ‰è¿™ä¸ªæ¨¡å‹ï¼Œå…ˆæ·»åŠ å®ƒ
            if self.openai_model.findText(configured_model) == -1:
                self.openai_model.addItem(configured_model)
            self.openai_model.setCurrentText(configured_model)
        
        self.openai_temperature.setValue(openai_config.get('temperature', 0.7))
        self.openai_max_tokens.setValue(openai_config.get('max_tokens', 1000))
        
        # Ollamaè®¾ç½®
        ollama_config = config.get('ollama', {})
        self.ollama_base_url.setText(ollama_config.get('base_url', 'http://localhost:11434'))
        self.ollama_models.setCurrentText(ollama_config.get('model', 'llama2'))
        self.ollama_temperature.setValue(ollama_config.get('temperature', 0.7))
        self.ollama_num_predict.setValue(ollama_config.get('num_predict', 1000))
        self.ollama_timeout.setValue(ollama_config.get('timeout', 120))
        
        # é€šç”¨è®¾ç½®
        general_config = config.get('general', {})
        default_adapter = general_config.get('default_adapter', 'æ¨¡æ‹Ÿé€‚é…å™¨')
        if default_adapter == 'openai':
            default_adapter = 'OpenAI'
        elif default_adapter == 'local':
            default_adapter = 'Ollama'
        self.default_adapter.setCurrentText(default_adapter)
        self.request_timeout.setValue(general_config.get('request_timeout', 60))
        self.max_retries.setValue(general_config.get('max_retries', 3))
        self.enable_cache.setChecked(general_config.get('enable_cache', True))
        self.enable_streaming.setChecked(general_config.get('enable_streaming', False))
    
    def _save_config_to_file(self):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶ï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œç”±è®¾ç½®Tabè°ƒç”¨ï¼‰"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.config_file), exist_ok=True)
            
            # ä½¿ç”¨å½“å‰é…ç½®ï¼ˆå·²é€šè¿‡update_settings_previewæ›´æ–°ï¼‰
            config = self.current_config
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            return True
            
        except Exception as e:
            print(f"ä¿å­˜AIé…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
            return False
    
    def reset_to_defaults(self):
        """é‡ç½®ä¸ºé»˜è®¤è®¾ç½®"""
        # é‡ç½®UIåˆ°é»˜è®¤å€¼
        self.openai_api_key.clear()
        self.openai_base_url.clear()
        self.openai_model.clear()  # æ¸…ç©ºæ¨¡å‹é€‰æ‹©ï¼Œä¸è®¾ç½®é»˜è®¤å€¼
        self.openai_temperature.setValue(0.7)
        self.openai_max_tokens.setValue(1000)
        
        self.ollama_base_url.setText('http://localhost:11434')
        self.ollama_models.setCurrentText('llama2')
        self.ollama_temperature.setValue(0.7)
        self.ollama_num_predict.setValue(1000)
        self.ollama_timeout.setValue(120)
        
        self.default_adapter.setCurrentText('æ¨¡æ‹Ÿé€‚é…å™¨')
        self.request_timeout.setValue(60)
        self.max_retries.setValue(3)
        self.enable_cache.setChecked(True)
        self.enable_streaming.setChecked(False)
        
        # é‡ç½®æµ‹è¯•ç»“æœ
        self.openai_test_result.setText("å°šæœªæµ‹è¯•")
        self.openai_test_result.setStyleSheet("color: #6c757d;")
        self.ollama_test_result.setText("å°šæœªæµ‹è¯•")
        self.ollama_test_result.setStyleSheet("color: #6c757d;")
    
    def get_config(self):
        """è·å–å½“å‰é…ç½®"""
        return self.current_config.copy()
    
    def _connect_signals(self):
        """è¿æ¥æ‰€æœ‰æ§ä»¶çš„ä¿¡å·"""
        # OpenAIè®¾ç½®ä¿¡å·
        self.openai_api_key.textChanged.connect(self.update_settings_preview)
        self.openai_base_url.textChanged.connect(self.update_settings_preview)
        self.openai_model.currentTextChanged.connect(self.update_settings_preview)
        self.openai_temperature.valueChanged.connect(self.update_settings_preview)
        self.openai_max_tokens.valueChanged.connect(self.update_settings_preview)
        
        # Ollamaè®¾ç½®ä¿¡å·
        self.ollama_base_url.textChanged.connect(self.update_settings_preview)
        self.ollama_models.currentTextChanged.connect(self.update_settings_preview)
        self.ollama_temperature.valueChanged.connect(self.update_settings_preview)
        self.ollama_num_predict.valueChanged.connect(self.update_settings_preview)
        self.ollama_timeout.valueChanged.connect(self.update_settings_preview)
        
        # é€šç”¨è®¾ç½®ä¿¡å·
        self.default_adapter.currentTextChanged.connect(self.update_settings_preview)
        self.request_timeout.valueChanged.connect(self.update_settings_preview)
        self.max_retries.valueChanged.connect(self.update_settings_preview)
        self.enable_cache.toggled.connect(self.update_settings_preview)
        self.enable_streaming.toggled.connect(self.update_settings_preview)
    
    def update_settings_preview(self):
        """æ›´æ–°è®¾ç½®é¢„è§ˆï¼ˆå½“ä»»ä½•è®¾ç½®æ”¹å˜æ—¶è°ƒç”¨ï¼‰"""
        # æ„å»ºå½“å‰é…ç½®
        default_adapter_text = self.default_adapter.currentText()
        if default_adapter_text == 'OpenAI':
            default_adapter = 'openai'
        elif default_adapter_text == 'Ollama':
            default_adapter = 'local'
        else:
            default_adapter = 'mock'
        
        config = {
            'openai': {
                'api_key': self.openai_api_key.text().strip(),
                'base_url': self.openai_base_url.text().strip(),
                'model': self.openai_model.currentText(),
                'temperature': self.openai_temperature.value(),
                'max_tokens': self.openai_max_tokens.value()
            },
            'ollama': {
                'base_url': self.ollama_base_url.text().strip() or 'http://localhost:11434',
                'model': self.ollama_models.currentText(),
                'temperature': self.ollama_temperature.value(),
                'num_predict': self.ollama_num_predict.value(),
                'timeout': self.ollama_timeout.value()
            },
            'general': {
                'default_adapter': default_adapter,
                'request_timeout': self.request_timeout.value(),
                'max_retries': self.max_retries.value(),
                'enable_cache': self.enable_cache.isChecked(),
                'enable_streaming': self.enable_streaming.isChecked()
            }
        }
        
        # æ›´æ–°å½“å‰é…ç½®
        self.current_config = config
        
        # å‘å‡ºè®¾ç½®å˜æ›´ä¿¡å·
        self.settings_changed.emit(config) 