"""
è®­ç»ƒçº¿ç¨‹ - åœ¨å•ç‹¬çº¿ç¨‹ä¸­æ‰§è¡Œæ¨¡å‹è®­ç»ƒè¿‡ç¨‹

ä¸»è¦åŠŸèƒ½ï¼š
- åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œè®­ç»ƒï¼Œé¿å…é˜»å¡UI
- å¤„ç†è®­ç»ƒè¿‡ç¨‹ä¸­çš„å„ç§çŠ¶æ€æ›´æ–°
- æ”¯æŒè®­ç»ƒè¿‡ç¨‹çš„åœæ­¢æ§åˆ¶
- é›†æˆå„ç§è®­ç»ƒç»„ä»¶ï¼ˆæ¨¡å‹å·¥å‚ã€æƒé‡è®¡ç®—å™¨ç­‰ï¼‰
"""

import os
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import json
from PyQt5.QtCore import QThread, pyqtSignal

from .model_factory import ModelFactory
from .weight_calculator import WeightCalculator
from .model_configurator import ModelConfigurator
from .tensorboard_logger import TensorBoardLogger
from .training_validator import TrainingValidator
from .resource_limited_trainer import ResourceLimitedTrainer, enable_resource_limited_training
from .model_ema import ModelEMAManager
from .advanced_augmentation import AdvancedAugmentationManager, create_advanced_criterion
from .real_time_metrics_collector import get_global_metrics_collector
from ..utils.resource_limiter import (
    initialize_resource_limiter, ResourceLimits, ResourceLimitException, get_resource_limiter
)


class TrainingThread(QThread):
    """è´Ÿè´£åœ¨å•ç‹¬çº¿ç¨‹ä¸­æ‰§è¡Œè®­ç»ƒè¿‡ç¨‹çš„ç±»"""
    
    # å®šä¹‰ä¿¡å·
    progress_updated = pyqtSignal(int)
    status_updated = pyqtSignal(str)
    training_finished = pyqtSignal()
    training_error = pyqtSignal(str)
    epoch_finished = pyqtSignal(dict)
    model_download_failed = pyqtSignal(str, str)  # æ¨¡å‹åç§°ï¼Œä¸‹è½½é“¾æ¥
    training_stopped = pyqtSignal()
    conflict_detected = pyqtSignal(list, list)  # å†²çªåˆ—è¡¨ï¼Œå»ºè®®åˆ—è¡¨
    waiting_for_conflict_resolution = pyqtSignal()  # ç­‰å¾…å†²çªè§£å†³ä¿¡å·
    
    def __init__(self, config, parent=None):
        super().__init__(parent)
        self.config = config
        self.stop_training = False
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.training_info = {}
        
        # å†²çªè§£å†³ç›¸å…³çŠ¶æ€
        self.conflict_resolution_result = None
        self.conflict_resolution_config = None
        self.waiting_for_resolution = False
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.model_factory = ModelFactory()
        self.weight_calculator = WeightCalculator()
        self.model_configurator = ModelConfigurator()
        self.tensorboard_logger = TensorBoardLogger()
        self.validator = TrainingValidator()
        self.metrics_collector = get_global_metrics_collector()
        
        # åˆå§‹åŒ–ç¬¬äºŒé˜¶æ®µç»„ä»¶
        self.ema_manager = None
        self.augmentation_manager = None
        self.advanced_criterion = None
        self.gradient_accumulation_steps = config.get('gradient_accumulation_steps', 1)
        self._setup_stage_two_components()
        
        # åˆå§‹åŒ–èµ„æºé™åˆ¶å™¨
        self.resource_limiter = None
        self.resource_limited_trainer = None
        self._setup_resource_limiter()
        
        # è¿æ¥ç»„ä»¶ä¿¡å·
        self._connect_component_signals()
    
    def _setup_stage_two_components(self):
        """è®¾ç½®ç¬¬äºŒé˜¶æ®µç»„ä»¶ï¼ˆæ¨¡å‹EMAã€é«˜çº§æ•°æ®å¢å¼ºç­‰ï¼‰"""
        try:
            # è®¾ç½®é«˜çº§æ•°æ®å¢å¼ºç®¡ç†å™¨
            self.augmentation_manager = AdvancedAugmentationManager(self.config)
            
            # è®°å½•å¯ç”¨çš„é«˜çº§ç‰¹æ€§
            advanced_features = []
            
            if self.config.get('model_ema', False):
                advanced_features.append("æ¨¡å‹EMA")
            
            if self.gradient_accumulation_steps > 1:
                advanced_features.append(f"æ¢¯åº¦ç´¯ç§¯(æ­¥æ•°:{self.gradient_accumulation_steps})")
            
            if self.augmentation_manager.is_enabled():
                aug_methods = []
                if self.config.get('cutmix_prob', 0.0) > 0:
                    aug_methods.append("CutMix")
                if self.config.get('mixup_alpha', 0.0) > 0:
                    aug_methods.append("MixUp")
                advanced_features.append(f"é«˜çº§æ•°æ®å¢å¼º({'+'.join(aug_methods)})")
            
            # æ£€æŸ¥æŸå¤±ç¼©æ”¾çŠ¶æ€
            loss_scaling_enabled = self.config.get('loss_scaling_enabled', False)
            loss_scale = self.config.get('loss_scale', 'dynamic')
            if loss_scaling_enabled and loss_scale != 'none' and loss_scale == 'static':
                advanced_features.append("é™æ€æŸå¤±ç¼©æ”¾")
            elif loss_scaling_enabled and loss_scale != 'none' and loss_scale == 'dynamic':
                advanced_features.append("åŠ¨æ€æŸå¤±ç¼©æ”¾")
            
            if advanced_features:
                self.status_updated.emit(f"âœ¨ å¯ç”¨ç¬¬äºŒé˜¶æ®µé«˜çº§ç‰¹æ€§: {', '.join(advanced_features)}")
            
        except Exception as e:
            self.status_updated.emit(f"âš ï¸ è®¾ç½®ç¬¬äºŒé˜¶æ®µç»„ä»¶å¤±è´¥: {e}")
            print(f"ç¬¬äºŒé˜¶æ®µç»„ä»¶è®¾ç½®é”™è¯¯: {e}")
    
    def _setup_resource_limiter(self):
        """è®¾ç½®èµ„æºé™åˆ¶å™¨"""
        try:
            # ä»é…ç½®ä¸­è·å–èµ„æºé™åˆ¶è®¾ç½®
            resource_limits_config = self.config.get('resource_limits', {})
            
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨å¼ºåˆ¶èµ„æºé™åˆ¶ï¼ˆä»è®­ç»ƒç•Œé¢æˆ–è®¾ç½®ç•Œé¢ï¼‰
            enable_from_ui = self.config.get('enable_resource_limits', False)  # ä»è®­ç»ƒç•Œé¢
            enable_from_settings = resource_limits_config.get('enforce_limits_enabled', False)  # ä»è®¾ç½®ç•Œé¢
            
            if enable_from_ui or enable_from_settings:
                # åˆ›å»ºèµ„æºé™åˆ¶é…ç½®
                limits = ResourceLimits(
                    max_memory_gb=resource_limits_config.get('memory_absolute_limit_gb', 8.0),
                    max_cpu_percent=resource_limits_config.get('cpu_percent_limit', 80.0),
                    max_disk_usage_gb=resource_limits_config.get('temp_files_limit_gb', 10.0),
                    max_processes=4,
                    max_threads=resource_limits_config.get('cpu_cores_limit', 8),
                    check_interval=resource_limits_config.get('check_interval', 2.0),
                    enforce_limits=True,
                    auto_cleanup=resource_limits_config.get('auto_cleanup_enabled', True)
                )
                
                # åˆå§‹åŒ–å…¨å±€èµ„æºé™åˆ¶å™¨
                self.resource_limiter = initialize_resource_limiter(limits)
                
                # æ·»åŠ å›è°ƒå¤„ç†èµ„æºè¶…é™
                self.resource_limiter.add_callback('memory_limit', self._on_resource_limit_exceeded)
                self.resource_limiter.add_callback('cpu_limit', self._on_resource_limit_exceeded)
                self.resource_limiter.add_callback('disk_limit', self._on_resource_limit_exceeded)
                self.resource_limiter.add_callback('process_limit', self._on_resource_limit_exceeded)
                
                source = "è®­ç»ƒç•Œé¢" if enable_from_ui else "è®¾ç½®ç•Œé¢"
                print(f"âœ… è®­ç»ƒè¿›ç¨‹å¯ç”¨å¼ºåˆ¶èµ„æºé™åˆ¶(æ¥æº: {source}): å†…å­˜{limits.max_memory_gb}GB, CPU{limits.max_cpu_percent}%")
            else:
                print("â„¹ï¸ è®­ç»ƒè¿›ç¨‹æœªå¯ç”¨å¼ºåˆ¶èµ„æºé™åˆ¶ï¼Œä»…ä½¿ç”¨ç›‘æ§æ¨¡å¼")
                
        except Exception as e:
            print(f"âš ï¸ è®¾ç½®èµ„æºé™åˆ¶å™¨å¤±è´¥: {e}")
            self.resource_limiter = None
    
    def _on_resource_limit_exceeded(self, event_type: str, current_value: float, limit_value: float):
        """å¤„ç†èµ„æºé™åˆ¶è¶…é™"""
        resource_name = {"memory_limit": "å†…å­˜", "cpu_limit": "CPU", 
                        "disk_limit": "ç£ç›˜", "process_limit": "è¿›ç¨‹"}
        resource_name = resource_name.get(event_type, event_type)
        
        error_msg = f"ğŸš¨ è®­ç»ƒè¿‡ç¨‹{resource_name}èµ„æºè¶…é™ï¼å½“å‰: {current_value:.2f}, é™åˆ¶: {limit_value:.2f}"
        print(error_msg)
        self.status_updated.emit(error_msg)
        
        # åœæ­¢è®­ç»ƒ
        self.stop_training = True
        self.training_error.emit(f"è®­ç»ƒå› {resource_name}èµ„æºè¶…é™è€Œä¸­æ–­")
    
    def _connect_component_signals(self):
        """è¿æ¥å„ä¸ªç»„ä»¶çš„ä¿¡å·"""
        self.model_factory.status_updated.connect(self.status_updated)
        self.model_factory.model_download_failed.connect(self.model_download_failed)
        
        self.weight_calculator.status_updated.connect(self.status_updated)
        
        self.model_configurator.status_updated.connect(self.status_updated)
        
        self.tensorboard_logger.status_updated.connect(self.status_updated)
        
        self.validator.status_updated.connect(self.status_updated)
        self.validator.validation_error.connect(self.training_error)
    
    def resolve_conflict(self, user_choice, modified_config=None):
        """ä»ä¸»çº¿ç¨‹æ¥æ”¶å†²çªè§£å†³ç»“æœ"""
        self.conflict_resolution_result = user_choice
        self.conflict_resolution_config = modified_config
        self.waiting_for_resolution = False
        
    def _wait_for_conflict_resolution(self):
        """ç­‰å¾…ä¸»çº¿ç¨‹çš„å†²çªè§£å†³ç»“æœ"""
        self.waiting_for_resolution = True
        self.waiting_for_conflict_resolution.emit()
        
        # ç­‰å¾…ä¸»çº¿ç¨‹å“åº”
        while self.waiting_for_resolution and not self.stop_training:
            self.msleep(100)  # ç¡çœ 100msé¿å…å¿™ç­‰å¾…
            
        return self.conflict_resolution_result, self.conflict_resolution_config
    
    def _validate_config_thread_safe(self, config):
        """çº¿ç¨‹å®‰å…¨çš„é…ç½®éªŒè¯æ–¹æ³•"""
        self.status_updated.emit("å¼€å§‹éªŒè¯è®­ç»ƒé…ç½®...")
        
        try:
            # éªŒè¯æ•°æ®é›†è·¯å¾„
            if not self.validator.validate_dataset_paths(config):
                return False, config
            
            # éªŒè¯è®­ç»ƒå‚æ•°
            if not self.validator.validate_training_parameters(config):
                return False, config
            
            # éªŒè¯æ¨¡å‹é…ç½®
            if not self.validator.validate_model_config(config):
                return False, config
            
            # éªŒè¯ä¿å­˜è·¯å¾„
            if not self.validator.validate_save_paths(config):
                return False, config
            
            # æ£€æµ‹è¶…å‚æ•°å†²çª
            conflicts, suggestions = self.validator.detect_hyperparameter_conflicts(config)
            
            if conflicts:
                self.status_updated.emit(f"æ£€æµ‹åˆ° {len(conflicts)} ä¸ªè¶…å‚æ•°å†²çª")
                
                # é€šè¿‡ä¿¡å·é€šçŸ¥ä¸»çº¿ç¨‹æ˜¾ç¤ºå¯¹è¯æ¡†
                self.conflict_detected.emit(conflicts, suggestions)
                
                # ç­‰å¾…ä¸»çº¿ç¨‹çš„ç”¨æˆ·é€‰æ‹©
                user_choice, modified_config = self._wait_for_conflict_resolution()
                
                if user_choice == 'apply':
                    if modified_config:
                        self.status_updated.emit("å·²åº”ç”¨å‚æ•°å†²çªä¿®å¤")
                        return True, modified_config
                    else:
                        # å¦‚æœæ²¡æœ‰ä¿®å¤é…ç½®ï¼Œåº”ç”¨è‡ªåŠ¨ä¿®å¤
                        auto_fixed_config = self.validator.apply_conflict_fixes(config, suggestions)
                        self.status_updated.emit("å·²è‡ªåŠ¨ä¿®å¤å‚æ•°å†²çª")
                        return True, auto_fixed_config
                elif user_choice == 'ignore':
                    self.status_updated.emit("ç”¨æˆ·é€‰æ‹©å¿½ç•¥å†²çªï¼Œç»§ç»­è®­ç»ƒ")
                    return True, config
                else:
                    # ç”¨æˆ·å–æ¶ˆè®­ç»ƒ
                    self.status_updated.emit("ç”¨æˆ·å–æ¶ˆè®­ç»ƒ")
                    return False, config
            
            self.status_updated.emit("é…ç½®éªŒè¯é€šè¿‡")
            return True, config
            
        except Exception as e:
            self.training_error.emit(f"é…ç½®éªŒè¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return False, config
    
    def run(self):
        """çº¿ç¨‹è¿è¡Œå…¥å£ï¼Œæ‰§è¡Œæ¨¡å‹è®­ç»ƒ"""
        try:
            # é‡ç½®åœæ­¢æ ‡å¿—
            self.stop_training = False
            
            # å¯åŠ¨å®æ—¶æŒ‡æ ‡é‡‡é›†
            if self.metrics_collector:
                session_id = f"training_{int(time.time())}"
                self.metrics_collector.start_collection(session_id)
            
            # ğŸ” å®Œæ•´çš„å‚æ•°æ¥æ”¶éªŒè¯
            print("=" * 60)
            print("ğŸ” è®­ç»ƒçº¿ç¨‹å‚æ•°æ¥æ”¶éªŒè¯")
            print("=" * 60)
            
            # åŸºç¡€è®­ç»ƒå‚æ•°
            print("ğŸ“‹ åŸºç¡€è®­ç»ƒå‚æ•°:")
            basic_params = ['data_dir', 'model_name', 'num_epochs', 'batch_size', 'learning_rate', 
                          'model_save_dir', 'task_type', 'use_tensorboard']
            for param in basic_params:
                value = self.config.get(param, 'æœªè®¾ç½®')
                print(f"   {param}: {value}")
            
            # é«˜çº§è®­ç»ƒå‚æ•°
            print("\nğŸ”§ é«˜çº§è®­ç»ƒå‚æ•°:")
            advanced_params = ['optimizer', 'weight_decay', 'lr_scheduler', 'use_augmentation',
                             'early_stopping', 'early_stopping_patience', 'gradient_clipping',
                             'gradient_clipping_value', 'mixed_precision', 'dropout_rate',
                             'activation_function']
            for param in advanced_params:
                value = self.config.get(param, 'æœªè®¾ç½®')
                print(f"   {param}: {value}")
            
            # é¢„è®­ç»ƒæ¨¡å‹å‚æ•°
            print("\nğŸ—ï¸ é¢„è®­ç»ƒæ¨¡å‹å‚æ•°:")
            pretrained_params = ['use_pretrained', 'pretrained_path', 'use_local_pretrained', 'pretrained_model']
            for param in pretrained_params:
                value = self.config.get(param, 'æœªè®¾ç½®')
                print(f"   {param}: {value}")
            
            # ç±»åˆ«æƒé‡å‚æ•°
            print("\nâš–ï¸ ç±»åˆ«æƒé‡å‚æ•°:")
            weight_params = ['use_class_weights', 'weight_strategy', 'class_weights', 'custom_class_weights']
            for param in weight_params:
                value = self.config.get(param, 'æœªè®¾ç½®')
                print(f"   {param}: {value}")
            
            # ç›®æ ‡æ£€æµ‹ç‰¹æœ‰å‚æ•°ï¼ˆå¦‚æœæ˜¯æ£€æµ‹ä»»åŠ¡ï¼‰
            if self.config.get('task_type') == 'detection':
                print("\nğŸ¯ ç›®æ ‡æ£€æµ‹ç‰¹æœ‰å‚æ•°:")
                detection_params = ['iou_threshold', 'conf_threshold', 'resolution', 'use_mosaic',
                                  'use_multiscale', 'use_ema', 'nms_threshold', 'use_fpn']
                for param in detection_params:
                    value = self.config.get(param, 'æœªè®¾ç½®')
                    print(f"   {param}: {value}")
            
            # èµ„æºé™åˆ¶å‚æ•°
            print("\nğŸ’¾ èµ„æºä¸æ§åˆ¶å‚æ•°:")
            resource_params = ['enable_resource_limits', 'metrics', 'model_note', 'layer_config']
            for param in resource_params:
                value = self.config.get(param, 'æœªè®¾ç½®')
                if param == 'layer_config' and isinstance(value, dict):
                    print(f"   {param}: å·²é…ç½®å±‚å‚æ•° (å…±{len(value)}é¡¹)")
                else:
                    print(f"   {param}: {value}")
            
            # ç¬¬ä¸€é˜¶æ®µé«˜çº§è¶…å‚æ•°
            print("\nğŸ”§ ç¬¬ä¸€é˜¶æ®µé«˜çº§è¶…å‚æ•°:")
            stage_one_params = ['beta1', 'beta2', 'momentum', 'nesterov', 'warmup_steps', 
                              'warmup_ratio', 'warmup_method', 'min_lr', 'label_smoothing']
            for param in stage_one_params:
                value = self.config.get(param, 'æœªè®¾ç½®')
                print(f"   {param}: {value}")
            
            # ç¬¬äºŒé˜¶æ®µé«˜çº§è¶…å‚æ•°
            print("\nâš¡ ç¬¬äºŒé˜¶æ®µé«˜çº§è¶…å‚æ•°:")
            stage_two_params = ['model_ema', 'model_ema_decay', 'gradient_accumulation_steps',
                              'cutmix_prob', 'mixup_alpha', 'loss_scale', 'static_loss_scale']
            for param in stage_two_params:
                value = self.config.get(param, 'æœªè®¾ç½®')
                print(f"   {param}: {value}")
            
            # ç›®å½•é…ç½®å‚æ•°
            print("\nğŸ“ ç›®å½•é…ç½®å‚æ•°:")
            dir_params = ['default_param_save_dir', 'tensorboard_log_dir']
            for param in dir_params:
                value = self.config.get(param, 'æœªè®¾ç½®')
                print(f"   {param}: {value}")
            
            # ç»Ÿè®¡å‚æ•°æ€»æ•°
            total_basic = len(basic_params)
            total_advanced = len(advanced_params)
            total_pretrained = len(pretrained_params)
            total_weight = len(weight_params)
            total_stage_one = len([p for p in stage_one_params if self.config.get(p) is not None])
            total_stage_two = len([p for p in stage_two_params if self.config.get(p) is not None])
            total_resource = len(resource_params)
            total_dir = len(dir_params)
            
            # å¦‚æœæ˜¯æ£€æµ‹ä»»åŠ¡ï¼Œä¹Ÿç»Ÿè®¡æ£€æµ‹å‚æ•°
            total_detection = 0
            if self.config.get('task_type') == 'detection':
                detection_params = ['iou_threshold', 'conf_threshold', 'resolution', 'use_mosaic',
                                  'use_multiscale', 'use_ema', 'nms_threshold', 'use_fpn']
                total_detection = len([p for p in detection_params if self.config.get(p) is not None])
            
            print("=" * 60)
            print(f"âœ… å‚æ•°æ¥æ”¶éªŒè¯å®Œæˆï¼Œå…±æ¥æ”¶ {len(self.config)} ä¸ªå‚æ•°")
            print(f"   ğŸ“‹ åŸºç¡€å‚æ•°: {total_basic}ä¸ª")
            print(f"   ğŸ”§ é«˜çº§å‚æ•°: {total_advanced}ä¸ª") 
            print(f"   ğŸ—ï¸ é¢„è®­ç»ƒå‚æ•°: {total_pretrained}ä¸ª")
            print(f"   âš–ï¸ æƒé‡å‚æ•°: {total_weight}ä¸ª")
            print(f"   ğŸ”§ ç¬¬ä¸€é˜¶æ®µè¶…å‚æ•°: {total_stage_one}ä¸ª")
            print(f"   âš¡ ç¬¬äºŒé˜¶æ®µè¶…å‚æ•°: {total_stage_two}ä¸ª")
            print(f"   ğŸ’¾ èµ„æºå‚æ•°: {total_resource}ä¸ª")
            print(f"   ğŸ“ ç›®å½•å‚æ•°: {total_dir}ä¸ª")
            if total_detection > 0:
                print(f"   ğŸ¯ æ£€æµ‹å‚æ•°: {total_detection}ä¸ª")
            print("=" * 60)
            
            # å¯åŠ¨èµ„æºé™åˆ¶å™¨ç›‘æ§
            if self.resource_limiter:
                self.resource_limiter.start_monitoring()
                self.status_updated.emit("âœ… å¼ºåˆ¶èµ„æºé™åˆ¶å·²å¯åŠ¨")
            
            # éªŒè¯é…ç½®ï¼ˆçº¿ç¨‹å®‰å…¨ç‰ˆæœ¬ï¼‰
            is_valid, validated_config = self._validate_config_thread_safe(self.config)
            if not is_valid:
                return
            
            # ä½¿ç”¨éªŒè¯åçš„é…ç½®
            self.config = validated_config
            
            # æå–åŸºæœ¬å‚æ•°
            data_dir = self.config.get('data_dir', '')
            model_name = self.config.get('model_name', 'ResNet50')
            num_epochs = self.config.get('num_epochs', 20)
            batch_size = self.config.get('batch_size', 32)
            learning_rate = self.config.get('learning_rate', 0.001)
            model_save_dir = self.config.get('model_save_dir', 'models/saved_models')
            task_type = self.config.get('task_type', 'classification')
            use_tensorboard = self.config.get('use_tensorboard', True)
            
            print(f"ğŸš€ å¼€å§‹æ‰§è¡Œè®­ç»ƒæµç¨‹...")
            
            # è°ƒç”¨è®­ç»ƒæµç¨‹
            self.train_model(
                data_dir=data_dir,
                model_name=model_name,
                num_epochs=num_epochs,
                batch_size=batch_size,
                learning_rate=learning_rate,
                model_save_dir=model_save_dir,
                task_type=task_type,
                use_tensorboard=use_tensorboard
            )
            
            # è®­ç»ƒå®Œæˆ
            self.training_finished.emit()
            
        except Exception as e:
            self.training_error.emit(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
        finally:
            # ç¡®ä¿åœæ­¢èµ„æºé™åˆ¶å™¨
            if self.resource_limiter:
                self.resource_limiter.stop_monitoring()
                self.status_updated.emit("ğŸ”š èµ„æºé™åˆ¶å™¨å·²åœæ­¢")
    
    def stop(self):
        """åœæ­¢è®­ç»ƒè¿‡ç¨‹"""
        self.stop_training = True
        
        # åœæ­¢èµ„æºé™åˆ¶å™¨
        if self.resource_limiter:
            self.resource_limiter.request_stop()
            self.status_updated.emit("ğŸ›‘ å·²è¯·æ±‚èµ„æºé™åˆ¶å™¨åœæ­¢æ‰€æœ‰æ“ä½œ")
        
        # é‡Šæ”¾æ•°æ®æµæœåŠ¡å™¨å¼•ç”¨
        self._release_stream_server()
        
        self.status_updated.emit("è®­ç»ƒçº¿ç¨‹æ­£åœ¨åœæ­¢...")
    
    def _release_stream_server(self):
        """é‡Šæ”¾æ•°æ®æµæœåŠ¡å™¨å¼•ç”¨"""
        try:
            if hasattr(self, 'stream_server') and self.stream_server is not None:
                from ..api.stream_server_manager import release_stream_server
                release_stream_server()
                self.stream_server = None
                print("æ•°æ®æµæœåŠ¡å™¨å¼•ç”¨å·²é‡Šæ”¾")
            else:
                print("æ•°æ®æµæœåŠ¡å™¨æœªå¯åŠ¨ï¼Œæ— éœ€é‡Šæ”¾")
        except Exception as e:
            print(f"é‡Šæ”¾æ•°æ®æµæœåŠ¡å™¨å¼•ç”¨æ—¶å‡ºé”™: {str(e)}")
    
    def train_model(self, data_dir, model_name, num_epochs, batch_size, learning_rate, 
                   model_save_dir, task_type='classification', use_tensorboard=True):
        """æ‰§è¡Œæ¨¡å‹è®­ç»ƒ"""
        try:
            # æ ‡å‡†åŒ–è·¯å¾„æ ¼å¼
            data_dir = os.path.normpath(data_dir).replace('\\', '/')
            model_save_dir = os.path.normpath(model_save_dir).replace('\\', '/')
            
            # å‡†å¤‡æ•°æ®
            dataloaders, dataset_sizes, class_names, num_classes = self._prepare_data(
                data_dir, batch_size, task_type
            )
            
            if self.stop_training:
                return
            
            # åˆ›å»ºå’Œé…ç½®æ¨¡å‹
            self.model = self._create_and_configure_model(model_name, num_classes, task_type)
            
            if self.stop_training:
                return
            
            # åˆå§‹åŒ–EMAç®¡ç†å™¨ï¼ˆç¬¬äºŒé˜¶æ®µï¼‰
            if self.config.get('model_ema', False):
                self.ema_manager = ModelEMAManager(self.model, self.config)
                if self.ema_manager.is_enabled():
                    self.ema_manager.to(self.device)
                    self.status_updated.emit("ğŸ”„ EMAæ¨¡å‹å·²åˆå§‹åŒ–")
            
            # è®¡ç®—ç±»åˆ«æƒé‡å’Œè®¾ç½®æŸå¤±å‡½æ•°
            criterion = self._setup_loss_function(dataloaders['train'], class_names)
            
            if self.stop_training:
                return
            
            # è®¾ç½®ä¼˜åŒ–å™¨ï¼ˆä½¿ç”¨æ–°çš„ä¼˜åŒ–å™¨å·¥å‚ï¼‰
            from .optimizer_factory import OptimizerFactory
            optimizer = OptimizerFactory.create_optimizer(self.model, self.config)
            
            # è®¡ç®—æ€»è®­ç»ƒæ­¥æ•°ï¼ˆç”¨äºæŸäº›è°ƒåº¦å™¨ï¼‰
            steps_per_epoch = len(dataloaders['train'])
            total_steps = num_epochs * steps_per_epoch
            
            # è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆæ”¯æŒé¢„çƒ­ï¼‰
            scheduler = OptimizerFactory.create_scheduler(optimizer, self.config, total_steps)
            if scheduler:
                warmup_steps = self.config.get('warmup_steps', 0)
                warmup_ratio = self.config.get('warmup_ratio', 0.0)
                if warmup_steps > 0 or warmup_ratio > 0:
                    self.status_updated.emit(f"å¯ç”¨å­¦ä¹ ç‡é¢„çƒ­ï¼Œé¢„çƒ­æ­¥æ•°: {warmup_steps}")
                else:
                    self.status_updated.emit(f"ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨: {self.config.get('lr_scheduler', 'StepLR')}")
            
            # åˆå§‹åŒ–TensorBoardå’Œæ•°æ®æµæœåŠ¡å™¨
            tensorboard_log_dir = None
            if use_tensorboard:
                tensorboard_log_dir = self.tensorboard_logger.initialize(self.config, model_name)
                self.training_info['tensorboard_log_dir'] = tensorboard_log_dir
                
                # åˆå§‹åŒ–æ•°æ®æµæœåŠ¡å™¨
                self._initialize_stream_server()
                
                # è®°å½•æ¨¡å‹å›¾å’Œç±»åˆ«ä¿¡æ¯
                self.tensorboard_logger.log_model_graph(self.model, dataloaders['train'], self.device)
                
                class_weights = getattr(self.weight_calculator, 'class_weights', None)
                class_distribution = self.weight_calculator.get_class_distribution()
                if class_weights is not None and class_distribution:
                    self.tensorboard_logger.log_class_info(
                        class_names, class_distribution, class_weights, epoch=0
                    )
            
            if self.stop_training:
                return
            
            # æ‰§è¡Œè®­ç»ƒå¾ªç¯ï¼ˆä½¿ç”¨èµ„æºé™åˆ¶çš„è®­ç»ƒå™¨å¦‚æœå¯ç”¨ï¼‰
            if self.resource_limiter:
                # ä½¿ç”¨èµ„æºé™åˆ¶çš„è®­ç»ƒå™¨
                self.resource_limited_trainer = enable_resource_limited_training(self)
                best_acc = self._resource_limited_training_loop(
                    dataloaders, dataset_sizes, class_names, num_epochs, 
                    criterion, optimizer, scheduler, model_name, model_save_dir
                )
            else:
                # ä½¿ç”¨æ ‡å‡†è®­ç»ƒå¾ªç¯
                best_acc = self._training_loop(
                    dataloaders, dataset_sizes, class_names, num_epochs, 
                    criterion, optimizer, scheduler, model_name, model_save_dir
                )
            
            if self.stop_training:
                return
            
            # ä¿å­˜è®­ç»ƒä¿¡æ¯
            self._save_training_info(model_name, num_epochs, batch_size, learning_rate, 
                                   best_acc, class_names, model_save_dir)
            
            # è®°å½•è¶…å‚æ•°å’Œæœ€ç»ˆæŒ‡æ ‡
            if hasattr(self, 'tensorboard_logger') and self.tensorboard_logger:
                final_metrics = {
                    'final_accuracy': float(best_acc),
                    'final_loss': float(epoch_loss) if 'epoch_loss' in locals() else 0.0,
                    'total_epochs': num_epochs,
                    'best_epoch': epoch + 1 if 'epoch' in locals() else num_epochs
                }
                self.tensorboard_logger.log_hyperparameters(self.config, final_metrics)
            
            # å…³é—­TensorBoard
            self.tensorboard_logger.close()
            
            self.status_updated.emit(f'è®­ç»ƒå®Œæˆï¼Œæœ€ä½³å‡†ç¡®ç‡: {best_acc:.4f}')
            
        except Exception as e:
            self.training_error.emit(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
    
    def _prepare_data(self, data_dir, batch_size, task_type):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        if task_type != 'classification':
            raise ValueError(f"å½“å‰ä»…æ”¯æŒåˆ†ç±»ä»»åŠ¡ï¼Œä¸æ”¯æŒ: {task_type}")
        
        self.status_updated.emit("åŠ è½½åˆ†ç±»æ•°æ®é›†...")
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨åŸºç¡€æ•°æ®å¢å¼º
        use_augmentation = self.config.get('use_augmentation', True)
        
        # æ„å»ºè®­ç»ƒæ—¶çš„transformåˆ—è¡¨
        train_transforms = [
            transforms.Resize((224, 224)),
        ]
        
        # åŸºç¡€æ•°æ®å¢å¼ºï¼ˆåªæœ‰åœ¨å¯ç”¨æ—¶æ‰æ·»åŠ ï¼‰
        if use_augmentation:
            train_transforms.extend([
                transforms.RandomHorizontalFlip(p=0.5),
                transforms.RandomRotation(degrees=15),
                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
                transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
            ])
            self.status_updated.emit("âœ… å¯ç”¨åŸºç¡€æ•°æ®å¢å¼ºï¼ˆç¿»è½¬ã€æ—‹è½¬ã€é¢œè‰²æŠ–åŠ¨ã€ä»¿å°„å˜æ¢ï¼‰")
        else:
            self.status_updated.emit("âšª åŸºç¡€æ•°æ®å¢å¼ºå·²ç¦ç”¨")
        
        # æ·»åŠ å¿…è¦çš„è½¬æ¢
        train_transforms.extend([
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        # æ•°æ®è½¬æ¢é…ç½®
        data_transforms = {
            'train': transforms.Compose(train_transforms),
            'val': transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ]),
        }
        
        # åŠ è½½æ•°æ®é›†
        image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                                data_transforms[x])
                        for x in ['train', 'val']}
        
        # æ ¹æ®æ“ä½œç³»ç»Ÿé€‰æ‹©åˆé€‚çš„num_workers
        import platform
        num_workers = 0 if platform.system() == 'Windows' else 4
        
        dataloaders = {x: DataLoader(image_datasets[x],
                                   batch_size=batch_size,
                                   shuffle=True,
                                   num_workers=num_workers)
                      for x in ['train', 'val']}
        
        dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
        class_names = image_datasets['train'].classes
        num_classes = len(class_names)
        
        # è¾“å‡ºæ•°æ®å¢å¼ºé…ç½®ä¿¡æ¯
        augmentation_status = []
        if use_augmentation:
            augmentation_status.append("åŸºç¡€å¢å¼º")
        if self.augmentation_manager and self.augmentation_manager.is_enabled():
            augmentation_status.append("é«˜çº§å¢å¼º")
        
        if augmentation_status:
            self.status_updated.emit(f"ğŸ“Š æ•°æ®å¢å¼ºé…ç½®: {' + '.join(augmentation_status)}")
        else:
            self.status_updated.emit("ğŸ“Š æ•°æ®å¢å¼ºé…ç½®: æ— å¢å¼º")
        
        return dataloaders, dataset_sizes, class_names, num_classes
    
    def _create_and_configure_model(self, model_name, num_classes, task_type):
        """åˆ›å»ºå’Œé…ç½®æ¨¡å‹"""
        # åˆ›å»ºæ¨¡å‹
        model = self.model_factory.create_model(model_name, num_classes, task_type)
        
        # é…ç½®æ¨¡å‹
        model = self.model_configurator.configure_model(model, self.config)
        
        # ç§»åˆ°è®¾å¤‡
        model = model.to(self.device)
        
        return model
    
    def _setup_loss_function(self, train_dataset, class_names):
        """è®¾ç½®æŸå¤±å‡½æ•°ï¼ˆæ”¯æŒæ ‡ç­¾å¹³æ»‘å’Œé«˜çº§æ•°æ®å¢å¼ºï¼‰"""
        use_class_weights = self.config.get('use_class_weights', True)
        weight_strategy = self.config.get('weight_strategy', 'balanced')
        label_smoothing = self.config.get('label_smoothing', 0.0)
        
        # è®¡ç®—ç±»åˆ«æƒé‡
        class_weights = None
        if use_class_weights:
            class_weights = self.weight_calculator.calculate_class_weights(
                train_dataset.dataset, class_names, self.config, self.device
            )
        
        # åˆ›å»ºåŸºç¡€æŸå¤±å‡½æ•°
        from .optimizer_factory import OptimizerFactory
        base_criterion = OptimizerFactory.create_criterion(self.config, class_weights)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é«˜çº§æŸå¤±å‡½æ•°ï¼ˆç¬¬äºŒé˜¶æ®µï¼‰
        if self.augmentation_manager and self.augmentation_manager.is_enabled():
            # ä½¿ç”¨é«˜çº§æŸå¤±å‡½æ•°æ”¯æŒMixUp/CutMix
            criterion, aug_manager = create_advanced_criterion(self.config, base_criterion)
            self.advanced_criterion = criterion
            self.status_updated.emit("ğŸš€ ä½¿ç”¨é«˜çº§æ··åˆæŸå¤±å‡½æ•°ï¼ˆæ”¯æŒMixUp/CutMixï¼‰")
        else:
            # ä½¿ç”¨æ ‡å‡†æŸå¤±å‡½æ•°
            criterion, _ = create_advanced_criterion(self.config, base_criterion)
            self.advanced_criterion = None
        
        # æ›´æ–°çŠ¶æ€ä¿¡æ¯
        status_parts = []
        if label_smoothing > 0:
            status_parts.append(f"æ ‡ç­¾å¹³æ»‘(ç³»æ•°:{label_smoothing})")
        if use_class_weights:
            status_parts.append(f"ç±»åˆ«æƒé‡({weight_strategy})")
        
        if status_parts:
            self.status_updated.emit(f"æŸå¤±å‡½æ•°é…ç½®: {', '.join(status_parts)}")
        else:
            self.status_updated.emit("ä½¿ç”¨æ ‡å‡†äº¤å‰ç†µæŸå¤±å‡½æ•°")
        
        return criterion
    
    def _training_loop(self, dataloaders, dataset_sizes, class_names, num_epochs, 
                      criterion, optimizer, scheduler, model_name, model_save_dir):
        """æ‰§è¡Œè®­ç»ƒå¾ªç¯ï¼ˆæ”¯æŒé«˜çº§å­¦ä¹ ç‡è°ƒåº¦ï¼‰"""
        best_acc = 0.0
        
        for epoch in range(num_epochs):
            if self.stop_training:
                self.status_updated.emit("è®­ç»ƒå·²åœæ­¢")
                break
            
            self.status_updated.emit(f'Epoch {epoch+1}/{num_epochs}')
            
            # è®­ç»ƒå’ŒéªŒè¯é˜¶æ®µ
            for phase in ['train', 'val']:
                if self.stop_training:
                    break
                
                epoch_loss, epoch_acc, all_preds, all_labels = self._train_epoch(
                    phase, dataloaders, dataset_sizes, criterion, optimizer, epoch, num_epochs
                )
                
                if self.stop_training:
                    break
                
                # è®°å½•åˆ°TensorBoard
                self.tensorboard_logger.log_epoch_metrics(epoch, phase, epoch_loss, epoch_acc)
                
                # è®°å½•é«˜çº§è¯„ä¼°æŒ‡æ ‡
                if len(all_labels) > 0 and len(all_preds) > 0:
                    self.tensorboard_logger.log_advanced_metrics(
                        all_labels, all_preds, epoch=epoch, phase=phase
                    )
                
                # é‡‡é›†å®æ—¶æŒ‡æ ‡æ•°æ®ä¾›æ™ºèƒ½è®­ç»ƒä½¿ç”¨
                if self.metrics_collector:
                    metrics_data = {
                        'loss': epoch_loss,
                        'accuracy': epoch_acc,
                        'epoch': epoch + 1,  # è½¬æ¢ä¸ºä»1å¼€å§‹çš„epochç¼–å·
                        'phase': phase
                    }
                    self.metrics_collector.collect_tensorboard_metrics(epoch + 1, phase, metrics_data)
                
                # è®°å½•æ ·æœ¬å›¾åƒï¼ˆæ¯5ä¸ªepochä¸€æ¬¡ï¼‰
                if phase == 'val' and epoch % 5 == 0:
                    self.tensorboard_logger.log_sample_images(dataloaders[phase], epoch)
                
                # è®°å½•æ··æ·†çŸ©é˜µï¼ˆéªŒè¯é˜¶æ®µï¼‰
                if phase == 'val':
                    self.tensorboard_logger.log_confusion_matrix(
                        all_labels, all_preds, class_names, epoch
                    )
                
                # è®°å½•æ¨¡å‹é¢„æµ‹å¯è§†åŒ–ï¼ˆæ¯10ä¸ªepochä¸€æ¬¡ï¼‰
                if phase == 'val' and epoch % 10 == 0:
                    self.tensorboard_logger.log_model_predictions(
                        self.model, dataloaders[phase], class_names, epoch, self.device
                    )
                
                # è®°å½•æ¨¡å‹æƒé‡å’Œæ¢¯åº¦ï¼ˆæ¯5ä¸ªepochä¸€æ¬¡ï¼‰
                if phase == 'train' and epoch % 5 == 0:
                    self.tensorboard_logger.log_model_weights_and_gradients(self.model, epoch)
                
                # è®°å½•å­¦ä¹ ç‡è°ƒåº¦
                if phase == 'train':
                    self.tensorboard_logger.log_learning_rate_schedule(optimizer, epoch)
                
                # è®°å½•æ€§èƒ½æŒ‡æ ‡
                self.tensorboard_logger.log_performance_metrics(
                    epoch, num_samples=dataset_sizes[phase]
                )
                
                # åˆ·æ–°TensorBoardæ•°æ®
                self.tensorboard_logger.flush()
            
            if self.stop_training:
                break
            
            # æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨
            if scheduler and phase == 'val':
                if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):
                    # ReduceLROnPlateauéœ€è¦ä¼ å…¥ç›‘æ§çš„æŒ‡æ ‡
                    scheduler.step(epoch_loss)
                else:
                    scheduler.step()
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                self._save_best_model(model_name, model_save_dir, epoch, best_acc)
        
        return best_acc
    
    def _resource_limited_training_loop(self, dataloaders, dataset_sizes, class_names, num_epochs, 
                                       criterion, optimizer, scheduler, model_name, model_save_dir):
        """æ‰§è¡Œå¸¦èµ„æºé™åˆ¶çš„è®­ç»ƒå¾ªç¯"""
        try:
            best_acc = 0.0
            
            def save_callback(epoch, model, optimizer, train_result, val_result):
                """ä¿å­˜å›è°ƒå‡½æ•°"""
                nonlocal best_acc
                val_acc = val_result.get('val_accuracy', 0) / 100.0  # è½¬æ¢ä¸ºå°æ•°
                
                if val_acc > best_acc:
                    best_acc = val_acc
                    self._save_best_model(model_name, model_save_dir, epoch, best_acc)
                
                # è®°å½•åˆ°TensorBoard
                if hasattr(self, 'tensorboard_logger'):
                    self.tensorboard_logger.log_epoch_metrics(epoch-1, 'train', 
                                                            train_result['loss'], train_result['accuracy']/100.0)
                    self.tensorboard_logger.log_epoch_metrics(epoch-1, 'val', 
                                                            val_result['val_loss'], val_result['val_accuracy']/100.0)
                    self.tensorboard_logger.flush()
                
                # å‘é€epochç»“æœ
                epoch_data = {
                    'epoch': epoch,
                    'phase': 'val',
                    'loss': val_result['val_loss'],
                    'accuracy': val_result['val_accuracy'],
                    'batch': len(dataloaders['val']),
                    'total_batches': len(dataloaders['val'])
                }
                self.epoch_finished.emit(epoch_data)
                
                # æ›´æ–°è¿›åº¦
                progress = int((epoch / num_epochs) * 100)
                self.progress_updated.emit(progress)
            
            # ä½¿ç”¨èµ„æºé™åˆ¶çš„è®­ç»ƒå™¨
            self.resource_limited_trainer.train_with_resource_limits(
                epochs=num_epochs,
                train_loader=dataloaders['train'],
                val_loader=dataloaders['val'],
                model=self.model,
                optimizer=optimizer,
                criterion=criterion,
                device=self.device,
                save_callback=save_callback
            )
            
            return best_acc
            
        except ResourceLimitException as e:
            error_msg = f"è®­ç»ƒå› èµ„æºé™åˆ¶ä¸­æ–­: {e}"
            self.status_updated.emit(error_msg)
            self.training_error.emit(error_msg)
            return 0.0
        except Exception as e:
            error_msg = f"èµ„æºé™åˆ¶è®­ç»ƒå¾ªç¯å‡ºé”™: {e}"
            self.status_updated.emit(error_msg)
            self.training_error.emit(error_msg)
            return 0.0
    
    def _train_epoch(self, phase, dataloaders, dataset_sizes, criterion, optimizer, epoch, num_epochs):
        """è®­ç»ƒä¸€ä¸ªepochï¼ˆæ”¯æŒç¬¬äºŒé˜¶æ®µé«˜çº§ç‰¹æ€§ï¼‰"""
        if phase == 'train':
            self.model.train()
        else:
            self.model.eval()
        
        running_loss = 0.0
        running_corrects = 0
        all_preds = []
        all_labels = []
        
        # æ¢¯åº¦ç´¯ç§¯ç›¸å…³å˜é‡
        accumulation_steps = self.gradient_accumulation_steps if phase == 'train' else 1
        accumulated_loss = 0.0
        
        # éå†æ•°æ®
        for i, (inputs, labels) in enumerate(dataloaders[phase]):
            if self.stop_training:
                break
            
            inputs = inputs.to(self.device)
            labels = labels.to(self.device)
            
            # åªåœ¨ç´¯ç§¯æ­¥éª¤å¼€å§‹æ—¶æ¸…é›¶æ¢¯åº¦
            if phase == 'train' and i % accumulation_steps == 0:
                optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            with torch.set_grad_enabled(phase == 'train'):
                # åº”ç”¨é«˜çº§æ•°æ®å¢å¼ºï¼ˆç¬¬äºŒé˜¶æ®µï¼‰
                if phase == 'train' and self.augmentation_manager and self.augmentation_manager.is_enabled():
                    # ä½¿ç”¨é«˜çº§æ•°æ®å¢å¼ºï¼ˆMixUp/CutMixï¼‰
                    mixed_inputs, y_a, y_b, lam, aug_method = self.augmentation_manager(inputs, labels)
                    outputs = self.model(mixed_inputs)
                    
                    # è®¡ç®—æ··åˆæŸå¤±
                    loss = self._calculate_mixed_loss(outputs, y_a, y_b, lam, criterion)
                    
                    # è®¡ç®—æ··åˆå¢å¼ºçš„å‡†ç¡®ç‡
                    _, preds = torch.max(outputs, 1)
                    corrects = lam * preds.eq(y_a.data).sum().float() + (1 - lam) * preds.eq(y_b.data).sum().float()
                    
                    # è®°å½•ä½¿ç”¨çš„å¢å¼ºæ–¹æ³•ï¼ˆåªåœ¨ç¬¬ä¸€ä¸ªbatchè®°å½•ï¼‰
                    if i == 0:
                        self.status_updated.emit(f"ğŸ“Š ä½¿ç”¨{aug_method}é«˜çº§æ•°æ®å¢å¼º")
                    
                else:
                    # æ ‡å‡†å‰å‘ä¼ æ’­ï¼ˆå¯èƒ½åŒ…å«åŸºç¡€æ•°æ®å¢å¼ºï¼‰
                    outputs = self.model(inputs)
                    _, preds = torch.max(outputs, 1)
                    
                    # è®¡ç®—æ ‡å‡†æŸå¤±
                    loss = self._calculate_standard_loss(outputs, labels, criterion)
                    corrects = torch.sum(preds == labels.data).float()
                
                # æ¢¯åº¦ç´¯ç§¯ï¼šç¼©æ”¾æŸå¤±
                if phase == 'train' and accumulation_steps > 1:
                    loss = loss / accumulation_steps
                
                # åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°
                if phase == 'train':
                    self._backward_and_update(loss, optimizer, i, accumulation_steps, dataloaders[phase])
            
            if self.stop_training:
                break
            
            # ç´¯ç§¯ç»Ÿè®¡ä¿¡æ¯
            if accumulation_steps > 1:
                accumulated_loss += loss.item() * inputs.size(0) * accumulation_steps  # è¿˜åŸçœŸå®æŸå¤±
            else:
                accumulated_loss += loss.item() * inputs.size(0)
                
            running_loss += accumulated_loss if (i + 1) % accumulation_steps == 0 else 0
            running_corrects += corrects
            
            # æ”¶é›†é¢„æµ‹å’Œæ ‡ç­¾ï¼ˆç”¨äºæŒ‡æ ‡è®¡ç®—ï¼‰
            if phase == 'train' and self.augmentation_manager and self.augmentation_manager.is_enabled():
                # æ··åˆå¢å¼ºæ—¶ä½¿ç”¨åŸå§‹æ ‡ç­¾
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
            else:
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
            
            # é‡ç½®ç´¯ç§¯æŸå¤±
            if (i + 1) % accumulation_steps == 0:
                accumulated_loss = 0.0
            
            # æ›´æ–°è¿›åº¦
            progress = int(((epoch * len(dataloaders[phase]) + i + 1) /
                          (num_epochs * len(dataloaders[phase]))) * 100)
            self.progress_updated.emit(progress)
            
            # å‘é€è®­ç»ƒçŠ¶æ€æ›´æ–°
            if i % 10 == 0:
                current_loss = running_loss / ((i + 1) * inputs.size(0))
                current_acc = running_corrects.double() / ((i + 1) * inputs.size(0))
                
                # æ·»åŠ æ¢¯åº¦ç´¯ç§¯ä¿¡æ¯
                status_info = {
                    'epoch': epoch + 1,
                    'phase': phase,
                    'loss': float(current_loss),
                    'accuracy': float(current_acc.item()),
                    'batch': i + 1,
                    'total_batches': len(dataloaders[phase])
                }
                
                # æ·»åŠ ç¬¬äºŒé˜¶æ®µç‰¹æ€§ä¿¡æ¯
                if phase == 'train':
                    if accumulation_steps > 1:
                        status_info['grad_accum'] = f"{accumulation_steps}æ­¥"
                    if self.ema_manager and self.ema_manager.is_enabled():
                        status_info['ema'] = "å¯ç”¨"
                
                self.epoch_finished.emit(status_info)
        
        if self.stop_training:
            return 0, 0, [], []
        
        epoch_loss = running_loss / dataset_sizes[phase]
        epoch_acc = running_corrects.double() / dataset_sizes[phase]
        
        # å‘é€epochç»“æœ
        epoch_data = {
            'epoch': epoch + 1,
            'phase': phase,
            'loss': float(epoch_loss),
            'accuracy': float(epoch_acc.item()) if isinstance(epoch_acc, torch.Tensor) else float(epoch_acc),
            'batch': len(dataloaders[phase]),
            'total_batches': len(dataloaders[phase])
        }
        self.epoch_finished.emit(epoch_data)
        
        return epoch_loss, epoch_acc, all_preds, all_labels
    
    def _calculate_mixed_loss(self, outputs, y_a, y_b, lam, criterion):
        """è®¡ç®—æ··åˆæŸå¤±ï¼ˆMixUp/CutMixï¼‰"""
        if self.advanced_criterion:
            return self.advanced_criterion(outputs, y_a, y_b, lam)
        else:
            return lam * criterion(outputs, y_a) + (1 - lam) * criterion(outputs, y_b)
    
    def _calculate_standard_loss(self, outputs, labels, criterion):
        """è®¡ç®—æ ‡å‡†æŸå¤±"""
        if self.advanced_criterion and hasattr(self.advanced_criterion, '__call__'):
            # æ£€æŸ¥æ˜¯å¦æ˜¯MixCriterionç±»å‹
            if hasattr(self.advanced_criterion, 'criterion'):
                # è¿™æ˜¯MixCriterionï¼Œä½†æ²¡æœ‰æ··åˆå¢å¼ºï¼Œç›´æ¥ä½¿ç”¨åŸºç¡€æŸå¤±å‡½æ•°
                return self.advanced_criterion.criterion(outputs, labels)
            else:
                # è¿™æ˜¯å…¶ä»–é«˜çº§æŸå¤±å‡½æ•°ï¼ˆå¦‚æ ‡ç­¾å¹³æ»‘ï¼‰
                return self.advanced_criterion(outputs, labels)
        else:
            # ä½¿ç”¨æ ‡å‡†æŸå¤±å‡½æ•°
            return criterion(outputs, labels)
    
    def _backward_and_update(self, loss, optimizer, batch_idx, accumulation_steps, dataloader):
        """åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°"""
        loss.backward()
        
        # åªåœ¨ç´¯ç§¯æ­¥éª¤ç»“æŸæ—¶æ›´æ–°å‚æ•°
        if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(dataloader):
            # æ¢¯åº¦è£å‰ªï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.config.get('gradient_clipping', False):
                clip_value = self.config.get('gradient_clipping_value', 1.0)
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), clip_value)
            
            optimizer.step()
            
            # æ›´æ–°EMAæ¨¡å‹ï¼ˆç¬¬äºŒé˜¶æ®µï¼‰
            if self.ema_manager and self.ema_manager.is_enabled():
                self.ema_manager.update(self.model)
    
    def _save_best_model(self, model_name, model_save_dir, epoch, best_acc):
        """ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆæ”¯æŒEMAæ¨¡å‹ï¼‰"""
        model_note = self.config.get('model_note', '')
        timestamp = time.strftime("%Y%m%d-%H%M%S")
        
        # ä¿å­˜æ ‡å‡†æ¨¡å‹
        model_save_path = os.path.join(model_save_dir, f'{model_name}_{timestamp}_{model_note}_best.pth')
        torch.save(self.model.state_dict(), model_save_path)
        self.status_updated.emit(f'ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ŒEpoch {epoch+1}, Acc: {best_acc:.4f}')
        
        # ä¿å­˜EMAæ¨¡å‹ï¼ˆç¬¬äºŒé˜¶æ®µï¼‰
        if self.ema_manager and self.ema_manager.is_enabled():
            ema_save_path = os.path.join(model_save_dir, f'{model_name}_{timestamp}_{model_note}_best_ema.pth')
            self.ema_manager.save_ema_model(ema_save_path)
            self.status_updated.emit(f'ğŸ”„ ä¿å­˜æœ€ä½³EMAæ¨¡å‹: {ema_save_path}')
        
        # å¯¼å‡ºONNXæ¨¡å‹ï¼ˆä¼˜å…ˆä½¿ç”¨EMAæ¨¡å‹ï¼‰
        try:
            onnx_save_path = os.path.join(model_save_dir, f'{model_name}_{timestamp}_{model_note}_best.onnx')
            sample_input = torch.randn(1, 3, 224, 224).to(self.device)
            
            # é€‰æ‹©ç”¨äºå¯¼å‡ºçš„æ¨¡å‹
            export_model = self.model
            if self.ema_manager and self.ema_manager.is_enabled():
                ema_model = self.ema_manager.get_model()
                if ema_model is not None:
                    export_model = ema_model
                    self.status_updated.emit('ğŸ“¦ ä½¿ç”¨EMAæ¨¡å‹å¯¼å‡ºONNX')
            
            torch.onnx.export(
                export_model, 
                sample_input, 
                onnx_save_path,
                export_params=True,
                opset_version=11,
                input_names=['input'],
                output_names=['output'],
                dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}
            )
            self.status_updated.emit(f'ğŸ“¦ å¯¼å‡ºONNXæ¨¡å‹: {onnx_save_path}')
        except Exception as e:
            self.status_updated.emit(f'âš ï¸ å¯¼å‡ºONNXæ¨¡å‹æ—¶å‡ºé”™: {str(e)}')
    
    def _save_training_info(self, model_name, num_epochs, batch_size, learning_rate, 
                           best_acc, class_names, model_save_dir):
        """ä¿å­˜è®­ç»ƒä¿¡æ¯"""
        model_note = self.config.get('model_note', '')
        timestamp = time.strftime("%Y%m%d-%H%M%S")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_model_path = os.path.join(model_save_dir, f'{model_name}_{timestamp}_{model_note}_final.pth')
        torch.save(self.model.state_dict(), final_model_path)
        self.status_updated.emit(f'ä¿å­˜æœ€ç»ˆæ¨¡å‹: {final_model_path}')
        
        # ä¿å­˜ç±»åˆ«ä¿¡æ¯
        class_info = {
            'class_names': class_names,
            'class_to_idx': {name: idx for idx, name in enumerate(class_names)}
        }
        
        os.makedirs(model_save_dir, exist_ok=True)
        with open(os.path.join(model_save_dir, 'class_info.json'), 'w') as f:
            json.dump(class_info, f)
        
        # è®°å½•è®­ç»ƒä¿¡æ¯
        training_info = {
            'model_name': model_name,
            'num_epochs': num_epochs,
            'batch_size': batch_size,
            'learning_rate': learning_rate,
            'best_accuracy': best_acc.item() if isinstance(best_acc, torch.Tensor) else best_acc,
            'class_names': class_names,
            'model_path': final_model_path,
            'timestamp': timestamp
        }
        
        with open(os.path.join(model_save_dir, 'training_info.json'), 'w') as f:
            json.dump(training_info, f, indent=4) 

    def _initialize_stream_server(self):
        """åˆå§‹åŒ–æ•°æ®æµæœåŠ¡å™¨"""
        try:
            # é¦–å…ˆæ£€æŸ¥AIé…ç½®ä¸­çš„æ•°æ®æµæœåŠ¡å™¨å¼€å…³
            ai_config = self._load_ai_config()
            enable_data_stream_server = ai_config.get('general', {}).get('enable_data_stream_server', True)
            
            if not enable_data_stream_server:
                self.status_updated.emit("ğŸ“Š æ•°æ®æµæœåŠ¡å™¨å·²ç¦ç”¨ï¼ˆæ ¹æ®AIè®¾ç½®ï¼‰")
                self.stream_server = None
                return
            
            # å¯¼å…¥å…¨å±€æ•°æ®æµæœåŠ¡å™¨ç®¡ç†å™¨
            from ..api.stream_server_manager import get_stream_server
            
            # åˆ›å»ºæ•°æ®æµæœåŠ¡å™¨é…ç½®
            stream_config = {
                'sse_host': '127.0.0.1',
                'sse_port': 8888,
                'websocket_host': '127.0.0.1',
                'websocket_port': 8889,
                'rest_api_host': '127.0.0.1',
                'rest_api_port': 8890,
                'buffer_size': 1000,
                'debug_mode': False
            }
            
            # è·å–å…¨å±€æ•°æ®æµæœåŠ¡å™¨å®ä¾‹
            self.stream_server = get_stream_server(
                training_system=self.parent() if self.parent() else None,
                config=stream_config
            )
            
            # è®¾ç½®TensorBoardæ—¥å¿—å™¨çš„æ•°æ®æµæœåŠ¡å™¨
            self.tensorboard_logger.set_stream_server(self.stream_server)
            
            # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨å®Œæˆ
            import time
            time.sleep(2)
            
            # è·å–APIç«¯ç‚¹ä¿¡æ¯
            endpoints = self.stream_server.get_api_endpoints()
            self.status_updated.emit(f"æ•°æ®æµæœåŠ¡å·²å¯åŠ¨:")
            self.status_updated.emit(f"â€¢ SSE: {endpoints.get('sse_stream')}")
            self.status_updated.emit(f"â€¢ WebSocket: {endpoints.get('websocket')}")
            self.status_updated.emit(f"â€¢ REST API: {endpoints.get('rest_current_metrics')}")
            
        except Exception as e:
            print(f"åˆå§‹åŒ–æ•°æ®æµæœåŠ¡å™¨å¤±è´¥: {str(e)}")
            self.stream_server = None
    
    def _load_ai_config(self):
        """åŠ è½½AIé…ç½®æ–‡ä»¶"""
        import json
        import os
        
        config_file = "setting/ai_config.json"
        default_config = {
            'general': {
                'enable_data_stream_server': True
            }
        }
        
        try:
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    # ç¡®ä¿generaléƒ¨åˆ†å­˜åœ¨
                    if 'general' not in config:
                        config['general'] = {}
                    # ç¡®ä¿enable_data_stream_serverå­˜åœ¨
                    if 'enable_data_stream_server' not in config['general']:
                        config['general']['enable_data_stream_server'] = True
                    return config
            else:
                return default_config
        except Exception as e:
            print(f"åŠ è½½AIé…ç½®å¤±è´¥: {str(e)}")
            return default_config 