"""
æ™ºèƒ½é…ç½®ç”Ÿæˆå™¨

åŸºäºè®­ç»ƒé…ç½®å’Œå®æ—¶æ•°æ®ï¼Œä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆä¼˜åŒ–çš„è®­ç»ƒé…ç½®
ä¸»è¦åŠŸèƒ½ï¼š
- æ¥æ”¶å½“å‰è®­ç»ƒé…ç½®å’Œå®æ—¶è®­ç»ƒæ•°æ®
- ä½¿ç”¨LLMåˆ†æç”Ÿæˆä¼˜åŒ–é…ç½®
- è°ƒç”¨ç°æœ‰é…ç½®åº”ç”¨æœºåˆ¶
- è®°å½•é…ç½®è°ƒæ•´å†å²
"""

import os
import json
import time
import copy
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
from PyQt5.QtCore import QObject, pyqtSignal, QThread
from PyQt5.QtWidgets import QMessageBox

from .real_time_metrics_collector import get_global_metrics_collector
from ..llm.llm_framework import LLMFramework
from ..llm.analysis_engine import TrainingAnalysisEngine


@dataclass
class ConfigAdjustment:
    """é…ç½®è°ƒæ•´è®°å½•"""
    adjustment_id: str
    timestamp: float
    original_config: Dict[str, Any]
    adjusted_config: Dict[str, Any]
    changes: Dict[str, Any]  # å…·ä½“å˜æ›´çš„å‚æ•°
    reason: str  # è°ƒæ•´åŸå› 
    training_metrics: Dict[str, Any]  # è§¦å‘è°ƒæ•´çš„è®­ç»ƒæŒ‡æ ‡
    llm_analysis: Dict[str, Any]  # LLMåˆ†æç»“æœ
    status: str  # 'pending', 'applied', 'failed'


@dataclass
class TrainingSession:
    """è®­ç»ƒä¼šè¯è®°å½•"""
    session_id: str
    start_time: float
    original_config: Dict[str, Any]
    adjustments: List[ConfigAdjustment]
    final_config: Optional[Dict[str, Any]]
    status: str  # 'running', 'completed', 'failed'


class IntelligentConfigGenerator(QObject):
    """æ™ºèƒ½é…ç½®ç”Ÿæˆå™¨"""
    
    # ä¿¡å·å®šä¹‰
    config_generated = pyqtSignal(dict)  # é…ç½®ç”Ÿæˆå®Œæˆä¿¡å·
    config_applied = pyqtSignal(dict)    # é…ç½®åº”ç”¨å®Œæˆä¿¡å·
    adjustment_recorded = pyqtSignal(dict)  # è°ƒæ•´è®°å½•ä¿¡å·
    status_updated = pyqtSignal(str)     # çŠ¶æ€æ›´æ–°ä¿¡å·
    error_occurred = pyqtSignal(str)     # é”™è¯¯ä¿¡å·
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self.llm_framework = None
        self.analysis_engine = None
        self.metrics_collector = None
        
        # ä¼šè¯ç®¡ç†
        self.current_session: Optional[TrainingSession] = None
        self.adjustment_history: List[ConfigAdjustment] = []
        
        # é…ç½®çº¦æŸ
        self.parameter_constraints = self._load_parameter_constraints()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._initialize_components()
        
    def _initialize_components(self):
        """åˆå§‹åŒ–ç›¸å…³ç»„ä»¶"""
        try:
            # è·å–LLMé…ç½®
            llm_config = self._load_llm_config()
            adapter_type = llm_config.get('adapter_type', 'openai')
            
            # ç”Ÿäº§ç¯å¢ƒæ£€æŸ¥
            if adapter_type == 'mock':
                self.error_occurred.emit("âŒ ç”Ÿäº§ç¯å¢ƒä¸å…è®¸ä½¿ç”¨mock LLMé€‚é…å™¨ï¼è¯·åœ¨æ™ºèƒ½è®­ç»ƒè®¾ç½®ä¸­é…ç½®çœŸå®çš„LLMæœåŠ¡ã€‚")
                raise ValueError("ç”Ÿäº§ç¯å¢ƒä¸å…è®¸ä½¿ç”¨mock LLMé€‚é…å™¨")
            
            # åˆå§‹åŒ–LLMæ¡†æ¶
            self.llm_framework = LLMFramework(
                adapter_type=adapter_type,
                adapter_config=llm_config.get('adapter_config', {})
            )
            self.llm_framework.start()
            
            # åˆå§‹åŒ–åˆ†æå¼•æ“
            self.analysis_engine = TrainingAnalysisEngine(self.llm_framework.llm_adapter)
            
            # è·å–æŒ‡æ ‡é‡‡é›†å™¨
            self.metrics_collector = get_global_metrics_collector()
            
            print(f"âœ… æ™ºèƒ½é…ç½®ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨LLMé€‚é…å™¨: {adapter_type}")
            
        except Exception as e:
            self.error_occurred.emit(f"åˆå§‹åŒ–ç»„ä»¶å¤±è´¥: {str(e)}")
            # ç”Ÿäº§ç¯å¢ƒä¸­ä¸å…è®¸ä½¿ç”¨æ¨¡æ‹Ÿé€‚é…å™¨ä½œä¸ºåå¤‡
            raise
    
    def _load_llm_config(self) -> Dict[str, Any]:
        """åŠ è½½LLMé…ç½®"""
        try:
            print("[DEBUG] å¼€å§‹åŠ è½½LLMé…ç½®...")
            
            # é¦–å…ˆå°è¯•ä»æ™ºèƒ½è®­ç»ƒè®¾ç½®ä¸­åŠ è½½
            intelligent_config_file = "setting/intelligent_training_config.json"
            if os.path.exists(intelligent_config_file):
                print(f"[DEBUG] æ£€æŸ¥æ™ºèƒ½è®­ç»ƒé…ç½®æ–‡ä»¶: {intelligent_config_file}")
                with open(intelligent_config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    llm_config = config.get('llm_config', {})
                    if llm_config:
                        print(f"[DEBUG] ä»æ™ºèƒ½è®­ç»ƒé…ç½®ä¸­æ‰¾åˆ°LLMé…ç½®: {llm_config}")
                        return llm_config
                    else:
                        print("[DEBUG] æ™ºèƒ½è®­ç»ƒé…ç½®ä¸­æœªæ‰¾åˆ°llm_config")
            else:
                print(f"[DEBUG] æ™ºèƒ½è®­ç»ƒé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {intelligent_config_file}")
            
            # ç„¶åå°è¯•ä»AIè®¾ç½®ä¸­åŠ è½½
            ai_config_file = "setting/ai_config.json"
            if os.path.exists(ai_config_file):
                print(f"[DEBUG] æ£€æŸ¥AIé…ç½®æ–‡ä»¶: {ai_config_file}")
                with open(ai_config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    
                    # è·å–é»˜è®¤é€‚é…å™¨ç±»å‹
                    default_adapter = config.get('general', {}).get('default_adapter', 'openai')
                    print(f"[DEBUG] ä»AIé…ç½®ä¸­è·å–é»˜è®¤é€‚é…å™¨: {default_adapter}")
                    
                    # æ ¹æ®é€‚é…å™¨ç±»å‹è·å–å¯¹åº”é…ç½®
                    if default_adapter == 'deepseek':
                        adapter_config = config.get('deepseek', {})
                        print(f"[DEBUG] åŠ è½½DeepSeeké…ç½®: {adapter_config}")
                        result = {
                            'adapter_type': 'deepseek',
                            'adapter_config': {
                                'api_key': adapter_config.get('api_key', ''),
                                'base_url': adapter_config.get('base_url', ''),
                                'model': adapter_config.get('model', 'deepseek-chat'),
                                'temperature': adapter_config.get('temperature', 0.7),
                                'max_tokens': adapter_config.get('max_tokens', 3000)
                            }
                        }
                        print(f"[DEBUG] è¿”å›DeepSeeké…ç½®: {result}")
                        return result
                    elif default_adapter == 'openai':
                        adapter_config = config.get('openai', {})
                        return {
                            'adapter_type': 'openai',
                            'adapter_config': {
                                'api_key': adapter_config.get('api_key', ''),
                                'base_url': adapter_config.get('base_url', ''),
                                'model': adapter_config.get('model', 'gpt-4'),
                                'temperature': adapter_config.get('temperature', 0.7),
                                'max_tokens': adapter_config.get('max_tokens', 1000)
                            }
                        }
                    elif default_adapter == 'ollama':
                        adapter_config = config.get('ollama', {})
                        return {
                            'adapter_type': 'ollama',
                            'adapter_config': {
                                'base_url': adapter_config.get('base_url', ''),
                                'model': adapter_config.get('model', 'llama2'),
                                'temperature': adapter_config.get('temperature', 0.7),
                                'num_predict': adapter_config.get('num_predict', 1000),
                                'timeout': adapter_config.get('timeout', 120)
                            }
                        }
                    elif default_adapter == 'custom':
                        adapter_config = config.get('custom_api', {})
                        return {
                            'adapter_type': 'custom',
                            'adapter_config': {
                                'api_key': adapter_config.get('api_key', ''),
                                'base_url': adapter_config.get('base_url', ''),
                                'model': adapter_config.get('model', ''),
                                'temperature': adapter_config.get('temperature', 0.7),
                                'max_tokens': adapter_config.get('max_tokens', 1000)
                            }
                        }
            
            # å¦‚æœéƒ½æ²¡æœ‰ï¼Œè¿”å›é»˜è®¤é…ç½®
            return {
                'adapter_type': 'openai',
                'adapter_config': {
                    'api_key': '',
                    'model': 'gpt-4',
                    'temperature': 0.7,
                    'max_tokens': 1000
                }
            }
            
        except Exception as e:
            print(f"åŠ è½½LLMé…ç½®å¤±è´¥: {str(e)}")
            # è¿”å›é»˜è®¤é…ç½®
            return {
                'adapter_type': 'openai',
                'adapter_config': {
                    'api_key': '',
                    'model': 'gpt-4',
                    'temperature': 0.7,
                    'max_tokens': 1000
                }
            }
    
    def _load_parameter_constraints(self) -> Dict[str, Dict[str, Any]]:
        """åŠ è½½å‚æ•°çº¦æŸé…ç½®"""
        return {
            'learning_rate': {
                'min': 1e-6,
                'max': 0.1,
                'step': 1e-6,
                'description': 'å­¦ä¹ ç‡'
            },
            'batch_size': {
                'min': 1,
                'max': 128,
                'step': 1,
                'description': 'æ‰¹æ¬¡å¤§å°'
            },
            'num_epochs': {
                'min': 1,
                'max': 1000,
                'step': 1,
                'description': 'è®­ç»ƒè½®æ•°'
            },
            'dropout_rate': {
                'min': 0.0,
                'max': 0.9,
                'step': 0.01,
                'description': 'Dropoutç‡'
            },
            'weight_decay': {
                'min': 0.0,
                'max': 0.01,
                'step': 1e-6,
                'description': 'æƒé‡è¡°å‡'
            },
            'early_stopping_patience': {
                'min': 1,
                'max': 50,
                'step': 1,
                'description': 'æ—©åœè€å¿ƒå€¼'
            }
        }
    
    def start_training_session(self, initial_config: Dict[str, Any]) -> str:
        """å¼€å§‹æ–°çš„è®­ç»ƒä¼šè¯"""
        try:
            session_id = f"session_{int(time.time())}"
            
            self.current_session = TrainingSession(
                session_id=session_id,
                start_time=time.time(),
                original_config=copy.deepcopy(initial_config),
                adjustments=[],
                final_config=None,
                status='running'
            )
            
            self.status_updated.emit(f"å¼€å§‹è®­ç»ƒä¼šè¯: {session_id}")
            return session_id
            
        except Exception as e:
            self.error_occurred.emit(f"å¼€å§‹è®­ç»ƒä¼šè¯å¤±è´¥: {str(e)}")
            return ""
    
    def generate_optimized_config(self, 
                                current_config: Dict[str, Any],
                                training_metrics: Dict[str, Any] = None) -> Dict[str, Any]:
        """ç”Ÿæˆä¼˜åŒ–çš„è®­ç»ƒé…ç½®"""
        try:
            self.status_updated.emit("æ­£åœ¨ç”Ÿæˆä¼˜åŒ–é…ç½®...")
            
            # è·å–å®æ—¶è®­ç»ƒæ•°æ®
            if training_metrics is None:
                real_data = self.metrics_collector.get_current_training_data_for_ai()
                if 'error' in real_data:
                    self.error_occurred.emit(f"æ— æ³•è·å–è®­ç»ƒæ•°æ®: {real_data['error']}")
                    return current_config
                training_metrics = real_data.get('current_metrics', {})
            
            # ä½¿ç”¨LLMåˆ†æå½“å‰é…ç½®å’Œè®­ç»ƒæ•°æ®
            analysis_result = self._analyze_config_and_metrics(current_config, training_metrics)
            
            # ç”Ÿæˆä¼˜åŒ–å»ºè®®
            optimization_suggestions = self._generate_optimization_suggestions(
                current_config, training_metrics, analysis_result
            )
            
            # åº”ç”¨ä¼˜åŒ–å»ºè®®åˆ°é…ç½®
            optimized_config = self._apply_optimization_suggestions(
                current_config, optimization_suggestions
            )
            
            # éªŒè¯é…ç½®æœ‰æ•ˆæ€§
            validated_config = self._validate_config(optimized_config)
            
            # è®°å½•é…ç½®è°ƒæ•´
            # ç¡®ä¿analysis_resultæ˜¯å­—å…¸æ ¼å¼
            if isinstance(analysis_result, str):
                # å¦‚æœåˆ†æç»“æœæ˜¯å­—ç¬¦ä¸²ï¼Œæå–å…¶ä¸­çš„å…³é”®ä¿¡æ¯
                analysis_dict = {
                    'reason': 'LLMæ™ºèƒ½åˆ†æå»ºè®®',
                    'analysis': analysis_result[:500] + '...' if len(analysis_result) > 500 else analysis_result
                }
            else:
                analysis_dict = analysis_result
            
            self._record_config_adjustment(
                current_config, validated_config, training_metrics, analysis_dict
            )
            
            self.status_updated.emit("ä¼˜åŒ–é…ç½®ç”Ÿæˆå®Œæˆ")
            return validated_config
            
        except Exception as e:
            self.error_occurred.emit(f"ç”Ÿæˆä¼˜åŒ–é…ç½®å¤±è´¥: {str(e)}")
            return current_config
    
    def _analyze_config_and_metrics(self, 
                                  config: Dict[str, Any], 
                                  metrics: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æé…ç½®å’Œè®­ç»ƒæŒ‡æ ‡"""
        try:
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            adapter_type = type(self.llm_framework.llm_adapter).__name__
            self.status_updated.emit(f"ğŸ” å¼€å§‹LLMåˆ†æï¼Œä½¿ç”¨é€‚é…å™¨: {adapter_type}")
            print(f"[DEBUG] ä½¿ç”¨LLMé€‚é…å™¨: {adapter_type}")
            print(f"[DEBUG] é€‚é…å™¨ç±»å‹: {getattr(self.llm_framework.llm_adapter, 'adapter_type', 'unknown')}")
            
            # æ„å»ºåˆ†ææç¤ºè¯
            prompt = self._build_config_analysis_prompt(config, metrics)
            print(f"[DEBUG] åˆ†ææç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
            
            # ä½¿ç”¨LLMè¿›è¡Œåˆ†æ
            self.status_updated.emit("ğŸ¤– æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œè®­ç»ƒåˆ†æ...")
            print(f"[DEBUG] å¼€å§‹è°ƒç”¨LLMåˆ†æ...")
            
            analysis_result = self.llm_framework.llm_adapter.analyze_metrics(metrics, prompt)
            
            print(f"[DEBUG] LLMåˆ†æç»“æœç±»å‹: {type(analysis_result)}")
            print(f"[DEBUG] LLMåˆ†æç»“æœé•¿åº¦: {len(str(analysis_result))} å­—ç¬¦")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ¨¡æ‹Ÿç»“æœ
            if isinstance(analysis_result, str) and "æ¨¡æ‹Ÿåˆ†æç»“æœ" in analysis_result:
                self.status_updated.emit("âš ï¸ æ£€æµ‹åˆ°æ¨¡æ‹Ÿåˆ†æç»“æœï¼è¯·é…ç½®çœŸå®çš„LLMæœåŠ¡")
                print("[WARNING] æ£€æµ‹åˆ°æ¨¡æ‹Ÿåˆ†æç»“æœï¼Œè¯·é…ç½®çœŸå®çš„LLMæœåŠ¡")
            else:
                self.status_updated.emit("âœ… LLMåˆ†æå®Œæˆ")
                print("[DEBUG] LLMåˆ†æå®Œæˆï¼Œç»“æœçœ‹èµ·æ¥æ˜¯çœŸå®çš„")
            
            return analysis_result
            
        except Exception as e:
            self.error_occurred.emit(f"åˆ†æé…ç½®å’ŒæŒ‡æ ‡å¤±è´¥: {str(e)}")
            print(f"[ERROR] LLMåˆ†æå¤±è´¥: {str(e)}")
            return {'error': str(e)}
    
    def _build_config_analysis_prompt(self, 
                                    config: Dict[str, Any], 
                                    metrics: Dict[str, Any]) -> str:
        """æ„å»ºé…ç½®åˆ†ææç¤ºè¯"""
        return f"""
è¯·åŸºäºä»¥ä¸‹è®­ç»ƒé…ç½®å’Œå®æ—¶è®­ç»ƒæ•°æ®ï¼Œæä¾›ä¸“ä¸šçš„é…ç½®ä¼˜åŒ–å»ºè®®ï¼š

## ğŸ“‹ å½“å‰è®­ç»ƒé…ç½®
```json
{json.dumps(config, ensure_ascii=False, indent=2)}
```

## ğŸ“Š å®æ—¶è®­ç»ƒæŒ‡æ ‡
```json
{json.dumps(metrics, ensure_ascii=False, indent=2)}
```

## ğŸ¯ åˆ†æè¦æ±‚

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œæä¾›ä»¥ä¸‹åˆ†æï¼š

### 1. é…ç½®è¯„ä¼°
- å½“å‰é…ç½®æ˜¯å¦é€‚åˆå½“å‰æ•°æ®é›†å’Œä»»åŠ¡ï¼Ÿ
- æ˜¯å¦å­˜åœ¨æ˜æ˜¾çš„é…ç½®é—®é¢˜æˆ–å†²çªï¼Ÿ
- å“ªäº›å‚æ•°å¯èƒ½éœ€è¦è°ƒæ•´ï¼Ÿ

### 2. è®­ç»ƒçŠ¶æ€åˆ†æ
- å½“å‰è®­ç»ƒçŠ¶æ€ï¼ˆæ”¶æ•›ã€è¿‡æ‹Ÿåˆã€æ¬ æ‹Ÿåˆç­‰ï¼‰
- è®­ç»ƒæŒ‡æ ‡åæ˜ çš„é—®é¢˜
- ä¸é…ç½®å‚æ•°çš„å…³è”æ€§

### 3. ä¼˜åŒ–å»ºè®®
è¯·æä¾›å…·ä½“çš„å‚æ•°è°ƒæ•´å»ºè®®ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
```json
{{
    "suggestions": [
        {{
            "parameter": "learning_rate",
            "current_value": 0.001,
            "suggested_value": 0.0005,
            "reason": "è®­ç»ƒæŸå¤±ä¸‹é™ç¼“æ…¢ï¼Œå»ºè®®é™ä½å­¦ä¹ ç‡",
            "priority": "high"
        }},
        {{
            "parameter": "batch_size",
            "current_value": 32,
            "suggested_value": 16,
            "reason": "GPUå†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®å‡å°æ‰¹æ¬¡å¤§å°",
            "priority": "medium"
        }}
    ]
}}
```

### 4. æ³¨æ„äº‹é¡¹
- åªå»ºè®®è°ƒæ•´ç°æœ‰é…ç½®ä¸­çš„å‚æ•°
- ç¡®ä¿å»ºè®®å€¼åœ¨åˆç†èŒƒå›´å†…
- ä¼˜å…ˆè€ƒè™‘é«˜ä¼˜å…ˆçº§å»ºè®®
- ä¿æŒé…ç½®çš„å®Œæ•´æ€§å’Œä¸€è‡´æ€§

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒä¸“ä¸šæ€§å’Œå®ç”¨æ€§ã€‚
"""
    
    def _generate_optimization_suggestions(self, 
                                         config: Dict[str, Any],
                                         metrics: Dict[str, Any],
                                         analysis_result: Any) -> List[Dict[str, Any]]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        try:
            print(f"[DEBUG] åˆ†æç»“æœç±»å‹: {type(analysis_result)}")
            print(f"[DEBUG] åˆ†æç»“æœå†…å®¹: {str(analysis_result)[:200]}...")
            
            # ä»LLMåˆ†æç»“æœä¸­æå–å»ºè®®
            if isinstance(analysis_result, dict) and 'suggestions' in analysis_result:
                suggestions.extend(analysis_result['suggestions'])
            elif isinstance(analysis_result, str):
                # å¦‚æœåˆ†æç»“æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æå…¶ä¸­çš„å»ºè®®
                parsed_suggestions = self._parse_suggestions_from_text(analysis_result)
                suggestions.extend(parsed_suggestions)
            
            # åŸºäºè§„åˆ™ç”Ÿæˆé¢å¤–å»ºè®®
            rule_suggestions = self._generate_rule_based_suggestions(config, metrics)
            suggestions.extend(rule_suggestions)
            
            # æŒ‰ä¼˜å…ˆçº§æ’åº
            suggestions.sort(key=lambda x: x.get('priority', 'low'), reverse=True)
            
            return suggestions
            
        except Exception as e:
            self.error_occurred.emit(f"ç”Ÿæˆä¼˜åŒ–å»ºè®®å¤±è´¥: {str(e)}")
            print(f"[ERROR] ç”Ÿæˆä¼˜åŒ–å»ºè®®å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return []
    
    def _parse_suggestions_from_text(self, text: str) -> List[Dict[str, Any]]:
        """ä»æ–‡æœ¬ä¸­è§£æå»ºè®®"""
        suggestions = []
        
        try:
            print(f"[DEBUG] å¼€å§‹è§£æLLMè¿”å›çš„æ–‡æœ¬å»ºè®®")
            
            # é¦–å…ˆå°è¯•æå–JSONæ ¼å¼çš„å»ºè®®
            json_suggestions = self._extract_json_suggestions(text)
            if json_suggestions:
                print(f"[DEBUG] æˆåŠŸæå–åˆ° {len(json_suggestions)} ä¸ªJSONæ ¼å¼å»ºè®®")
                return json_suggestions
            
            # å¦‚æœæ²¡æœ‰JSONæ ¼å¼ï¼Œåˆ™è¿›è¡Œæ–‡æœ¬è§£æ
            print(f"[DEBUG] æœªæ‰¾åˆ°JSONæ ¼å¼å»ºè®®ï¼Œè¿›è¡Œæ–‡æœ¬è§£æ")
            lines = text.split('\n')
            current_suggestion = None
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                # æ£€æµ‹å»ºè®®é¡¹ï¼ˆä»¥æ•°å­—å¼€å¤´æˆ–åŒ…å«å…³é”®è¯ï¼‰
                if (line.startswith(('1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.')) or
                    any(keyword in line.lower() for keyword in ['å»ºè®®', 'æ¨è', 'è°ƒæ•´', 'ä¼˜åŒ–', 'å¢åŠ ', 'å‡å°‘', 'é™ä½', 'æé«˜'])):
                    
                    if current_suggestion:
                        suggestions.append(current_suggestion)
                    
                    current_suggestion = {
                        'type': 'parameter_adjustment',
                        'description': line,
                        'priority': 'medium',
                        'confidence': 0.7
                    }
                elif current_suggestion and line.startswith(('  ', '\t', '-', '*')):
                    # è¿™æ˜¯å»ºè®®çš„è¯¦ç»†è¯´æ˜
                    current_suggestion['description'] += f" {line.strip()}"
            
            if current_suggestion:
                suggestions.append(current_suggestion)
                
        except Exception as e:
            print(f"[DEBUG] è§£ææ–‡æœ¬å»ºè®®å¤±è´¥: {str(e)}")
        
        return suggestions
    
    def _extract_json_suggestions(self, text: str) -> List[Dict[str, Any]]:
        """ä»æ–‡æœ¬ä¸­æå–JSONæ ¼å¼çš„å»ºè®®"""
        try:
            import re
            import json
            
            # æŸ¥æ‰¾JSONä»£ç å—
            json_pattern = r'```json\s*(\{.*?\})\s*```'
            matches = re.findall(json_pattern, text, re.DOTALL)
            
            if not matches:
                # å¦‚æœæ²¡æœ‰ä»£ç å—æ ‡è®°ï¼Œå°è¯•ç›´æ¥æŸ¥æ‰¾JSONå¯¹è±¡
                json_pattern = r'\{[^{}]*"suggestions"[^{}]*\[.*?\][^{}]*\}'
                matches = re.findall(json_pattern, text, re.DOTALL)
            
            for match in matches:
                try:
                    json_data = json.loads(match)
                    if 'suggestions' in json_data and isinstance(json_data['suggestions'], list):
                        print(f"[DEBUG] æˆåŠŸè§£æJSONå»ºè®®: {len(json_data['suggestions'])} ä¸ªå»ºè®®")
                        return json_data['suggestions']
                except json.JSONDecodeError as e:
                    print(f"[DEBUG] JSONè§£æå¤±è´¥: {str(e)}")
                    continue
            
            return []
            
        except Exception as e:
            print(f"[DEBUG] æå–JSONå»ºè®®å¤±è´¥: {str(e)}")
            return []
    
    def _generate_rule_based_suggestions(self, 
                                       config: Dict[str, Any],
                                       metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åŸºäºè§„åˆ™ç”Ÿæˆå»ºè®®"""
        suggestions = []
        
        try:
            train_loss = metrics.get('train_loss', 0)
            val_loss = metrics.get('val_loss', 0)
            train_acc = metrics.get('train_accuracy', 0)
            val_acc = metrics.get('val_accuracy', 0)
            epoch = metrics.get('epoch', 0)
            
            # è¿‡æ‹Ÿåˆæ£€æµ‹
            if val_loss > train_loss * 1.3 and epoch > 5:
                suggestions.append({
                    'parameter': 'dropout_rate',
                    'current_value': config.get('dropout_rate', 0.0),
                    'suggested_value': min(0.9, config.get('dropout_rate', 0.0) + 0.1),
                    'reason': 'æ£€æµ‹åˆ°è¿‡æ‹Ÿåˆï¼Œå»ºè®®å¢åŠ Dropoutç‡',
                    'priority': 'high'
                })
                
                suggestions.append({
                    'parameter': 'weight_decay',
                    'current_value': config.get('weight_decay', 0.0001),
                    'suggested_value': config.get('weight_decay', 0.0001) * 1.5,
                    'reason': 'æ£€æµ‹åˆ°è¿‡æ‹Ÿåˆï¼Œå»ºè®®å¢åŠ æƒé‡è¡°å‡',
                    'priority': 'high'
                })
            
            # æ¬ æ‹Ÿåˆæ£€æµ‹
            if train_acc < 0.6 and val_acc < 0.6 and epoch > 10:
                suggestions.append({
                    'parameter': 'learning_rate',
                    'current_value': config.get('learning_rate', 0.001),
                    'suggested_value': config.get('learning_rate', 0.001) * 1.5,
                    'reason': 'æ£€æµ‹åˆ°æ¬ æ‹Ÿåˆï¼Œå»ºè®®å¢åŠ å­¦ä¹ ç‡',
                    'priority': 'high'
                })
            
            # æ”¶æ•›ç¼“æ…¢æ£€æµ‹
            if train_loss > 0.5 and epoch > 15:
                suggestions.append({
                    'parameter': 'learning_rate',
                    'current_value': config.get('learning_rate', 0.001),
                    'suggested_value': config.get('learning_rate', 0.001) * 0.5,
                    'reason': 'è®­ç»ƒæ”¶æ•›ç¼“æ…¢ï¼Œå»ºè®®é™ä½å­¦ä¹ ç‡',
                    'priority': 'medium'
                })
            
            return suggestions
            
        except Exception as e:
            self.error_occurred.emit(f"ç”Ÿæˆè§„åˆ™å»ºè®®å¤±è´¥: {str(e)}")
            return []
    
    def _apply_optimization_suggestions(self, 
                                      config: Dict[str, Any],
                                      suggestions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åº”ç”¨ä¼˜åŒ–å»ºè®®åˆ°é…ç½®"""
        try:
            optimized_config = copy.deepcopy(config)
            
            for suggestion in suggestions:
                param_name = suggestion.get('parameter')
                suggested_value = suggestion.get('suggested_value')
                
                if param_name in optimized_config and suggested_value is not None:
                    # åº”ç”¨çº¦æŸ
                    constrained_value = self._apply_parameter_constraints(param_name, suggested_value)
                    optimized_config[param_name] = constrained_value
            
            return optimized_config
            
        except Exception as e:
            self.error_occurred.emit(f"åº”ç”¨ä¼˜åŒ–å»ºè®®å¤±è´¥: {str(e)}")
            return config
    
    def _apply_parameter_constraints(self, param_name: str, value: Any) -> Any:
        """åº”ç”¨å‚æ•°çº¦æŸ"""
        if param_name not in self.parameter_constraints:
            return value
        
        constraints = self.parameter_constraints[param_name]
        
        # åº”ç”¨èŒƒå›´çº¦æŸ
        if 'min' in constraints:
            value = max(value, constraints['min'])
        if 'max' in constraints:
            value = min(value, constraints['max'])
        
        # åº”ç”¨æ­¥é•¿çº¦æŸ
        if 'step' in constraints and isinstance(value, (int, float)):
            step = constraints['step']
            value = round(value / step) * step
        
        return value
    
    def _validate_config(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        try:
            validated_config = copy.deepcopy(config)
            
            # éªŒè¯å¿…éœ€å‚æ•°
            required_params = ['model_name', 'batch_size', 'learning_rate', 'num_epochs']
            for param in required_params:
                if param not in validated_config:
                    self.error_occurred.emit(f"ç¼ºå°‘å¿…éœ€å‚æ•°: {param}")
                    return config
            
            # éªŒè¯å‚æ•°ç±»å‹å’ŒèŒƒå›´
            for param_name, value in validated_config.items():
                if param_name in self.parameter_constraints:
                    validated_config[param_name] = self._apply_parameter_constraints(param_name, value)
            
            return validated_config
            
        except Exception as e:
            self.error_occurred.emit(f"éªŒè¯é…ç½®å¤±è´¥: {str(e)}")
            return config
    
    def _record_config_adjustment(self, 
                                original_config: Dict[str, Any],
                                adjusted_config: Dict[str, Any],
                                training_metrics: Dict[str, Any],
                                analysis_result: Dict[str, Any]):
        """è®°å½•é…ç½®è°ƒæ•´"""
        try:
            # è®¡ç®—å˜æ›´
            changes = {}
            for key, value in adjusted_config.items():
                if key in original_config and original_config[key] != value:
                    changes[key] = {
                        'from': original_config[key],
                        'to': value
                    }
            
            if not changes:
                return  # æ²¡æœ‰å˜æ›´ï¼Œä¸è®°å½•
            
            # åˆ›å»ºè°ƒæ•´è®°å½•
            adjustment = ConfigAdjustment(
                adjustment_id=f"adj_{int(time.time())}",
                timestamp=time.time(),
                original_config=copy.deepcopy(original_config),
                adjusted_config=copy.deepcopy(adjusted_config),
                changes=changes,
                reason=analysis_result.get('reason', 'æ™ºèƒ½ä¼˜åŒ–å»ºè®®'),
                training_metrics=copy.deepcopy(training_metrics),
                llm_analysis=copy.deepcopy(analysis_result),
                status='pending'
            )
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            self.adjustment_history.append(adjustment)
            if self.current_session:
                self.current_session.adjustments.append(adjustment)
            
            # å‘å°„ä¿¡å·
            self.adjustment_recorded.emit(asdict(adjustment))
            
        except Exception as e:
            self.error_occurred.emit(f"è®°å½•é…ç½®è°ƒæ•´å¤±è´¥: {str(e)}")
    
    def apply_config_to_training_system(self, 
                                      config: Dict[str, Any],
                                      training_tab) -> bool:
        """å°†é…ç½®åº”ç”¨åˆ°è®­ç»ƒç³»ç»Ÿ"""
        try:
            self.status_updated.emit("æ­£åœ¨åº”ç”¨é…ç½®åˆ°è®­ç»ƒç³»ç»Ÿ...")
            
            # ä½¿ç”¨ç°æœ‰çš„ConfigApplieråº”ç”¨é…ç½®
            from ..ui.components.training.config_applier import ConfigApplier
            success = ConfigApplier.apply_to_training_tab(config, training_tab)
            
            if success:
                self.status_updated.emit("é…ç½®åº”ç”¨æˆåŠŸ")
                self.config_applied.emit({
                    'config': config,
                    'timestamp': time.time(),
                    'success': True
                })
            else:
                self.error_occurred.emit("é…ç½®åº”ç”¨å¤±è´¥")
                self.config_applied.emit({
                    'config': config,
                    'timestamp': time.time(),
                    'success': False
                })
            
            return success
            
        except Exception as e:
            self.error_occurred.emit(f"åº”ç”¨é…ç½®åˆ°è®­ç»ƒç³»ç»Ÿå¤±è´¥: {str(e)}")
            return False
    
    def get_adjustment_history(self) -> List[Dict[str, Any]]:
        """è·å–è°ƒæ•´å†å²"""
        return [asdict(adj) for adj in self.adjustment_history]
    
    def get_current_session_info(self) -> Dict[str, Any]:
        """è·å–å½“å‰ä¼šè¯ä¿¡æ¯"""
        if not self.current_session:
            return {}
        
        return {
            'session_id': self.current_session.session_id,
            'start_time': self.current_session.start_time,
            'status': self.current_session.status,
            'adjustment_count': len(self.current_session.adjustments),
            'original_config': self.current_session.original_config,
            'final_config': self.current_session.final_config
        }
    
    def export_adjustment_report(self) -> Dict[str, Any]:
        """å¯¼å‡ºè°ƒæ•´æŠ¥å‘Š"""
        return {
            'export_time': time.time(),
            'current_session': self.get_current_session_info(),
            'adjustment_history': self.get_adjustment_history(),
            'parameter_constraints': self.parameter_constraints
        }
    
    def stop_training_session(self):
        """åœæ­¢è®­ç»ƒä¼šè¯"""
        if self.current_session:
            self.current_session.status = 'completed'
            self.current_session.final_config = self.current_session.adjustments[-1].adjusted_config if self.current_session.adjustments else self.current_session.original_config
            self.status_updated.emit(f"è®­ç»ƒä¼šè¯ {self.current_session.session_id} å·²åœæ­¢")