"""
æ™ºèƒ½é…ç½®ç”Ÿæˆå™¨

åŸºäºè®­ç»ƒé…ç½®å’Œå®æ—¶æ•°æ®ï¼Œä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆä¼˜åŒ–çš„è®­ç»ƒé…ç½®
ä¸»è¦åŠŸèƒ½ï¼š
- æ¥æ”¶å½“å‰è®­ç»ƒé…ç½®å’Œå®æ—¶è®­ç»ƒæ•°æ®
- ä½¿ç”¨LLMåˆ†æç”Ÿæˆä¼˜åŒ–é…ç½®
- è°ƒç”¨ç°æœ‰é…ç½®åº”ç”¨æœºåˆ¶
- è®°å½•é…ç½®è°ƒæ•´å†å²
"""

import os
import json
import time
import copy
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
from PyQt5.QtCore import QObject, pyqtSignal, QThread
from PyQt5.QtWidgets import QMessageBox

from .real_time_metrics_collector import get_global_metrics_collector
from ..llm.llm_framework import LLMFramework
from ..llm.analysis_engine import TrainingAnalysisEngine


@dataclass
class ConfigAdjustment:
    """é…ç½®è°ƒæ•´è®°å½•"""
    adjustment_id: str
    timestamp: float
    original_config: Dict[str, Any]
    adjusted_config: Dict[str, Any]
    changes: Dict[str, Any]  # å…·ä½“å˜æ›´çš„å‚æ•°
    reason: str  # è°ƒæ•´åŸå› 
    training_metrics: Dict[str, Any]  # è§¦å‘è°ƒæ•´çš„è®­ç»ƒæŒ‡æ ‡
    llm_analysis: Dict[str, Any]  # LLMåˆ†æç»“æœ
    status: str  # 'pending', 'applied', 'failed'


@dataclass
class TrainingSession:
    """è®­ç»ƒä¼šè¯è®°å½•"""
    session_id: str
    start_time: float
    original_config: Dict[str, Any]
    adjustments: List[ConfigAdjustment]
    final_config: Optional[Dict[str, Any]]
    status: str  # 'running', 'completed', 'failed'


class IntelligentConfigGenerator(QObject):
    """æ™ºèƒ½é…ç½®ç”Ÿæˆå™¨"""
    
    # ä¿¡å·å®šä¹‰
    config_generated = pyqtSignal(dict)  # é…ç½®ç”Ÿæˆå®Œæˆä¿¡å·
    config_applied = pyqtSignal(dict)    # é…ç½®åº”ç”¨å®Œæˆä¿¡å·
    adjustment_recorded = pyqtSignal(dict)  # è°ƒæ•´è®°å½•ä¿¡å·
    status_updated = pyqtSignal(str)     # çŠ¶æ€æ›´æ–°ä¿¡å·
    error_occurred = pyqtSignal(str)     # é”™è¯¯ä¿¡å·
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self.llm_framework = None
        self.analysis_engine = None
        self.metrics_collector = None
        
        # ä¼šè¯ç®¡ç†
        self.current_session: Optional[TrainingSession] = None
        self.adjustment_history: List[ConfigAdjustment] = []
        
        # é…ç½®çº¦æŸ
        self.parameter_constraints = self._load_parameter_constraints()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._initialize_components()
        
    def _initialize_components(self):
        """åˆå§‹åŒ–ç›¸å…³ç»„ä»¶"""
        try:
            # åˆå§‹åŒ–LLMæ¡†æ¶
            self.llm_framework = LLMFramework(adapter_type='mock')
            self.llm_framework.start()
            
            # åˆå§‹åŒ–åˆ†æå¼•æ“
            self.analysis_engine = TrainingAnalysisEngine(self.llm_framework.llm_adapter)
            
            # è·å–æŒ‡æ ‡é‡‡é›†å™¨
            self.metrics_collector = get_global_metrics_collector()
            
            print("æ™ºèƒ½é…ç½®ç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            self.error_occurred.emit(f"åˆå§‹åŒ–ç»„ä»¶å¤±è´¥: {str(e)}")
    
    def _load_parameter_constraints(self) -> Dict[str, Dict[str, Any]]:
        """åŠ è½½å‚æ•°çº¦æŸé…ç½®"""
        return {
            'learning_rate': {
                'min': 1e-6,
                'max': 0.1,
                'step': 1e-6,
                'description': 'å­¦ä¹ ç‡'
            },
            'batch_size': {
                'min': 1,
                'max': 128,
                'step': 1,
                'description': 'æ‰¹æ¬¡å¤§å°'
            },
            'num_epochs': {
                'min': 1,
                'max': 1000,
                'step': 1,
                'description': 'è®­ç»ƒè½®æ•°'
            },
            'dropout_rate': {
                'min': 0.0,
                'max': 0.9,
                'step': 0.01,
                'description': 'Dropoutç‡'
            },
            'weight_decay': {
                'min': 0.0,
                'max': 0.01,
                'step': 1e-6,
                'description': 'æƒé‡è¡°å‡'
            },
            'early_stopping_patience': {
                'min': 1,
                'max': 50,
                'step': 1,
                'description': 'æ—©åœè€å¿ƒå€¼'
            }
        }
    
    def start_training_session(self, initial_config: Dict[str, Any]) -> str:
        """å¼€å§‹æ–°çš„è®­ç»ƒä¼šè¯"""
        try:
            session_id = f"session_{int(time.time())}"
            
            self.current_session = TrainingSession(
                session_id=session_id,
                start_time=time.time(),
                original_config=copy.deepcopy(initial_config),
                adjustments=[],
                final_config=None,
                status='running'
            )
            
            self.status_updated.emit(f"å¼€å§‹è®­ç»ƒä¼šè¯: {session_id}")
            return session_id
            
        except Exception as e:
            self.error_occurred.emit(f"å¼€å§‹è®­ç»ƒä¼šè¯å¤±è´¥: {str(e)}")
            return ""
    
    def generate_optimized_config(self, 
                                current_config: Dict[str, Any],
                                training_metrics: Dict[str, Any] = None) -> Dict[str, Any]:
        """ç”Ÿæˆä¼˜åŒ–çš„è®­ç»ƒé…ç½®"""
        try:
            self.status_updated.emit("æ­£åœ¨ç”Ÿæˆä¼˜åŒ–é…ç½®...")
            
            # è·å–å®æ—¶è®­ç»ƒæ•°æ®
            if training_metrics is None:
                real_data = self.metrics_collector.get_current_training_data_for_ai()
                if 'error' in real_data:
                    self.error_occurred.emit(f"æ— æ³•è·å–è®­ç»ƒæ•°æ®: {real_data['error']}")
                    return current_config
                training_metrics = real_data.get('current_metrics', {})
            
            # ä½¿ç”¨LLMåˆ†æå½“å‰é…ç½®å’Œè®­ç»ƒæ•°æ®
            analysis_result = self._analyze_config_and_metrics(current_config, training_metrics)
            
            # ç”Ÿæˆä¼˜åŒ–å»ºè®®
            optimization_suggestions = self._generate_optimization_suggestions(
                current_config, training_metrics, analysis_result
            )
            
            # åº”ç”¨ä¼˜åŒ–å»ºè®®åˆ°é…ç½®
            optimized_config = self._apply_optimization_suggestions(
                current_config, optimization_suggestions
            )
            
            # éªŒè¯é…ç½®æœ‰æ•ˆæ€§
            validated_config = self._validate_config(optimized_config)
            
            # è®°å½•é…ç½®è°ƒæ•´
            # ç¡®ä¿analysis_resultæ˜¯å­—å…¸æ ¼å¼
            if isinstance(analysis_result, str):
                analysis_dict = {'reason': analysis_result, 'analysis': analysis_result}
            else:
                analysis_dict = analysis_result
            
            self._record_config_adjustment(
                current_config, validated_config, training_metrics, analysis_dict
            )
            
            self.status_updated.emit("ä¼˜åŒ–é…ç½®ç”Ÿæˆå®Œæˆ")
            return validated_config
            
        except Exception as e:
            self.error_occurred.emit(f"ç”Ÿæˆä¼˜åŒ–é…ç½®å¤±è´¥: {str(e)}")
            return current_config
    
    def _analyze_config_and_metrics(self, 
                                  config: Dict[str, Any], 
                                  metrics: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æé…ç½®å’Œè®­ç»ƒæŒ‡æ ‡"""
        try:
            # æ„å»ºåˆ†ææç¤ºè¯
            prompt = self._build_config_analysis_prompt(config, metrics)
            
            # ä½¿ç”¨LLMè¿›è¡Œåˆ†æ
            analysis_result = self.llm_framework.llm_adapter.analyze_metrics(metrics, prompt)
            
            return analysis_result
            
        except Exception as e:
            self.error_occurred.emit(f"åˆ†æé…ç½®å’ŒæŒ‡æ ‡å¤±è´¥: {str(e)}")
            return {'error': str(e)}
    
    def _build_config_analysis_prompt(self, 
                                    config: Dict[str, Any], 
                                    metrics: Dict[str, Any]) -> str:
        """æ„å»ºé…ç½®åˆ†ææç¤ºè¯"""
        return f"""
è¯·åŸºäºä»¥ä¸‹è®­ç»ƒé…ç½®å’Œå®æ—¶è®­ç»ƒæ•°æ®ï¼Œæä¾›ä¸“ä¸šçš„é…ç½®ä¼˜åŒ–å»ºè®®ï¼š

## ğŸ“‹ å½“å‰è®­ç»ƒé…ç½®
```json
{json.dumps(config, ensure_ascii=False, indent=2)}
```

## ğŸ“Š å®æ—¶è®­ç»ƒæŒ‡æ ‡
```json
{json.dumps(metrics, ensure_ascii=False, indent=2)}
```

## ğŸ¯ åˆ†æè¦æ±‚

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œæä¾›ä»¥ä¸‹åˆ†æï¼š

### 1. é…ç½®è¯„ä¼°
- å½“å‰é…ç½®æ˜¯å¦é€‚åˆå½“å‰æ•°æ®é›†å’Œä»»åŠ¡ï¼Ÿ
- æ˜¯å¦å­˜åœ¨æ˜æ˜¾çš„é…ç½®é—®é¢˜æˆ–å†²çªï¼Ÿ
- å“ªäº›å‚æ•°å¯èƒ½éœ€è¦è°ƒæ•´ï¼Ÿ

### 2. è®­ç»ƒçŠ¶æ€åˆ†æ
- å½“å‰è®­ç»ƒçŠ¶æ€ï¼ˆæ”¶æ•›ã€è¿‡æ‹Ÿåˆã€æ¬ æ‹Ÿåˆç­‰ï¼‰
- è®­ç»ƒæŒ‡æ ‡åæ˜ çš„é—®é¢˜
- ä¸é…ç½®å‚æ•°çš„å…³è”æ€§

### 3. ä¼˜åŒ–å»ºè®®
è¯·æä¾›å…·ä½“çš„å‚æ•°è°ƒæ•´å»ºè®®ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
```json
{{
    "suggestions": [
        {{
            "parameter": "learning_rate",
            "current_value": 0.001,
            "suggested_value": 0.0005,
            "reason": "è®­ç»ƒæŸå¤±ä¸‹é™ç¼“æ…¢ï¼Œå»ºè®®é™ä½å­¦ä¹ ç‡",
            "priority": "high"
        }},
        {{
            "parameter": "batch_size",
            "current_value": 32,
            "suggested_value": 16,
            "reason": "GPUå†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®å‡å°æ‰¹æ¬¡å¤§å°",
            "priority": "medium"
        }}
    ]
}}
```

### 4. æ³¨æ„äº‹é¡¹
- åªå»ºè®®è°ƒæ•´ç°æœ‰é…ç½®ä¸­çš„å‚æ•°
- ç¡®ä¿å»ºè®®å€¼åœ¨åˆç†èŒƒå›´å†…
- ä¼˜å…ˆè€ƒè™‘é«˜ä¼˜å…ˆçº§å»ºè®®
- ä¿æŒé…ç½®çš„å®Œæ•´æ€§å’Œä¸€è‡´æ€§

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒä¸“ä¸šæ€§å’Œå®ç”¨æ€§ã€‚
"""
    
    def _generate_optimization_suggestions(self, 
                                         config: Dict[str, Any],
                                         metrics: Dict[str, Any],
                                         analysis_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        try:
            # ä»LLMåˆ†æç»“æœä¸­æå–å»ºè®®
            if 'suggestions' in analysis_result:
                suggestions.extend(analysis_result['suggestions'])
            
            # åŸºäºè§„åˆ™ç”Ÿæˆé¢å¤–å»ºè®®
            rule_suggestions = self._generate_rule_based_suggestions(config, metrics)
            suggestions.extend(rule_suggestions)
            
            # æŒ‰ä¼˜å…ˆçº§æ’åº
            suggestions.sort(key=lambda x: x.get('priority', 'low'), reverse=True)
            
            return suggestions
            
        except Exception as e:
            self.error_occurred.emit(f"ç”Ÿæˆä¼˜åŒ–å»ºè®®å¤±è´¥: {str(e)}")
            return []
    
    def _generate_rule_based_suggestions(self, 
                                       config: Dict[str, Any],
                                       metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åŸºäºè§„åˆ™ç”Ÿæˆå»ºè®®"""
        suggestions = []
        
        try:
            train_loss = metrics.get('train_loss', 0)
            val_loss = metrics.get('val_loss', 0)
            train_acc = metrics.get('train_accuracy', 0)
            val_acc = metrics.get('val_accuracy', 0)
            epoch = metrics.get('epoch', 0)
            
            # è¿‡æ‹Ÿåˆæ£€æµ‹
            if val_loss > train_loss * 1.3 and epoch > 5:
                suggestions.append({
                    'parameter': 'dropout_rate',
                    'current_value': config.get('dropout_rate', 0.0),
                    'suggested_value': min(0.9, config.get('dropout_rate', 0.0) + 0.1),
                    'reason': 'æ£€æµ‹åˆ°è¿‡æ‹Ÿåˆï¼Œå»ºè®®å¢åŠ Dropoutç‡',
                    'priority': 'high'
                })
                
                suggestions.append({
                    'parameter': 'weight_decay',
                    'current_value': config.get('weight_decay', 0.0001),
                    'suggested_value': config.get('weight_decay', 0.0001) * 1.5,
                    'reason': 'æ£€æµ‹åˆ°è¿‡æ‹Ÿåˆï¼Œå»ºè®®å¢åŠ æƒé‡è¡°å‡',
                    'priority': 'high'
                })
            
            # æ¬ æ‹Ÿåˆæ£€æµ‹
            if train_acc < 0.6 and val_acc < 0.6 and epoch > 10:
                suggestions.append({
                    'parameter': 'learning_rate',
                    'current_value': config.get('learning_rate', 0.001),
                    'suggested_value': config.get('learning_rate', 0.001) * 1.5,
                    'reason': 'æ£€æµ‹åˆ°æ¬ æ‹Ÿåˆï¼Œå»ºè®®å¢åŠ å­¦ä¹ ç‡',
                    'priority': 'high'
                })
            
            # æ”¶æ•›ç¼“æ…¢æ£€æµ‹
            if train_loss > 0.5 and epoch > 15:
                suggestions.append({
                    'parameter': 'learning_rate',
                    'current_value': config.get('learning_rate', 0.001),
                    'suggested_value': config.get('learning_rate', 0.001) * 0.5,
                    'reason': 'è®­ç»ƒæ”¶æ•›ç¼“æ…¢ï¼Œå»ºè®®é™ä½å­¦ä¹ ç‡',
                    'priority': 'medium'
                })
            
            return suggestions
            
        except Exception as e:
            self.error_occurred.emit(f"ç”Ÿæˆè§„åˆ™å»ºè®®å¤±è´¥: {str(e)}")
            return []
    
    def _apply_optimization_suggestions(self, 
                                      config: Dict[str, Any],
                                      suggestions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åº”ç”¨ä¼˜åŒ–å»ºè®®åˆ°é…ç½®"""
        try:
            optimized_config = copy.deepcopy(config)
            
            for suggestion in suggestions:
                param_name = suggestion.get('parameter')
                suggested_value = suggestion.get('suggested_value')
                
                if param_name in optimized_config and suggested_value is not None:
                    # åº”ç”¨çº¦æŸ
                    constrained_value = self._apply_parameter_constraints(param_name, suggested_value)
                    optimized_config[param_name] = constrained_value
            
            return optimized_config
            
        except Exception as e:
            self.error_occurred.emit(f"åº”ç”¨ä¼˜åŒ–å»ºè®®å¤±è´¥: {str(e)}")
            return config
    
    def _apply_parameter_constraints(self, param_name: str, value: Any) -> Any:
        """åº”ç”¨å‚æ•°çº¦æŸ"""
        if param_name not in self.parameter_constraints:
            return value
        
        constraints = self.parameter_constraints[param_name]
        
        # åº”ç”¨èŒƒå›´çº¦æŸ
        if 'min' in constraints:
            value = max(value, constraints['min'])
        if 'max' in constraints:
            value = min(value, constraints['max'])
        
        # åº”ç”¨æ­¥é•¿çº¦æŸ
        if 'step' in constraints and isinstance(value, (int, float)):
            step = constraints['step']
            value = round(value / step) * step
        
        return value
    
    def _validate_config(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        try:
            validated_config = copy.deepcopy(config)
            
            # éªŒè¯å¿…éœ€å‚æ•°
            required_params = ['model_name', 'batch_size', 'learning_rate', 'num_epochs']
            for param in required_params:
                if param not in validated_config:
                    self.error_occurred.emit(f"ç¼ºå°‘å¿…éœ€å‚æ•°: {param}")
                    return config
            
            # éªŒè¯å‚æ•°ç±»å‹å’ŒèŒƒå›´
            for param_name, value in validated_config.items():
                if param_name in self.parameter_constraints:
                    validated_config[param_name] = self._apply_parameter_constraints(param_name, value)
            
            return validated_config
            
        except Exception as e:
            self.error_occurred.emit(f"éªŒè¯é…ç½®å¤±è´¥: {str(e)}")
            return config
    
    def _record_config_adjustment(self, 
                                original_config: Dict[str, Any],
                                adjusted_config: Dict[str, Any],
                                training_metrics: Dict[str, Any],
                                analysis_result: Dict[str, Any]):
        """è®°å½•é…ç½®è°ƒæ•´"""
        try:
            # è®¡ç®—å˜æ›´
            changes = {}
            for key, value in adjusted_config.items():
                if key in original_config and original_config[key] != value:
                    changes[key] = {
                        'from': original_config[key],
                        'to': value
                    }
            
            if not changes:
                return  # æ²¡æœ‰å˜æ›´ï¼Œä¸è®°å½•
            
            # åˆ›å»ºè°ƒæ•´è®°å½•
            adjustment = ConfigAdjustment(
                adjustment_id=f"adj_{int(time.time())}",
                timestamp=time.time(),
                original_config=copy.deepcopy(original_config),
                adjusted_config=copy.deepcopy(adjusted_config),
                changes=changes,
                reason=analysis_result.get('reason', 'æ™ºèƒ½ä¼˜åŒ–å»ºè®®'),
                training_metrics=copy.deepcopy(training_metrics),
                llm_analysis=copy.deepcopy(analysis_result),
                status='pending'
            )
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            self.adjustment_history.append(adjustment)
            if self.current_session:
                self.current_session.adjustments.append(adjustment)
            
            # å‘å°„ä¿¡å·
            self.adjustment_recorded.emit(asdict(adjustment))
            
        except Exception as e:
            self.error_occurred.emit(f"è®°å½•é…ç½®è°ƒæ•´å¤±è´¥: {str(e)}")
    
    def apply_config_to_training_system(self, 
                                      config: Dict[str, Any],
                                      training_tab) -> bool:
        """å°†é…ç½®åº”ç”¨åˆ°è®­ç»ƒç³»ç»Ÿ"""
        try:
            self.status_updated.emit("æ­£åœ¨åº”ç”¨é…ç½®åˆ°è®­ç»ƒç³»ç»Ÿ...")
            
            # ä½¿ç”¨ç°æœ‰çš„ConfigApplieråº”ç”¨é…ç½®
            from ..ui.components.training.config_applier import ConfigApplier
            success = ConfigApplier.apply_to_training_tab(config, training_tab)
            
            if success:
                self.status_updated.emit("é…ç½®åº”ç”¨æˆåŠŸ")
                self.config_applied.emit({
                    'config': config,
                    'timestamp': time.time(),
                    'success': True
                })
            else:
                self.error_occurred.emit("é…ç½®åº”ç”¨å¤±è´¥")
                self.config_applied.emit({
                    'config': config,
                    'timestamp': time.time(),
                    'success': False
                })
            
            return success
            
        except Exception as e:
            self.error_occurred.emit(f"åº”ç”¨é…ç½®åˆ°è®­ç»ƒç³»ç»Ÿå¤±è´¥: {str(e)}")
            return False
    
    def get_adjustment_history(self) -> List[Dict[str, Any]]:
        """è·å–è°ƒæ•´å†å²"""
        return [asdict(adj) for adj in self.adjustment_history]
    
    def get_current_session_info(self) -> Dict[str, Any]:
        """è·å–å½“å‰ä¼šè¯ä¿¡æ¯"""
        if not self.current_session:
            return {}
        
        return {
            'session_id': self.current_session.session_id,
            'start_time': self.current_session.start_time,
            'status': self.current_session.status,
            'adjustment_count': len(self.current_session.adjustments),
            'original_config': self.current_session.original_config,
            'final_config': self.current_session.final_config
        }
    
    def export_adjustment_report(self) -> Dict[str, Any]:
        """å¯¼å‡ºè°ƒæ•´æŠ¥å‘Š"""
        return {
            'export_time': time.time(),
            'current_session': self.get_current_session_info(),
            'adjustment_history': self.get_adjustment_history(),
            'parameter_constraints': self.parameter_constraints
        }
    
    def stop_training_session(self):
        """åœæ­¢è®­ç»ƒä¼šè¯"""
        if self.current_session:
            self.current_session.status = 'completed'
            self.current_session.final_config = self.current_session.adjustments[-1].adjusted_config if self.current_session.adjustments else self.current_session.original_config
            self.status_updated.emit(f"è®­ç»ƒä¼šè¯ {self.current_session.session_id} å·²åœæ­¢")