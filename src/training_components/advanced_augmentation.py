"""
é«˜çº§æ•°æ®å¢å¼º - ç¬¬äºŒé˜¶æ®µé«˜çº§ç‰¹æ€§

å®ç°CutMixå’ŒMixUpç­‰é«˜çº§æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œæå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import random
from typing import Tuple, Union


class MixUpAugmentation:
    """
    MixUpæ•°æ®å¢å¼º
    
    MixUpé€šè¿‡çº¿æ€§æ’å€¼æ··åˆä¸¤ä¸ªæ ·æœ¬åŠå…¶æ ‡ç­¾ï¼Œç”Ÿæˆæ–°çš„è®­ç»ƒæ ·æœ¬ã€‚
    è¿™ç§æ–¹æ³•å¯ä»¥æœ‰æ•ˆæå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚
    """
    
    def __init__(self, alpha: float = 1.0):
        """
        åˆå§‹åŒ–MixUpå¢å¼º
        
        Args:
            alpha: Betaåˆ†å¸ƒçš„å‚æ•°ï¼Œæ§åˆ¶æ··åˆå¼ºåº¦
        """
        self.alpha = alpha
    
    def __call__(self, x: torch.Tensor, y: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, float]:
        """
        æ‰§è¡ŒMixUpå¢å¼º
        
        Args:
            x: è¾“å…¥å›¾åƒå¼ é‡ [batch_size, channels, height, width]
            y: æ ‡ç­¾å¼ é‡ [batch_size]
            
        Returns:
            mixed_x: æ··åˆåçš„å›¾åƒ
            y_a: ç¬¬ä¸€ä¸ªæ ‡ç­¾
            y_b: ç¬¬äºŒä¸ªæ ‡ç­¾
            lam: æ··åˆæ¯”ä¾‹
        """
        if self.alpha > 0:
            lam = np.random.beta(self.alpha, self.alpha)
        else:
            lam = 1.0
        
        batch_size = x.size(0)
        index = torch.randperm(batch_size).to(x.device)
        
        mixed_x = lam * x + (1 - lam) * x[index, :]
        y_a, y_b = y, y[index]
        
        return mixed_x, y_a, y_b, lam


class CutMixAugmentation:
    """
    CutMixæ•°æ®å¢å¼º
    
    CutMixé€šè¿‡å‰ªåˆ‡ä¸€ä¸ªå›¾åƒçš„çŸ©å½¢åŒºåŸŸå¹¶ç²˜è´´åˆ°å¦ä¸€ä¸ªå›¾åƒä¸Šï¼Œ
    åŒæ—¶æŒ‰æ¯”ä¾‹æ··åˆæ ‡ç­¾ã€‚è¿™ç§æ–¹æ³•ä¿æŒäº†å›¾åƒçš„å±€éƒ¨ç‰¹å¾ã€‚
    """
    
    def __init__(self, alpha: float = 1.0):
        """
        åˆå§‹åŒ–CutMixå¢å¼º
        
        Args:
            alpha: Betaåˆ†å¸ƒçš„å‚æ•°ï¼Œæ§åˆ¶å‰ªåˆ‡åŒºåŸŸå¤§å°
        """
        self.alpha = alpha
    
    def rand_bbox(self, size: Tuple[int, int, int, int], lam: float) -> Tuple[int, int, int, int]:
        """
        ç”Ÿæˆéšæœºè¾¹ç•Œæ¡†
        
        Args:
            size: å›¾åƒå°ºå¯¸ (batch_size, channels, height, width)
            lam: æ··åˆæ¯”ä¾‹
            
        Returns:
            è¾¹ç•Œæ¡†åæ ‡ (bbx1, bby1, bbx2, bby2)
        """
        W = size[2]
        H = size[3]
        cut_rat = np.sqrt(1. - lam)
        cut_w = np.int32(W * cut_rat)
        cut_h = np.int32(H * cut_rat)
        
        # éšæœºé€‰æ‹©ä¸­å¿ƒç‚¹
        cx = np.random.randint(W)
        cy = np.random.randint(H)
        
        bbx1 = np.clip(cx - cut_w // 2, 0, W)
        bby1 = np.clip(cy - cut_h // 2, 0, H)
        bbx2 = np.clip(cx + cut_w // 2, 0, W)
        bby2 = np.clip(cy + cut_h // 2, 0, H)
        
        return bbx1, bby1, bbx2, bby2
    
    def __call__(self, x: torch.Tensor, y: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, float]:
        """
        æ‰§è¡ŒCutMixå¢å¼º
        
        Args:
            x: è¾“å…¥å›¾åƒå¼ é‡ [batch_size, channels, height, width]
            y: æ ‡ç­¾å¼ é‡ [batch_size]
            
        Returns:
            mixed_x: æ··åˆåçš„å›¾åƒ
            y_a: ç¬¬ä¸€ä¸ªæ ‡ç­¾
            y_b: ç¬¬äºŒä¸ªæ ‡ç­¾
            lam: æ··åˆæ¯”ä¾‹ï¼ˆåŸºäºå®é™…å‰ªåˆ‡é¢ç§¯è°ƒæ•´ï¼‰
        """
        if self.alpha > 0:
            lam = np.random.beta(self.alpha, self.alpha)
        else:
            lam = 1.0
        
        batch_size = x.size(0)
        index = torch.randperm(batch_size).to(x.device)
        
        y_a, y_b = y, y[index]
        bbx1, bby1, bbx2, bby2 = self.rand_bbox(x.size(), lam)
        
        x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]
        
        # æ ¹æ®å®é™…å‰ªåˆ‡é¢ç§¯è°ƒæ•´lambda
        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))
        
        return x, y_a, y_b, lam


class MixCriterion:
    """
    æ··åˆæŸå¤±å‡½æ•°
    
    ç”¨äºè®¡ç®—MixUpå’ŒCutMixå¢å¼ºåçš„æŸå¤±
    """
    
    def __init__(self, criterion):
        """
        åˆå§‹åŒ–æ··åˆæŸå¤±å‡½æ•°
        
        Args:
            criterion: åŸºç¡€æŸå¤±å‡½æ•°
        """
        self.criterion = criterion
    
    def __call__(self, pred: torch.Tensor, y_a: torch.Tensor, y_b: torch.Tensor, lam: float) -> torch.Tensor:
        """
        è®¡ç®—æ··åˆæŸå¤±
        
        Args:
            pred: æ¨¡å‹é¢„æµ‹è¾“å‡º
            y_a: ç¬¬ä¸€ä¸ªæ ‡ç­¾
            y_b: ç¬¬äºŒä¸ªæ ‡ç­¾
            lam: æ··åˆæ¯”ä¾‹
            
        Returns:
            æ··åˆæŸå¤±å€¼
        """
        return lam * self.criterion(pred, y_a) + (1 - lam) * self.criterion(pred, y_b)


class AdvancedAugmentationManager:
    """
    é«˜çº§æ•°æ®å¢å¼ºç®¡ç†å™¨
    
    ç»Ÿä¸€ç®¡ç†MixUpå’ŒCutMixå¢å¼ºï¼Œæ ¹æ®é…ç½®è‡ªåŠ¨é€‰æ‹©å¢å¼ºç­–ç•¥
    """
    
    def __init__(self, config: dict):
        """
        åˆå§‹åŒ–å¢å¼ºç®¡ç†å™¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨é«˜çº§æ•°æ®å¢å¼º
        self.advanced_augmentation_enabled = config.get('advanced_augmentation_enabled', False)
        
        # åªæœ‰åœ¨å¯ç”¨æ—¶æ‰è¯»å–å‚æ•°å€¼
        if self.advanced_augmentation_enabled:
            self.mixup_prob = config.get('mixup_alpha', 0.0)
            self.cutmix_prob = config.get('cutmix_prob', 0.0)
            
            # å‚æ•°éªŒè¯
            self.mixup_prob = max(0.0, min(2.0, self.mixup_prob))  # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
            self.cutmix_prob = max(0.0, min(1.0, self.cutmix_prob))  # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        else:
            # å¦‚æœç¦ç”¨ï¼Œå¼ºåˆ¶è®¾ç½®ä¸º0
            self.mixup_prob = 0.0
            self.cutmix_prob = 0.0
        
        # åˆå§‹åŒ–å¢å¼ºå™¨ï¼ˆåªæœ‰åœ¨å¯ç”¨ä¸”å‚æ•°å€¼å¤§äº0æ—¶ï¼‰
        self.mixup = MixUpAugmentation(alpha=self.mixup_prob) if self.mixup_prob > 0 else None
        self.cutmix = CutMixAugmentation(alpha=1.0) if self.cutmix_prob > 0 else None
        
        # å¯ç”¨çŠ¶æ€ï¼šå¿…é¡»åŒæ—¶æ»¡è¶³å¯ç”¨å¼€å…³å’Œå‚æ•°å€¼å¤§äº0
        self.enabled = self.advanced_augmentation_enabled and (self.mixup_prob > 0 or self.cutmix_prob > 0)
        
        # è®°å½•é…ç½®ä¿¡æ¯
        self._log_configuration()
    
    def _log_configuration(self):
        """è®°å½•é…ç½®ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        if self.enabled:
            methods = []
            if self.mixup_prob > 0:
                methods.append(f"MixUp(Î±={self.mixup_prob})")
            if self.cutmix_prob > 0:
                methods.append(f"CutMix(p={self.cutmix_prob})")
            print(f"ğŸš€ é«˜çº§æ•°æ®å¢å¼ºå·²å¯ç”¨: {', '.join(methods)}")
        else:
            if self.advanced_augmentation_enabled:
                print("âšª é«˜çº§æ•°æ®å¢å¼ºå·²å¯ç”¨ä½†å‚æ•°å€¼ä¸º0ï¼Œå®é™…æœªç”Ÿæ•ˆ")
            else:
                print("âšª é«˜çº§æ•°æ®å¢å¼ºå·²ç¦ç”¨")
    
    def get_augmentation_info(self) -> dict:
        """è·å–å¢å¼ºé…ç½®ä¿¡æ¯"""
        return {
            'enabled': self.enabled,
            'advanced_augmentation_enabled': self.advanced_augmentation_enabled,
            'mixup_prob': self.mixup_prob,
            'cutmix_prob': self.cutmix_prob,
            'mixup_available': self.mixup is not None,
            'cutmix_available': self.cutmix is not None
        }
    
    def is_enabled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†é«˜çº§å¢å¼º"""
        return self.enabled
    
    def __call__(self, x: torch.Tensor, y: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, float, str]:
        """
        æ‰§è¡Œé«˜çº§æ•°æ®å¢å¼º
        
        Args:
            x: è¾“å…¥å›¾åƒå¼ é‡
            y: æ ‡ç­¾å¼ é‡
            
        Returns:
            mixed_x: å¢å¼ºåçš„å›¾åƒ
            y_a: ç¬¬ä¸€ä¸ªæ ‡ç­¾
            y_b: ç¬¬äºŒä¸ªæ ‡ç­¾
            lam: æ··åˆæ¯”ä¾‹
            method: ä½¿ç”¨çš„å¢å¼ºæ–¹æ³•
        """
        if not self.enabled:
            return x, y, y, 1.0, 'none'
        
        # éšæœºé€‰æ‹©å¢å¼ºæ–¹æ³•
        r = np.random.rand(1)
        
        if self.cutmix_prob > 0 and r < self.cutmix_prob:
            # ä½¿ç”¨CutMix
            mixed_x, y_a, y_b, lam = self.cutmix(x, y)
            return mixed_x, y_a, y_b, lam, 'cutmix'
        elif self.mixup_prob > 0:
            # ä½¿ç”¨MixUp
            mixed_x, y_a, y_b, lam = self.mixup(x, y)
            return mixed_x, y_a, y_b, lam, 'mixup'
        else:
            # ä¸ä½¿ç”¨å¢å¼º
            return x, y, y, 1.0, 'none'
    
    def get_criterion(self, base_criterion) -> MixCriterion:
        """
        è·å–æ··åˆæŸå¤±å‡½æ•°
        
        Args:
            base_criterion: åŸºç¡€æŸå¤±å‡½æ•°
            
        Returns:
            æ··åˆæŸå¤±å‡½æ•°
        """
        return MixCriterion(base_criterion)


class LabelSmoothingCrossEntropy(nn.Module):
    """
    æ ‡ç­¾å¹³æ»‘äº¤å‰ç†µæŸå¤±
    
    ç»“åˆæ ‡ç­¾å¹³æ»‘å’Œäº¤å‰ç†µï¼Œæå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›
    """
    
    def __init__(self, smoothing: float = 0.1):
        """
        åˆå§‹åŒ–æ ‡ç­¾å¹³æ»‘äº¤å‰ç†µ
        
        Args:
            smoothing: æ ‡ç­¾å¹³æ»‘å‚æ•°
        """
        super().__init__()
        self.smoothing = smoothing
    
    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            pred: æ¨¡å‹é¢„æµ‹ [batch_size, num_classes]
            target: çœŸå®æ ‡ç­¾ [batch_size]
            
        Returns:
            æŸå¤±å€¼
        """
        num_classes = pred.size(-1)
        log_preds = F.log_softmax(pred, dim=-1)
        
        # åˆ›å»ºå¹³æ»‘æ ‡ç­¾
        targets = torch.zeros_like(log_preds).scatter_(1, target.unsqueeze(1), 1)
        targets = (1 - self.smoothing) * targets + self.smoothing / num_classes
        
        return (-targets * log_preds).sum(dim=1).mean()


def create_advanced_criterion(config: dict, base_criterion=None):
    """
    åˆ›å»ºé«˜çº§æŸå¤±å‡½æ•°
    
    Args:
        config: é…ç½®å­—å…¸
        base_criterion: åŸºç¡€æŸå¤±å‡½æ•°
        
    Returns:
        å¢å¼ºçš„æŸå¤±å‡½æ•°
    """
    # æ£€æŸ¥æ ‡ç­¾å¹³æ»‘å¯ç”¨çŠ¶æ€
    label_smoothing_enabled = config.get('label_smoothing_enabled', False)
    label_smoothing = config.get('label_smoothing', 0.0) if label_smoothing_enabled else 0.0
    
    if label_smoothing_enabled and label_smoothing > 0:
        # ä½¿ç”¨æ ‡ç­¾å¹³æ»‘äº¤å‰ç†µ
        criterion = LabelSmoothingCrossEntropy(smoothing=label_smoothing)
    else:
        # ä½¿ç”¨åŸºç¡€æŸå¤±å‡½æ•°
        criterion = base_criterion if base_criterion is not None else nn.CrossEntropyLoss()
    
    # å¦‚æœå¯ç”¨äº†é«˜çº§æ•°æ®å¢å¼ºï¼Œè¿”å›æ··åˆæŸå¤±å‡½æ•°
    aug_manager = AdvancedAugmentationManager(config)
    if aug_manager.is_enabled():
        return aug_manager.get_criterion(criterion), aug_manager
    else:
        return criterion, None 