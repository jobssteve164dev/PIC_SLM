#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
AIè®¾ç½®å®Œæ•´é›†æˆæµ‹è¯•è„šæœ¬
æµ‹è¯•AIè®¾ç½®ç»„ä»¶ä¸æ¨¡å‹å·¥å‚Tabçš„å®Œæ•´é›†æˆåŠŸèƒ½
"""

import sys
import os
import json
import traceback
from datetime import datetime

# è®¾ç½®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

def test_ai_config_file_operations():
    """æµ‹è¯•AIé…ç½®æ–‡ä»¶æ“ä½œ"""
    print("ğŸ”§ æµ‹è¯•AIé…ç½®æ–‡ä»¶æ“ä½œ...")
    
    try:
        # æµ‹è¯•é…ç½®æ•°æ®
        test_config = {
            'openai': {
                'api_key': 'sk-test12345',
                'base_url': 'https://api.openai.com/v1',
                'model': 'gpt-4',
                'temperature': 0.7,
                'max_tokens': 1000
            },
            'ollama': {
                'base_url': 'http://localhost:11434',
                'model': 'llama2',
                'temperature': 0.7,
                'num_predict': 1000
            },
            'general': {
                'default_adapter': 'openai',
                'request_timeout': 60,
                'max_retries': 3,
                'enable_cache': True,
                'enable_streaming': False
            }
        }
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs("setting", exist_ok=True)
        
        # ä¿å­˜é…ç½®
        config_file = "setting/ai_config.json"
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(test_config, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ°: {config_file}")
        
        # è¯»å–é…ç½®éªŒè¯
        with open(config_file, 'r', encoding='utf-8') as f:
            loaded_config = json.load(f)
        
        print(f"âœ… é…ç½®æ–‡ä»¶è¯»å–æˆåŠŸï¼ŒåŒ…å« {len(loaded_config)} ä¸ªé…ç½®ç»„")
        print(f"   - OpenAIé…ç½®: {loaded_config.get('openai', {}).get('model', 'N/A')}")
        print(f"   - Ollamaé…ç½®: {loaded_config.get('ollama', {}).get('model', 'N/A')}")
        print(f"   - é»˜è®¤é€‚é…å™¨: {loaded_config.get('general', {}).get('default_adapter', 'N/A')}")
        
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶æ“ä½œå¤±è´¥: {str(e)}")
        traceback.print_exc()
        return False

def test_model_factory_config_loading():
    """æµ‹è¯•æ¨¡å‹å·¥å‚Tabçš„é…ç½®åŠ è½½åŠŸèƒ½"""
    print("\nğŸ­ æµ‹è¯•æ¨¡å‹å·¥å‚Tabé…ç½®åŠ è½½...")
    
    try:
        from src.ui.model_factory_tab import LLMChatWidget
        
        # åˆ›å»ºèŠå¤©ç»„ä»¶å®ä¾‹
        chat_widget = LLMChatWidget()
        
        # æµ‹è¯•é…ç½®åŠ è½½æ–¹æ³•
        ai_config = chat_widget.load_ai_config()
        
        print(f"âœ… AIé…ç½®åŠ è½½æˆåŠŸ")
        print(f"   - OpenAI APIå¯†é’¥: {'å·²é…ç½®' if ai_config.get('openai', {}).get('api_key') else 'æœªé…ç½®'}")
        print(f"   - OpenAIæ¨¡å‹: {ai_config.get('openai', {}).get('model', 'N/A')}")
        print(f"   - OllamaæœåŠ¡å™¨: {ai_config.get('ollama', {}).get('base_url', 'N/A')}")
        print(f"   - Ollamaæ¨¡å‹: {ai_config.get('ollama', {}).get('model', 'N/A')}")
        print(f"   - é»˜è®¤é€‚é…å™¨: {ai_config.get('general', {}).get('default_adapter', 'N/A')}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹å·¥å‚Tabé…ç½®åŠ è½½å¤±è´¥: {str(e)}")
        traceback.print_exc()
        return False

def test_llm_framework_with_config():
    """æµ‹è¯•LLMæ¡†æ¶ä¸é…ç½®çš„é›†æˆ"""
    print("\nğŸ§  æµ‹è¯•LLMæ¡†æ¶é…ç½®é›†æˆ...")
    
    try:
        from src.llm.llm_framework import LLMFramework
        
        # æµ‹è¯•ä¸åŒé€‚é…å™¨ç±»å‹çš„åˆå§‹åŒ–
        test_configs = [
            ('mock', {}),
            ('openai', {
                'api_key': 'sk-test12345',
                'model': 'gpt-4',
                'temperature': 0.7,
                'max_tokens': 1000
            }),
            ('local', {
                'model_name': 'llama2',
                'base_url': 'http://localhost:11434',
                'temperature': 0.7
            })
        ]
        
        for adapter_type, adapter_config in test_configs:
            try:
                print(f"   æµ‹è¯• {adapter_type} é€‚é…å™¨...")
                framework = LLMFramework(adapter_type, adapter_config)
                framework.start()
                
                stats = framework.get_framework_stats()
                print(f"   âœ… {adapter_type} é€‚é…å™¨åˆå§‹åŒ–æˆåŠŸ")
                
            except Exception as e:
                print(f"   âš ï¸ {adapter_type} é€‚é…å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ LLMæ¡†æ¶é…ç½®é›†æˆæµ‹è¯•å¤±è´¥: {str(e)}")
        traceback.print_exc()
        return False

def test_ai_settings_widget():
    """æµ‹è¯•AIè®¾ç½®ç»„ä»¶"""
    print("\nğŸ¤– æµ‹è¯•AIè®¾ç½®ç»„ä»¶...")
    
    try:
        from PyQt5.QtWidgets import QApplication
        from src.ui.components.settings.ai_settings_widget import AISettingsWidget
        
        # åˆ›å»ºåº”ç”¨å®ä¾‹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if not QApplication.instance():
            app = QApplication([])
        
        # åˆ›å»ºAIè®¾ç½®ç»„ä»¶
        ai_widget = AISettingsWidget()
        
        print("âœ… AIè®¾ç½®ç»„ä»¶åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•é…ç½®åŠ è½½
        ai_widget.load_config()
        print("âœ… AIè®¾ç½®é…ç½®åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•è·å–å½“å‰é…ç½®
        current_config = ai_widget.get_config()
        print(f"âœ… å½“å‰é…ç½®è·å–æˆåŠŸï¼ŒåŒ…å« {len(current_config)} ä¸ªé…ç½®ç»„")
        
        return True
        
    except Exception as e:
        print(f"âŒ AIè®¾ç½®ç»„ä»¶æµ‹è¯•å¤±è´¥: {str(e)}")
        traceback.print_exc()
        return False

def test_settings_integration():
    """æµ‹è¯•è®¾ç½®Tabé›†æˆåŠŸèƒ½"""
    print("\nâš™ï¸ æµ‹è¯•è®¾ç½®Tabé›†æˆ...")
    
    try:
        # æ¨¡æ‹ŸAIè®¾ç½®å˜åŒ–
        test_ai_config = {
            'openai': {
                'api_key': 'sk-test12345',
                'model': 'gpt-4',
                'temperature': 0.8
            },
            'ollama': {
                'model': 'llama2',
                'base_url': 'http://localhost:11434'
            },
            'general': {
                'default_adapter': 'openai'
            }
        }
        
        # æµ‹è¯•é…ç½®ä¿å­˜é€»è¾‘
        import json
        os.makedirs("setting", exist_ok=True)
        config_file = "setting/ai_config.json"
        
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(test_ai_config, f, indent=2, ensure_ascii=False)
        
        print("âœ… è®¾ç½®Tabé…ç½®ä¿å­˜æ¨¡æ‹ŸæˆåŠŸ")
        
        # éªŒè¯é…ç½®æ–‡ä»¶
        with open(config_file, 'r', encoding='utf-8') as f:
            saved_config = json.load(f)
        
        assert saved_config['general']['default_adapter'] == 'openai'
        assert saved_config['openai']['model'] == 'gpt-4'
        
        print("âœ… è®¾ç½®Tabé›†æˆæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ è®¾ç½®Tabé›†æˆæµ‹è¯•å¤±è´¥: {str(e)}")
        traceback.print_exc()
        return False

def cleanup_test_files():
    """æ¸…ç†æµ‹è¯•æ–‡ä»¶"""
    print("\nğŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶...")
    
    try:
        test_file = "setting/ai_config.json"
        if os.path.exists(test_file):
            os.remove(test_file)
            print(f"âœ… å·²æ¸…ç†æµ‹è¯•æ–‡ä»¶: {test_file}")
        
    except Exception as e:
        print(f"âš ï¸ æ¸…ç†æµ‹è¯•æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("ğŸ§ª AIè®¾ç½®å®Œæ•´é›†æˆæµ‹è¯•")
    print("=" * 60)
    
    test_results = []
    
    # æ‰§è¡Œå„é¡¹æµ‹è¯•
    tests = [
        ("AIé…ç½®æ–‡ä»¶æ“ä½œ", test_ai_config_file_operations),
        ("æ¨¡å‹å·¥å‚é…ç½®åŠ è½½", test_model_factory_config_loading),
        ("LLMæ¡†æ¶é…ç½®é›†æˆ", test_llm_framework_with_config),
        ("AIè®¾ç½®ç»„ä»¶", test_ai_settings_widget),
        ("è®¾ç½®Tabé›†æˆ", test_settings_integration),
    ]
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            result = test_func()
            test_results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å‡ºç°å¼‚å¸¸: {str(e)}")
            test_results.append((test_name, False))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name:<20} {status}")
        if result:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼AIè®¾ç½®é›†æˆåŠŸèƒ½æ­£å¸¸å·¥ä½œ")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")
    
    # æ¸…ç†æµ‹è¯•æ–‡ä»¶
    cleanup_test_files()
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 